{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import sklearn\n",
    "import warnings\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('Auto.csv', na_values='?')\n",
    "data=data.dropna()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumervaid/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data['horsepower'] = data['horsepower'].convert_objects(convert_numeric = True)\n",
    "#create dummy variable below, based on median value of mpg\n",
    "data['mpg_high'] = data['mpg'].apply(lambda x: 1 if x >= data['mpg'].median() else 0).astype('category')\n",
    "\n",
    "data['const'] = 1\n",
    "xvars = data[['const','cylinders', 'displacement', 'horsepower', 'weight',\n",
    "              'acceleration', 'year', 'origin']].values\n",
    "yvals = data['mpg_high'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1) Part a):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When k= 0\n",
      "The error rate (mpghigh= 0) is 0.08\n",
      "The error rate (mpghigh= 1)  is 0.0833333333333\n",
      "The MSE of the model is 0.0816326530612\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.920     0.920     0.920        50\n",
      "          1      0.917     0.917     0.917        48\n",
      "\n",
      "avg / total      0.918     0.918     0.918        98\n",
      "\n",
      "\n",
      "k-fold results:\n",
      "The avg. error rate (mpghigh=0) is 0.02 and the stdev is 0.0346410161514\n",
      "The avg. error rate (mpghigh= 1) is 0.0208333333333 and the stdev is 0.0360843918244\n",
      "The avg. MSE is 0.0816326530612 and the stdev is 0.0\n",
      "When k= 1\n",
      "The error rate (mpghigh= 0) is 0.133333333333\n",
      "The error rate (mpghigh= 1)  is 0.11320754717\n",
      "The MSE of the model is 0.122448979592\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.867     0.867     0.867        45\n",
      "          1      0.887     0.887     0.887        53\n",
      "\n",
      "avg / total      0.878     0.878     0.878        98\n",
      "\n",
      "\n",
      "k-fold results:\n",
      "The avg. error rate (mpghigh=0) is 0.0533333333333 and the stdev is 0.0565685424949\n",
      "The avg. error rate (mpghigh= 1) is 0.0491352201258 and the stdev is 0.0502576206993\n",
      "The avg. MSE is 0.122448979592 and the stdev is 0.0\n",
      "When k= 2\n",
      "The error rate (mpghigh= 0) is 0.0425531914894\n",
      "The error rate (mpghigh= 1)  is 0.156862745098\n",
      "The MSE of the model is 0.102040816327\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.957     0.849     0.900        53\n",
      "          1      0.843     0.956     0.896        45\n",
      "\n",
      "avg / total      0.905     0.898     0.898        98\n",
      "\n",
      "\n",
      "k-fold results:\n",
      "The avg. error rate (mpghigh=0) is 0.0639716312057 and the stdev is 0.0490384376975\n",
      "The avg. error rate (mpghigh= 1) is 0.0883509064003 and the stdev is 0.0573209894657\n",
      "The avg. MSE is 0.102040816327 and the stdev is 0.0\n",
      "When k= 3\n",
      "The error rate (mpghigh= 0) is 0.0851063829787\n",
      "The error rate (mpghigh= 1)  is 0.0980392156863\n",
      "The MSE of the model is 0.0918367346939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.915     0.896     0.905        48\n",
      "          1      0.902     0.920     0.911        50\n",
      "\n",
      "avg / total      0.908     0.908     0.908        98\n",
      "\n",
      "\n",
      "k-fold results:\n",
      "The avg. error rate (mpghigh=0) is 0.0852482269504 and the stdev is 0.0322591363598\n",
      "The avg. error rate (mpghigh= 1) is 0.112860710322 and the stdev is 0.0275129154003\n",
      "The avg. MSE is 0.0918367346939 and the stdev is 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k=4\n",
    "kfold=KFold(n_splits=k, random_state=9, shuffle=True)\n",
    "kfold.get_n_splits(xvars)\n",
    "error0=np.zeros(k)\n",
    "error1=np.zeros(k)\n",
    "errormse=np.zeros(k)\n",
    "\n",
    "k_ind=int(0)\n",
    "\n",
    "\n",
    "for train_index, test_index in kfold.split(xvars):\n",
    "    print(\"When k=\", k_ind)\n",
    "    X_train, X_test=xvars[train_index], xvars[test_index]\n",
    "    y_train, y_test=yvals[train_index], yvals[test_index]\n",
    "    Reg=LogisticRegression(fit_intercept=True)\n",
    "    Reg.fit(X_train, y_train)\n",
    "    ypred=Reg.predict(X_test)\n",
    "    error=y_test!=ypred\n",
    "    error_all_class=error.mean()\n",
    "    error_0=((ypred==0)*error).sum()/(ypred==0).sum()\n",
    "    error_1=((ypred==1)*error).sum()/(ypred==1).sum()\n",
    "    error0[k_ind]=error_0\n",
    "    error1[k_ind]=error_1\n",
    "    errormse=error_all_class\n",
    "    print(\"The error rate (mpghigh= 0) is\", error_0)\n",
    "    print(\"The error rate (mpghigh= 1)  is\" ,error_1)\n",
    "    print(\"The MSE of the model is\", error_all_class)\n",
    "    print(classification_report(y_test, ypred, digits=3))\n",
    "\n",
    "    k_ind += 1\n",
    "    print(\"\\nk-fold results:\")\n",
    "    print(\"The avg. error rate (mpghigh=0) is\", error0.mean(), \"and the stdev is\", error0.std())\n",
    "    print(\"The avg. error rate (mpghigh= 1) is\", error1.mean(), \"and the stdev is\", error1.std())\n",
    "    print(\"The avg. MSE is\", errormse.mean(), \"and the stdev is\", errormse.std())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1) Part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=True, random_state=25, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=20, max_features=2,bootstrap=True, oob_score=True, random_state=25)\n",
    "rf.fit(xvars, yvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the model is 0.0790816326531\n",
      "MSE for mpg_high=1 is 0.0714285714286\n",
      "MSE for mpg_high=0 is 0.0867346938776\n"
     ]
    }
   ],
   "source": [
    "decision=rf.oob_decision_function_[:,1]\n",
    "binary=np.vectorize(lambda xvars: int(xvars>=.5))\n",
    "ypred=binary(decision)\n",
    "mse_all=mean_squared_error(yvals, ypred)\n",
    "print(\"The MSE of the model is\", mse_all)\n",
    "treedf=pd.DataFrame({'y':yvals, 'ypred': ypred})\n",
    "treedf['MSE']=treedf.apply(lambda x:(x['y']-x['ypred'])**2, axis=1)\n",
    "print(\"MSE for mpg_high=1 is\", treedf.groupby(yvals)[\"MSE\"].mean()[1])\n",
    "print(\"MSE for mpg_high=0 is\", treedf.groupby(yvals)[\"MSE\"].mean()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 Part c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When k index= 0\n",
      "The MSE for the test set 0 is 0.0\n",
      "When k index= 1\n",
      "The MSE for the test set 1 is 0.0\n",
      "When k index= 2\n",
      "The MSE for the test set 2 is 0.0\n",
      "When k index= 3\n",
      "The MSE for the test set 3 is 0.0\n",
      "The MSE k-fold estimate is 0.0\n",
      "The MSE stdev is 0.0\n"
     ]
    }
   ],
   "source": [
    "k=4\n",
    "kfold=KFold(n_splits=k, random_state=15, shuffle=True)\n",
    "kfold.get_n_splits(xvars)\n",
    "svmerr0=np.zeros(k)\n",
    "svmerr1=np.zeros(k)\n",
    "svm_mse=np.zeros(k)\n",
    "k_ind=int(0)\n",
    "\n",
    "for train_index, test_index in kfold.split(xvars):\n",
    "    print('When k index=', k_ind)\n",
    "    x_train, x_test=xvars[train_index], xvars[test_index]\n",
    "    y_train, y_test=yvals[train_index], yvals[test_index]\n",
    "    svc=svm.SVC(kernel='rbf', gamma=0.2, C=1)\n",
    "    svc.fit(x_train, y_train)\n",
    "    y_pred=svc.predict(x_test)\n",
    "    error=y_test!=y_pred\n",
    "    errorall=error.mean()\n",
    "    error_0=((y_pred==0)*error).sum()/(y_pred==0).sum()\n",
    "    error_1=((y_pred==1)*error).sum()/(y_pred==1).sum()\n",
    "    svmerr0[k_ind]=error_0\n",
    "    svmerr1[k_ind]=error_1\n",
    "    svm_mse[k_ind]=((y_test-y_pred)**2).mean()\n",
    "    print(\"The MSE for the test set\", k_ind, \"is\",svmgeneral_mse[k_ind])\n",
    "    k_ind+=1\n",
    "    \n",
    "msekf=svmgeneral_mse.mean()\n",
    "kfstd=svmgeneral_mse.std()\n",
    "print(\"The MSE k-fold estimate is\", msekf)\n",
    "print(\"The MSE stdev is\", kfstd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am unable to obtain the correct SVC error values for some reason. I would assume that under usual cases, either Random Forest or logistic regression would provide a better fit than SVC. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
