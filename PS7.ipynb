{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Classifier \"horse\" race\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"auto.csv\", na_values = \"?\")\n",
    "\n",
    "df.isna().sum()\n",
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\"name\"])\n",
    "\n",
    "cutoff = df[\"mpg\"].median()\n",
    "\n",
    "def mpg_trans(col):\n",
    "    mpg = col\n",
    "    if mpg >= cutoff:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df[\"mpg_high\"] = df[\"mpg\"].apply(mpg_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "df[\"horsepower\"] = df[\"horsepower\"].astype(\"int\")\n",
    "df[\"mpg_high\"] = df[\"mpg_high\"].astype(\"category\")\n",
    "Xvars = df[[\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"year\", \"origin\"]].values\n",
    "yvals = df[[\"mpg_high\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k index = 0\n",
      "MSE for test set 0 is 0.49625156184922947\n",
      "\n",
      "Error rate for category 0 in test set 0 is 0.057692307692307696\n",
      "Error rate for category 1 in test set 0 is 0.13043478260869565\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9423    0.8909    0.9159        55\n",
      "          1     0.8696    0.9302    0.8989        43\n",
      "\n",
      "avg / total     0.9104    0.9082    0.9084        98\n",
      "\n",
      "k index = 1\n",
      "MSE for test set 1 is 0.5\n",
      "\n",
      "Error rate for category 0 in test set 1 is 0.12244897959183673\n",
      "Error rate for category 1 in test set 1 is 0.08163265306122448\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8776    0.9149    0.8958        47\n",
      "          1     0.9184    0.8824    0.9000        51\n",
      "\n",
      "avg / total     0.8988    0.8980    0.8980        98\n",
      "\n",
      "k index = 2\n",
      "MSE for test set 2 is 0.4975010412328197\n",
      "\n",
      "Error rate for category 0 in test set 2 is 0.15217391304347827\n",
      "Error rate for category 1 in test set 2 is 0.11538461538461539\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8478    0.8667    0.8571        45\n",
      "          1     0.8846    0.8679    0.8762        53\n",
      "\n",
      "avg / total     0.8677    0.8673    0.8674        98\n",
      "\n",
      "k index = 3\n",
      "MSE for test set 3 is 0.5\n",
      "\n",
      "Error rate for category 0 in test set 3 is 0.046511627906976744\n",
      "Error rate for category 1 in test set 3 is 0.14545454545454545\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9535    0.8367    0.8913        49\n",
      "          1     0.8545    0.9592    0.9038        49\n",
      "\n",
      "avg / total     0.9040    0.8980    0.8976        98\n",
      "\n",
      "Average MSE k-fold = 0.4984381507705123\n",
      "Average MSE standard err = 0.0016231213315410148\n",
      "Average error rate for category 0 = 0.09470670705864986\n",
      "Average error rate for category 0 standard err = 0.044059462275132855\n",
      "Average error rate for category 1 = 0.11822664912727025\n",
      "Average error rate for category 1 standard err = 0.023651609698841367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\liaoa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "k = 4\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 15)\n",
    "kf.get_n_splits(Xvars)\n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "error_rate_0 = np.zeros(k)\n",
    "error_rate_1 = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    \n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    \n",
    "    LogReg = LogisticRegression(fit_intercept = True)\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    \n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred) ** 2).mean()\n",
    "    \n",
    "    y_test.shape = (len(y_test), )\n",
    "    temp = pd.DataFrame({\"y_test\": list(y_test), \"y_pred\": list(y_pred)})\n",
    "    error_0 = temp[(temp[\"y_pred\"] == 0) & (temp[\"y_pred\"] != temp[\"y_test\"])]\n",
    "    error_1 = temp[(temp[\"y_pred\"] == 1) & (temp[\"y_pred\"] != temp[\"y_test\"])]\n",
    "    \n",
    "    error_rate_0[k_ind] = len(error_0)/len(temp[(temp[\"y_pred\"] == 0)])\n",
    "    error_rate_1[k_ind] = len(error_1)/len(temp[(temp[\"y_pred\"] == 1)])\n",
    "    \n",
    "    print(\"k index =\", k_ind)\n",
    "    print(\"MSE for test set\", k_ind, \"is\", MSE_vec_kf[k_ind])\n",
    "    print(\"\")\n",
    "    print(\"Error rate for category 0 in test set\", k_ind, \"is\", error_rate_0[k_ind])\n",
    "    print(\"Error rate for category 1 in test set\", k_ind, \"is\", error_rate_1[k_ind]) \n",
    "    print(\"\")\n",
    "    print(classification_report(y_test, y_pred, digits = 4))\n",
    "    \n",
    "    k_ind += 1\n",
    "\n",
    "print(\"Average MSE k-fold =\", MSE_vec_kf.mean())\n",
    "print(\"Average MSE standard err =\", MSE_vec_kf.std())\n",
    "print(\"Average error rate for category 0 =\", error_rate_0.mean())\n",
    "print(\"Average error rate for category 0 standard err =\", error_rate_0.std())\n",
    "print(\"Average error rate for category 1 =\", error_rate_1.mean())\n",
    "print(\"Average error rate for category 1 standard err =\", error_rate_1.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=True, random_state=25, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (b)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "yvals.shape = (len(yvals), )\n",
    "RandClass = RandomForestClassifier(n_estimators = 20, max_features = 2, random_state = 25,\\\n",
    "                                   bootstrap = True, oob_score = True)\n",
    "RandClass.fit(Xvars, yvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the model is 0.07142857142857142\n",
      "The error rate for category 0 is 0.05789473684210526\n",
      "The error rate for category 1 is 0.08415841584158416\n"
     ]
    }
   ],
   "source": [
    "oob_prediction = RandClass.oob_decision_function_.T[1]\n",
    "MSE_RandClass = pd.DataFrame({\"pred\": oob_prediction, \"yvals\": yvals})\n",
    "MSE_RandClass[\"pred\"] = MSE_RandClass[\"pred\"].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "def calculate_MSE(df):\n",
    "    return mean_squared_error(df[\"yvals\"], df[\"pred\"])\n",
    "\n",
    "MSE = calculate_MSE(MSE_RandClass)\n",
    "\n",
    "MSE_RandClass_0 = MSE_RandClass[MSE_RandClass[\"pred\"] < 0.5]\n",
    "MSE_0 = calculate_MSE(MSE_RandClass_0)\n",
    "\n",
    "MSE_RandClass_1 = MSE_RandClass[MSE_RandClass[\"pred\"] >= 0.5]\n",
    "MSE_1 = calculate_MSE(MSE_RandClass_1)\n",
    "\n",
    "print('The MSE of the model is', MSE)\n",
    "print('The error rate for category 0 is', MSE_0)\n",
    "print('The error rate for category 1 is', MSE_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k index = 0\n",
      "MSE for test set 0 is 0.49625156184922947\n",
      "\n",
      "Error rate for category 0 in test set 0 is 0.0\n",
      "Error rate for category 1 in test set 0 is 0.5520833333333334\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     1.0000    0.0364    0.0702        55\n",
      "          1     0.4479    1.0000    0.6187        43\n",
      "\n",
      "avg / total     0.7578    0.4592    0.3109        98\n",
      "\n",
      "k index = 1\n",
      "MSE for test set 1 is 0.5\n",
      "\n",
      "Error rate for category 0 in test set 1 is 0.5204081632653061\n",
      "Error rate for category 1 in test set 1 is inf\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.4796    1.0000    0.6483        47\n",
      "          1     0.0000    0.0000    0.0000        51\n",
      "\n",
      "avg / total     0.2300    0.4796    0.3109        98\n",
      "\n",
      "k index = 2\n",
      "MSE for test set 2 is 0.4975010412328197\n",
      "\n",
      "Error rate for category 0 in test set 2 is 0.53125\n",
      "Error rate for category 1 in test set 2 is 0.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.4688    1.0000    0.6383        45\n",
      "          1     1.0000    0.0377    0.0727        53\n",
      "\n",
      "avg / total     0.7561    0.4796    0.3324        98\n",
      "\n",
      "k index = 3\n",
      "MSE for test set 3 is 0.5\n",
      "\n",
      "Error rate for category 0 in test set 3 is 0.4731182795698925\n",
      "Error rate for category 1 in test set 3 is 0.0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.5269    1.0000    0.6901        49\n",
      "          1     1.0000    0.1020    0.1852        49\n",
      "\n",
      "avg / total     0.7634    0.5510    0.4377        98\n",
      "\n",
      "Average MSE k-fold = 0.5076530612244898\n",
      "Average MSE standard err = 0.03488467941626875\n",
      "\n",
      "Average error rate for category 0 = 0.38119411070879966\n",
      "Average error rate for category 0 standard err = 0.22116528050309686\n",
      "\n",
      "Average error rate for category 1 = 0.1840277777777778\n",
      "Average error rate for category 1 standard err = 0.26025457918671546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\liaoa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# (c)\n",
    "from sklearn import svm\n",
    "\n",
    "k = 4\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 15)\n",
    "kf.get_n_splits(Xvars)\n",
    "\n",
    "MSE_vec_kf_svm = np.zeros(k)\n",
    "error_rate_0_svm = np.zeros(k)\n",
    "error_rate_1_svm = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    \n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    \n",
    "    svc = svm.SVC(kernel = \"rbf\", C = 1, gamma = 0.2)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    \n",
    "    MSE_vec_kf_svm[k_ind] = ((y_test - y_pred) ** 2).mean()\n",
    "    \n",
    "    y_test.shape = (len(y_test), )\n",
    "    temp = pd.DataFrame({\"y_test\": list(y_test), \"y_pred\": list(y_pred)})\n",
    "    \n",
    "    error_0 = temp[(temp[\"y_pred\"] == 0) & (temp[\"y_pred\"] != temp[\"y_test\"])]\n",
    "    error_1 = temp[(temp[\"y_pred\"] == 1) & (temp[\"y_pred\"] != temp[\"y_test\"])]\n",
    "        \n",
    "    try:\n",
    "        error_rate_0_svm[k_ind] = len(error_0)/len(temp[(temp[\"y_pred\"] == 0)])\n",
    "    except:\n",
    "        error_rate_0_svm[k_ind] = np.inf\n",
    "        \n",
    "    try:\n",
    "        error_rate_1_svm[k_ind] = len(error_1)/len(temp[(temp[\"y_pred\"] == 1)])\n",
    "    except:\n",
    "        error_rate_1_svm[k_ind] = np.inf\n",
    "    \n",
    "    print(\"k index =\", k_ind)\n",
    "    print(\"MSE for test set\", k_ind, \"is\", MSE_vec_kf[k_ind])\n",
    "    print(\"\")\n",
    "    print(\"Error rate for category 0 in test set\", k_ind, \"is\", error_rate_0_svm[k_ind])\n",
    "    print(\"Error rate for category 1 in test set\", k_ind, \"is\", error_rate_1_svm[k_ind]) \n",
    "    print(\"\")\n",
    "    print(classification_report(y_test, y_pred, digits = 4))\n",
    "    \n",
    "    k_ind += 1\n",
    "\n",
    "print(\"Average MSE k-fold =\", MSE_vec_kf_svm.mean())\n",
    "print(\"Average MSE standard err =\", MSE_vec_kf_svm.std())\n",
    "print(\"\")\n",
    "\n",
    "print(\"Average error rate for category 0 =\", error_rate_0_svm.mean())\n",
    "print(\"Average error rate for category 0 standard err =\", error_rate_0_svm.std())\n",
    "print(\"\")\n",
    "\n",
    "error_rate_1_svm = error_rate_1_svm[ error_rate_1_svm < 1]\n",
    "print(\"Average error rate for category 1 =\", error_rate_1_svm.mean())\n",
    "print(\"Average error rate for category 1 standard err =\", error_rate_1_svm.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: MSE mean: 0.4984381507705123\n",
      "LogisticRegression: error rate mean for category 0: 0.09470670705864986\n",
      "LogisticRegression: error rate mean for category 1: 0.11822664912727025\n",
      "\n",
      "RandomForest: MSE mean: 0.07142857142857142\n",
      "RandomForest: error rate mean for category 0: 0.05789473684210526\n",
      "RandomForest: error rate mean for category 1: 0.08415841584158416\n",
      "\n",
      "SupportVectorMachines: MSE mean: 0.5076530612244898\n",
      "SupportVectorMachines: error rate mean for category 0: 0.38119411070879966\n",
      "SupportVectorMachines: error rate mean for category 1: 0.1840277777777778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (d)\n",
    "print(\"LogisticRegression:\", \"MSE mean:\",  MSE_vec_kf.mean())\n",
    "print(\"LogisticRegression:\", \"error rate mean for category 0:\",  error_rate_0.mean())\n",
    "print(\"LogisticRegression:\", \"error rate mean for category 1:\",  error_rate_1.mean())\n",
    "print(\"\")\n",
    "\n",
    "print(\"RandomForest:\", \"MSE mean:\",  MSE)\n",
    "print(\"RandomForest:\", \"error rate mean for category 0:\",  MSE_0)\n",
    "print(\"RandomForest:\", \"error rate mean for category 1:\",  MSE_1)\n",
    "print(\"\")\n",
    "\n",
    "print(\"SupportVectorMachines:\", \"MSE mean:\",  MSE_vec_kf_svm.mean())\n",
    "print(\"SupportVectorMachines:\", \"error rate mean for category 0:\",  error_rate_0_svm.mean())\n",
    "print(\"SupportVectorMachines:\", \"error rate mean for category 1:\",  error_rate_1_svm.mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the comparison above, the random forest model has the best result, including the the lowest MSE, the lowest error rate for category 0 as well as the lowest error rate for category 1. The second best model is logistic regression model, and the support vector machines model is the worst model.\n",
    "\n",
    "Based on the calculation above, I think that the random forest model is the best predictor of mpg_high, although we should keep in mind that the random forest model is the only one which doesn't use k-fold cross validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
