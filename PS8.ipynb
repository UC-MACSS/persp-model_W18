{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.(a)\n",
    "import pandas as pd\n",
    "drink = pd.read_csv(\"strongdrink.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_palette(sns.color_palette(\"deep\"))\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAH7CAYAAABhfo2fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzs3XuAlFd9//H3zrJLIAtkgeGSLEuW2yEhV0iAjZpEjUlN1cRLq21Na6xW01qNplW8/bT2klirtWqN1npNbbVqTFKrJtYYcuMWSCSQcCAsYVnCwrIQlg0bFnb398fMkNnZuTwz89zn8/oHduaZ5znneWb3+T7nfM85dSMjI4iIiIi4LRF0AURERCSeFGSIiIiIJxRkiIiIiCcUZIiIiIgnFGSIiIiIJxRkiIiIiCcUZEjZjDErjTG/McZsNsZsMcb8whizpIr9XWqM+VrWz/cZY6a7U1owxnzaGPMVB9vlPa7Tz+f53DeMMcvK/ZzfjDEjlZ5vY8wDxpi3lPmZis6nw32/xRjzgEv7+o4x5q+q3McTxpgzSmzzu8aYz1RznFLHN8ZMMcbc78UxRIpRkCFlMcaMB34G3GKtvcBaex7wfeAXxpj6Cne7BGjJ+vk1VRazUm4f9zVAncv7lAix1l5krX2+xGaXAlM9Pn4zsNyLY4gUMy7oAkjkTATOAJqyXvs+0AfUA0PGmHcCtwBDwEHgT4C9wD8DK4FJpG6+7wI6gc8AU4wx387a52+MMdcCw8BXgFagAfiBtfYfjDFnAw8BTwNnp4/xA+CXwIr0/t9nrX0ou/DpFpevANOAEeDz1trvZR37N8aYa621e3LqfY4x5kFSN4PHgT+31h41xpxVoHx/D5wJfN8Y8y3gddbaV6TLYNPbfcoY0wKsJxVkrQQ+C5yePnd/Y639Wfozfwr8OakHg9503bYZY76TPvfnA3OAzcAfW2v7c+q9CPjX9LmfDTwBvNVa+2LOdh9Nn8uTwA7gHdbaI8aYTwJ/kH59e/r43emPXWeM+WtgFvB/wLuttcPGmOuBT6XLfBT4kLV2PQUYY2YCXwdmpve1G/h9a+0BY8yzwHeAV6fP9festZ9Mf+4zwB+lz8uOIvsf87201u4xxvwZ8P706/vTddue89lXAJ8j9f0fBD5hrf2lMeYdwJ+SumZHrLWvzPncCJAEXge8kdT3eSFwLH2eJwPvBeqNMUestR+v5FobY/4mvf/B9GfeYa3dl3X8bwMTjDFPpOvx59bal6XL2AqsBc621g4WOn8ilVBLhpTFWnsY+DDwS2NMhzHmDuBG4P+stYPGmAtJ3Sh/x1p7AXAP8HFSN/4zgXZr7bnAd4FV6Zv5/wMestbeaK29MX2oV6bfuwP4lrV2GaknsauMMb+f3qYF+Ftr7SJgH6mbz2pr7UXAKuCHxpiGTNmNMePS5flyumyvBf7BGNOe57i5FgBvJvUHvg74RPr1vOWz1n4ceI7Uze9LwAXpZuuzSd1YMq0mbwDuAqaQuhHcYK1dClwH3G6MaTXGXEHqhvQKa+3FwD8CP80q2zLgd4BzSAVcv5en/O8GvmutXZmuSxvwu9kbGGPeALyD1DU6D9gFvM8Yc2P6XF2aPm9bSN3wMyYBl6WP/1rgZcaYxcDXgDdbay8kdY3vNsZMzlO2jLcBa6y17cA8UjfiG7Leb0oHapcBf2WMaTPGXEfqulyUfn1Kvh0X+l4aY15F6vv8ynQ5/xO4yxhTl/XZacCPgQ+kP/snwH8YY9rSmywBrswNMPK4AvjL9LldR+r7vy59nn6YDjDKvtbGmDnAzaSuzyXAfaR+37LdCAykfzd+BCzI6uJ8F6nvhgIMcZ2CDCmbtfYLpJ4230/q5v4R4HFjzBRST5r3Zm7U1tovWmvfa61dQ+rG/B5jzD8Bb2F0a8gYxpjTSf1h/tv0E9haUoHERelNTgJrsj5y2Fr7n+nj/oLUk+kFWe8vAk6z1t6Z3uY54Cek/miXcqe1tsdaO0IqGHiNg/JlztcAqSf815C6CX8daEufr+vSZWgn1cJwV3pfPyfV0nIBqWBgAfBo+r1/BJqNMZkm9l9aa49ba08AT5K/6f0jQI8x5sPA7aQCvtzzfxXwo3QgibX2Q9bav0+X+dvW2hfS2/0L8GpjTGP65x9aa4estcdItSTMAF4F/Npa25He1/3AAVI3ybystf+SruOHgK8C5+WU8e70dnvT+5qaLvOd1tqj1tqTwLcK7D7v95LUtf+htbYn/fp3gLNI3cAzVgDPpAMCrLVbgUeAK9Pvb7bW9hWqV5aN1tqu9P83kf86VXKt9wK/BTalf7eesNbeVagQ6WDi34F3pbs43wH8m4Pyi5RN3SVSFmPMy4DLrLWfI5Wb8TNjzMdIPd2+htSNfyRr+wnAXGA+qZvT50ndLLYBby9xuHpSrQaXpW9gpBMUXwSmA8fTN5aMkzmfT5AKNLL3l7tYT4JUN0cp2ftJACdKlC/XT4FrSXU1/SOwGLie1I30gfR7T1trTz2BGmPOBHqAVwJ3WGs/kn49QSpIOJzedCDrOCPkzwP5L1K/7/8N/C+pYCh3u9xrd0a6vLnnLZHeV+bzJ/Icv+xzbYz5LKnWoG8Bv0lvm13GQvXM3ib3O5D9er7vZT2pLoZsdTnlLFaXQaAfZ5xcp3rKvNbprqkrgEtIBV3/bIz5pbX2w0XK8jVgA7Aa2GKt3eWwDiJlUUuGlKsH+IQx5uVZr80m1Uz9JKmbw1XGmNnp995D6qb6GuB/rLW3A4+RusFmEkVPMvqP+hDQkH46XAt8CE7d9B4h9fSfT9IY8zvpbV9P6ub3ZNb724ATxpg3pbc5k1RT+6+yj1tg328wxjSnn/zeDfzCQfmy6/U/pJ6mLyKVg3Ef8Lfp/Qyl97PQGHN5el8XkWoVOAu4F/iDrHP6XuDXBcpZyDXAZ6y1P0z/vIKXzn/G/wFvyurS+HS6br8E3pluuYFUC9aD1trjRY73a+AaY8y8dH1eRSqPYF2JMn7RWnsHqZaK1+QpY65fkOoyOCN9Q76hwHaFvpe/BN5mjEmmy3kjqZyGZ7I+uwZYbIxZnt5mCXA5qeDQDdnfk7KvdboraAupIPVWUrlPl+Y5Rn2mGyjdorMmve3tblRCJB8FGVKWdELc9aRyGTqMMU+Rejq+0aY8Cfw1qZyN35Jqjn4vqSenK40xT5JqKt5JqssgQeoGO88Yc2f6MD8CVhtjzgP+EFiZ/tw64L+std8vULwXgRvSx/04cH36Bp4p+4l02T9gjNlM6qb6GWvtb/IcN9dTpFpungSeB25Lv16sfHeS6ru/2lp7hFSS6uPpMt1L6qb7k3TZekgFPJ9Ll/8OUvkZz1pr7yOVT/CrdLn/EHhTuuvGqY8BP02X8+uknmAXZG9grf05qa6gR9LbzUqfx2+mz9V6Y8zTwFJSuSYFWWufIpW8eKcxZkv6fL0+fR4K+QzwT+k63gM8nFvGPMf5OamWj8dInf+8+y/0vbTW/orUjfZ+Y8xWUvkQr7PWDmd99iCpPJcvp8/Lf5L6vm/PPU6F7icVkH25kmttrf0tqd/Bx4wxjwHvJB34ZtlHKrjdms4xgdS1rifVNSfiiTot9S5xkE6o3GKtLZrnISKnumG+Auy21n426PJIfKklQ0SkhhhjJpHqEmolNfJJxDNqyRARERFPqCVDREREPKEgQ0RERDyhIENEREQ8EerJuHp6jrqaMNLcPJHDh4+5ucvAqU7REcd6qU7REcd61UKdkslJkV5ksaZaMsaNq3SR0PBSnaIjjvVSnaIjjvVSncKvpoIMERER8Y+CDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwREfFdIlEXdBHEB+OCLoCIiNSOoc4O+tasoX+7pWmRYXJ7O/Wt84IulnhEQYaIiPhiqLODXbfdxvDgIAADuzvpXb2atlWrFGjElLpLRETEF31r154KMDKGBwfpW7c2oBKJ1xRkiIiI5xKJOvrttrzv9VurHI2YUpAhIiKeGx4eoWmRyftekzEMD4/4XCLxg4IMERHxxeT2dhKNjaNeSzQ2MnnFyoBKJF5T4qeIiPiivnUebatW0bduLf3W0mQMk1esVNJnjCnIEBER39S3zqO5dR7TEnXqIqkB6i4RERHfKcCoDQoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBPjvNy5MWYF8Flr7ZXGmIuALwNDwHHgj621+708voiIiATHs5YMY8yHgX8HTku/9C/AX1prrwTuBD7i1bFFREQkeF52l+wE3pT189ustU+k/z8OeNHDY4uIiEjA6kZGRjzbuTHmbOAH1tqVWa9dBnwTuNxa21Ps8ydPDo2MG1fvWflERERCri7oAlTD05yMXMaYtwIfB363VIABcPjwMVePn0xOoqfnqKv7DJrqFB1xrJfqFB1xrFct1CmZnBRgaarnW5BhjHk78B7gSmvtIb+OKyIiIsHwZQirMaYe+BIwCbjTGPOAMeZv/Di2iIiIBMPTlgxr7bNAJh9jqpfHEhERkXDRZFwiIkAiEen8OpFQ8jXxU0QkbIY6O+hbs4b+7ZamRYbGV10ByZagiyUSCwoyRKRmDXV2sOu22xgeHARgYHcnvatX07ZqFfWt8wIunUj0qbtERGpW39q1pwKMjOHBQfrWrQ2oRCLxoiBDRGpSIlFHv92W971+a5WjIeICBRkiUpOGh0doWmTyvtdkDMPD3s2GLFIrFGSISM2a3N5OorFx1GuJxkYmr1hZ4BMiUg4lfopIzapvnUfbqlX0rVtLv7U0GcPMKy9nUKNLRFyhIENEalp96zyaW+cxLVHH8PAIU2K4HoZIUNRdIiICysEQ8YCCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggwRERHxhIIMERER8YSCDBEREfGEggyRGpBI1AVdBBGpQeOCLoCIeGeos4O+NWvo325pWmSY3N5Ofeu8oIslIjVCQYZITA11drDrttsYHhwEYGB3J72rV9O2apUCDRHxhbpLRGKqb+3aUwFGxvDgIH3r1gZUIhGpNQoyRGIokaij327L+16/tcrREBFfKMgQiaHh4RGaFpm87zUZw/DwiM8lCicFWyLeUk6GSExNbm+nd/XqUV0micZGJq9YGWCpwkEJsSL+UJAhElP1rfNoW7WKvnVr6beWJmOYvGJlzd9MlRAr4h8FGSIxVt86j+bWeUxL1KmLJK1YQmyzggwRVyknQ6QGKMBIUUKsiL8UZIhIqLl541dCrIi/1F0iIqHkVXKmEmJF/KMgQ0RCx8vkTCXEivhHQYaIhI7XyZlKiBXxh3IyRCRU/EzOVIAh4i0FGSISKkrOFIkPBRkiEjqT29tJNDaOek3JmSLRo5wMEQkdJWeKxIOCDBEJJSVnikSfuktEakzUZrVUgCESXWrJEKkRWnlURPymIEOkBsRp5dGEuk9EIkNBhkgNiMPKo2qJEYkeBRkiMVdqcqsoJFbGqSVGpJYo8VMk5uIwuVWxlhgRCS8FGSI1IMqTW/k5zbiIuEvdJSI1IMqTW2VaYgZ2d455LyotMSK1SkGGSI2I8uRWk9vb6V29elSXSVRaYkRqmYIMkRoTtQADot0SI1LLPA0yjDErgM9aa680xiwAvgOMAFuAv7DWDnt5fBGJjyi3xIjUKs8SP40xHwb+HTgt/dIXgE9Ya18B1AHXeXVsEYkvBRgi0eHl6JKdwJuyfl4GrE7//xfAVR4eW6TmadSFiATNs+4Sa+1PjDFnZ71UZ63NPIIcBaaU2kdz80TGjat3tVzJ5CRX9xcGqlN0+FGvI089zcHVD3Lk6W1MOWcx06+4nCnnnuPZ8eJ4reJYJ4hnvVSncPMz8TM7/2IS8HypDxw+fMzVAiSTk+jpOerqPoOmOkWHH/XKNzPmgfsf8GxmzDheqzjWCeJZr1qoU9QDDj8n43rcGHNl+v+vBR7y8dgiNUEzY4pImPjZknEL8A1jTCPwNPBjH48tEntxWKNEROLF0yDDWvsssDL9/+3AFV4eT6SWaWZMEQkbrV0iEiNRXqNEROJHM36KxIhmxhQvJdTlJmVSkCESM5oZU9w21NlB35o19G+3NC0yTG5vV+AqjijIEIkpBRjihnzDontXr/ZsWLTEi3IyRESkIA2LlmooyBARkbxKDYvW1PVSioIMEZEQCOMNOzMsOh8NixYnlJMhIhKgsCdVTm5vp3f16lFdJhoWLU4pyBARCUgUkio1LFqqoSBDRCQgxZIqm0N0E9ewaKmUcjJERAIQxaRKBRhSLgUZIiIBUFKl1AIFGSLiqTA+kYeF1pqRuFNOhoh4IuyjJsJASZUSdwoyRMR1URg1ERZKqpQ4U3eJiLiu3Kmo1aWipEqJJ7VkiIirSo2ayH5iV5eKSLwpyBARV2VGTQzs7hzzXvaoCXWpiMSfuktExHVORk1odU+R+FNLhoi4rtSoiXK6VCRYCV0LqYKCDBHxRLFRE067VCQ4ypcRNyjIEBFPFQoYtLpneClfRtyiIENEAqGJqMIrKgu3SfgpyBCRwGgiqvBRvoy4SaNLRCRwummFhxZuEzcpyBARCTm/Z0TVwm3iFnWXiIiEVFAjPJQvI25RkCEiEkJBj/BQvoy4Qd0lIiIhFJYZURVgSDUUZIiIhEypER6FcjS0mq2EjbpLRERCptwZUTsP9LNmazfbdj/P4rln0L5kFq0zmvwqrkhBCjJERELI6YyonQf6ufWOjRw/MQTA7u4+Hti0l4/esEyBhgROQYaISAg5HeGxZmv3qQAj4/iJIdZs3a8gQwKnIENEJKRKjfBIJOrYtvv5vJ+1nYe1gqoETomfIiIhVyhQGB4eYfHcM/K+Z1qbFWBI4BRkiIhEWPuSWYxvqB/12viGetqXzAyoRCIvUXeJiEiEtc5o4qM3LGPN1v3YzsOY1mbal8z0PB9DXTHihIIMEZEyhe0G2zqjidYZTb6US8NlpRwKMkREHApqLRGn/AgwNFxWyqEgQ0TEgaDXEgkDDZeVcinIEBHhpVaKPQVaKYqtJdJcA0GGhstKJRRkiEjNK9VKUWotkVpYqTQzXHZ3d9+Y9zRcVgrREFYRqXmlVjzNrCWST761ROJKw2WlXGrJEJGaUKg532krhdO1ROIsqOGyEl0KMkQk1kqNCHG64qnTtUTizs/hshJ9CjJEJLacjghx2kpRai2RWlLr9RdnFGSISOQVeqp2OiIku5XiBWs5vUQrhW6wIs4oyBCRyCrWFVLuiJBMK8Wi5CR6eo76Un6RuFOQISKRVKorxGmuhYh4R0NYRSSSSg07hVSuRaKxcdQ2tTYiRCRIaskQkchx2hWiESEiwVKQISKRU05XiEaEiARH3SUiEknldoUowBDxn1oypKZpQqHoUleISPgpyJCaVGoWSIkGdYWIhJuCDKk5TmeBlOhQgCESTsrJkJrjZOijiIhUT0GG1JRSQx8TiTqfSyQiEl8KMqSmZIY+5qNZIEVE3KUgQ2qOZoEUEfGHEj+l5mjoo4iIP3wNMowxDcB3gbOBIeDd1hboIBfxkIY+ioh4z+/ukmuBcdbay4DPAH/v8/FFRlGAISLiHb+DjO3AOGNMApgMnPD5+CISQhrVIxJPdSMj/j3JGWPmAHcDTcB04HXW2kcLbX/y5NDIuHH1fhVPRHx25KmnObj6QY48vY0p5yxm+hWXM+Xcc4IulkiYRDoC9zvI+AJw3Fr70XTAcT9wvrX2xXzb9/QcdbVwyeQkenqOurnLwKlO0RHHelVTp9yZVyE1yifomVfjeJ0gnvWqhTolk5MiHWT43V1yGDiS/v8hoAFQU4VIDdLMqyLx53eQ8c/AUmPMQ6RaMT5mrX3B5zKISMA086pk0/WOL1+HsFpr+4Hf9/OYIhI+mZlXB3Z3jnlPM6/Wjs4D/azZ2s223c+zeO4ZtC+ZReuMpqCLJS7SZFwiEojJ7e30rl49JidDM6/Whs4D/dx6x0aOnxgCYHd3Hw9s2stHb1imQCNGFGSISCBqcebVhCZ/O2XN1u5TAUbG8RNDrNm6X0FGjCjIEJHA1MrMq0OdHfStWUP/dkvTIsPk9vZYB1OlJBJ1bNv9fN73bOdhBWMxoiBDRAL/ox7nG0ruUN2B3Z30rl4d+FDdIA0Pj7B47hns7u4b855pbY7196HWKMgQqWF6wvZesaG6zTV8rtuXzOKBTXtHdZmMb6infcnMAEslblOQIRISfrcm6Anbe6WG6sa9m6iY1hlNfPSGZazZuh/beRjT2kz7kpnKx4gZR0GGMeaj1tpbc177B2vtx7wplkjtCKo1QU/Y3tNQ3eJaZzTROqMp8O468U7RIMMYcxswA3iDMWZh1lsNwApAQYZIFYJqTdATtn80VLc0fde8Z4z5NLANuA+43Fp7lzHmi8BnrLWHvDpuqZaMnwDnAq8GVme9fpLUUu0ikqOcp7KgWhP0hO2fWhyqWwm1ZvjmAuB3gLustTd7fbCiQYa1dgOwwRhzl7X2SLFtRWpdud0eQbcm6AnbP7UyVLcSmvWzesaYScB/kOp5eBFIAldZa7uNMd8Bvpa1+YeAS4wx9wIfAG4AfgZcbK0dNsb8DPhL4PeAq4EpwD3W2r81xjwAHAD6rLXvclI2p4mf1xtjPg80p3+uA0astVrcTITKuj2Cbk3QE7b/FGCMplk/XXMj8LC19nPGmDcCxVoovgC8zVr7U2PMB4ATwIPAlcaYzcBEoBPAWnuVMWY8sBX42/Tnv2qtfcBpwZwGGf8PuNJau8XpjkVqSaXdHkG3JugJW4KkWT9dY4D/BsgKHjKcrD73XeC9wDnAfwHDwERjzPeAfqAxa9vt5RTM6SqszynAEMmvmhVFM60JyWuuZsLZc0lec3UgQ0gVYIjfnMz6KY51AEsBjDFvBS4HZhpj6oHzcrYdIefeb619DFgEXA/8CLgQWGGt/WPgH4HsiG+4nII5bcnYaIz5Mams1BezCva9cg4mEkfVdnuoNUFqkWb9dNXXge8ZY64DjgPvAL5PqtvjuZxtO4CXG2PelvP6/wLLrLXPG2N2AKcbY9YBfcD+dN5H2ZwGGVOAo0B71msjgIIMEdzp9tAfVak1mvXTHdbafuBNOS/n3p/XZv3/3PS/P8jax2ez/v8CqdaQXFeWWzZHQYa19sZydyxSS5REGX5eD5HUEMzyadbP+Cs1GdfPrLWvM8bsItVyMYq1Vn9BRdLU7RFOXs+oqiGY1dGsn/FWqiXj3el/ryy0gTFmqbV2k2slEok4/aEMD69nVNUQTPfo9yaeSk3GtS/97+4im/076axWEZEw8XpGVb+HYOppX6LGjVVYNc5IRE4Jy43Q6xlVnQzBdOs8qEtGosqNICP4vyYiEriw3Qi9nlHVryGY6pKRKHM6GZeISEGZG+G96zrZ3d3Hves6ufWOjXQe6A+0XJPb20k0No56zc0ZVduXzGJ8w+jVFdweglmsS0akhInA/PS/rjDGrEivYeKIGy0ZIlLjnOYm+N2V4vXQYq+HYPrZJSOxMu7nj+763G939Fzftb9/TsvMpj0XLkzede1lbX9NahX1ihhjPkxqQbUXHBfE4Y7rrbVDBd5WToZIDXNyIzzx7E5Ph5EW4/XQYi+HYGpWTKnEzx/d9blv3bP15kzg37n/6Nkbnz5wM8C1l7V9sIpd7yQ16dcdTj/gtLtkQ5H33uz0YCISP5kbYT6mtZkTz+5k12230fOrXzGwu5OeX/2KXbfdxlBnh+/ljNL+M2t3+NElI7EycfOOg9fna1ncvOPgdVTRdWKt/QmpVVsdc9pd0m2MeQWw3lp7POeg/v6lEJHQKTQ99GXnzaTvN/d4Oow0bvIl0GpWTCnD7D37j87J98aeA0fnALNJtUj4wmmQcSmwGsAYk3ltxFpbX/ATIlIzCuUmzJ05id0eDiONm2IjSd76yvnKwRAn9rXMbNrTuf/o2blvzJkxaQ+wz8/COF27JOl1QUQk2vLlJng9jDRuSiXQ6nyJA8cuXJi8a+PTB27ObVm8YOH0u4FjfhbGaeLnROBTwKvTn7kf+GR6pTYRkVNyb4RurFBbCzSSRNySHkXC5h0Hr9tz4OicOTMm7blg4fS7M69Xw1r7LOD4l9dpd8lXSEU/7yQ1muTdwNdIDWURESkojivUaiSJhNzJay9r++C1l7V9nFQOxj58bsHIcBpkLLPWXpj18/uMMU95USARiZ+4rFDr9aymhRJoNZJEKnQMH5M883EaZCSMMWdYa58HMMacQRUTeohIbYp6gOH19N5eT+4l4jenQcYXgA3GmHtIdZe8HrjVs1KJiISMWyuulupq8XJyLxG/OR1d8m1jzAbgClITeL3JWvukpyUTEQkJN5Iyy+1qUYAhcVA0yDDG/HHOS0fT/15sjLnYWvs9b4olIhIe1SZlxnUlVbW2SCmlWjJeWeS9EUBBhojUhGqSMt3qagkLrxNgxTUTcWl0iTGmAfgWcDYwHvg7a+09pT5XNMiw1t6YcwCT/swWa60SP0WkZlSalBm3+S/i2ioTM+Pue+bBzz25f9v1e/u655w1edae82cuvuvqBZdXswrr24Fea+0NxphpwONAdUFGhjFmGfAToJdUTsZMY8wbrbXrKiysiEjkVJKUGbf5L+LWKhNH9z3z4Oe+98SPbx4cSq1l1tW37+zH9225GeDqBZdXugrrj4BSrC9YAAAgAElEQVQfZ/3sKFhxugrrl4C3WmuXWWsvJrXU65fLK5+ISDyUGxjEZSVVJ60yEriJW/bb6zMBRsbg0Am27LcVr8Jqre231h41xkwiFWx8wsnnnA5hbcputbDWrjXGnFZBOUVEak52V0vHc0e4aGGS89qamZMs/eQfpu6UuLXKxNTsrr59eVdh3Zt6veJVWI0xc4CfAl+11v6nk884bck4ZIy5LutA15PqOhEREQdaZzTxlvl1vLfhac679xs03X83Q50dBbfvPNDPD3/zDJ/61gZ++Jtn6DzQ72NpC4tLq0yM7Ttr8qw9+d44a/LsildhNcbMBO4DPmKt/ZbTzzltyfgz4GfGmG+SmoxrBLis7FKKiNSooc4Odt1226mF4gZ2d9K7ejVtq1aNWcclzMmVmpU09I6dP3PxXY/v23JzdpdJY30D58001azC+jGgGfikMeaT6ddea60dKPYhp0HGa9MFWwrMB34IXAlsr6ioIiI1pm/t2lEr0QIMDw7St24tzTlBRtiTKzUrabilR5GwZb+9bm/fvjlnTZ6957yZ5u7M65Ww1n4A+EC5nyunJWO5tfYYsDk92mQd8G/lHlBEpNYkEnX022153+u3dtTCcVEa8hqWcsgYJ69ecPkHr15weeCrsDrNyWgAskPwQVJdJiIiUsLw8AhNi0ze95qMGXWzziRX5qPkSilTZhXWQAIMcB5k3AXcb4x5nzHmL0glf9ztXbFEROJlcns7icbGUa8lGhuZvGLlmG2VXClx4XSBtI8YY95CaoG0E8CXrLV3eVoyEZEYqW+dR9uqVfStW0u/tTQZw+QVK8ckfYKSKyU+nOZkYK39MaNn+xIRkTLUt86juXXeqByMQqKUXBmFMkowHAcZIiLijnJuyGG+eWuhNClFQYaIiJQtzHN5yCmurcIKYIypB75BarHUIeBGa23R2UMVZIiIBCyK3Q1hn8ujxo3b94t7P3fkt5uvH9i7d86Es87aM+XCC+6a/dprqlmFFeD1ANbalxljrgS+AFxX7AMKMkREHHI7GIhqd0OU5vKoRft+ce/nnv3Wd27OTP52rHPP2Yc3broZYPZrr6l0FVastXcZY36W/nEusL/UZxRkiIiU4EUwEOXuBi2UFmoTj2x+8vp8s8se2fzkdbNfe83HqaLrxFp70hjzXeCNwFtKbe90ngwRkZqUCQbuXdfJ7u4+7l3Xya13bKx6wbJi3Q1Bcrpce7lzeWgZeN/MHujqyrsKa/r12dUewFr7J8Ai4BvGmNOLbauWDBGRIrzIPQhjd0O5rTVO5/KIapdQhO2bcNZZe4517jk7940JLS0Vr8IKYIy5AWix1t5KqjVkmFQCaEEKMkRECvAqGAhbd0OlXTel5vKIcpdQhB2bcuEFdx3euOnm7C6TRGMjUy44v5pVWAHuBL5tjHmQ1HIjN1trXyz2AQUZIiIFeBkMtC+ZxQOb9o5qJQlq6vBqW2sKnQeNQAlGehQJRzY/ed1AV9ecCS0te6ZccP7dmdcrZa19Afj9cj6jIENEpAivggE3pg53o1vFq9aaMHYJ1ZCTs197zQfTSZ6BrsKqIENEpIQVS2bywosn6Tk8QLJ5Aqef5s6fzkqnDnczz8Gr1pqwdQnVqMwqrIFRkCEiUsSard08+MRzjG+op3nyeLbs7OX4iSEmjG9wrcm/3ADD7TwHr1prwtQlJMFQkBFTaoqUuPPjO57d5H/8xBDdvS+1OAfV5O9FnoNXq75qNVnxPcgwxnwUeAPQCHzVWvtNv8sQZ10DXazft4kdh3exsLmN5bOX0jKhJehiibjGzyGRYWvy9zLPwatVX6O0mqy4z9cgIz3X+WXAy0gt3PJXfh4/7roGuvj8+tsZHDoBQOeRvTy0Zx23LL9JgYbEQhBDIsPU5O9H0ONVIKAAozb5PePnNcCTwE+B/wF+VnxzKcf67k2nAoyMwaETbOh+PKASibgriFkyM03+16yYy9mzJ3PNirmBzvNQ7kybIkHyu7tkOqlFVV4HtAH3GGMWW2vzhrjNzRMZN64+31sVSyYnubq/MMjUacfGXXnf33Gog+TyaNU7jtcJ4lkvP+u0rbNwV4Gb5cjdVzI5iWVLqp6N2RXJ5CQ+8552Vm/q4qldhzi3bSpXLG3h3LZpjj4bN6pTuPkdZPQC26y1g4A1xrwIJIED+TY+fNjdYb3J5CR6eo66us+gZddpYXMbnUf2jtlm4dR5kap3HK8TxLNeftdpcesZ7N6Xv6vArXK4Waehzg761qyhf7ulaZFhcns79a3zgOoSV5NNjbzl8nkkrpx/ah+lyqzvXzTk1inqAYffQcbDwAeMMV8gNUHI6aQCD3HB8tlLeWjPulFdJo31DVw66+IASyXinjDlR5Qy1NnBrttuIzO188DuTnpXr2b6+2/h3n31rs1xIRJmvgYZ1tqfGWMuB9aTygf5C2tt0cVVxLmWCS3csvwmNnQ/zvZDHSyaOo9LZ12spE+JjSgNiexbu5Z8y20ffPgRHjgyn+MnhrSWh8Se70NYrbUf9vuYtaRlQgstbS0k5mu4mMRTFIZEJhJ19Ntted9r2LuL5jPPPTXnhtbykDjze3SJ+CSsf3ylMolEXdBFCJ0wf8eHh0doWmTyvjd4ZhuH+46Pei0zx0UYhKUcEg+a8VMkxNyeXC3MT/9h4OYNdnJ7O72rV5O73PYz0xZwvPfkqG3DsJaHn5OcSe1QkCESUm5OrlZslEPQwhD4ZJ+f589ZzOnLV1Z9fupb59G2ahV969bSby1NxnDinIv5n1/1jNouDImrQUxyJrVBQYZISBWbXK2lzXmQUWiUQ9uqVYEGGmF5cs53fhL3P+DK+alvnUdz6zymJerYvf8ot/3HJpaaGbw4mFrRdUbzBC6/+KxAb+SJRB0btu2vej2UMASLEj4KMkRCKJGoY8eh/JOrbT/UUVZib6FRDn3r1tIcUJARpidnP87P8PAIj27pZuD4SR7Z/NKKrk/u7GXalAmcN7fZleOUIzvImzltIi+74EzWbNk36nvlZD2UsASLEk4KMkRCaHh4pODkaoumznMcYBQb5fBCRwfJcQlOnhyuqqyV8GIl0WxOn6qLnZ9+a5nm0tN57sJm2Su6lrqRe9FCkC/IG99QT/t5s3lk83OntiuVKxKmYFHCSUGGSEi5MblaZpTDwO7Ol15MJJi2cgXU1bHrU5/wPUfDy5VEy809yXt+0pqMce3mXmxhs5YZTezef5Q5ydE3ZS9bCAoFeS8OnmR8Qz3HTww5yhXxOliU6FOQIRJSbk2uljvKYdrKFRx+bGNgORperSRaae5JoVEgk1esrKgchRSarXRkBP7hextHPf172UJQLMjreX6A8+dPY9qUCSUnOfMyWJT4UJAhNSOKf/TcmFwte5TDCx0dUFcXeI6GF9ODV5pbkTsKZMq553D6JctdD7gys5X+38YuOruPkmyewGmN407lQWQ//XvZQlAsyDtn7lT+4NULHH3X/Fh2XqJPQYbEXpiHbzpV7R/szCiH5LgEuz71ibzbuJmDUIrb04NXm1uRPQpk2rQmzxbdOnvWJLp7jzF4cogtO3tHBRLZE3J53UJQLMgrZ99RWktGgqEgQ2ItbMM3g25NOXly2JccBCfcnB7crdwKr+s/PDzC/LMmc++6seXMfvr3uoXArSAvSmvJSDAUZEishWX45lBnBzt/vJYjT28LvDXFrxwEp9y6sYetXoU4efovtY0bgZlbQV4U1pKR4CjIkNjya3hiKWFrTck3E+XkFStpOHt+pG8SheoVtq6x7Kf/jueOcNHCJOe1NY8aXVKohQDgh795xtURJ26OoIkzBVGVUZAhseXX8MRSwtKaki07B+HE7g76Hn2U/u9+J/BWlmpl1yvMN4TswGD9U/vpe+H4mIAht4VAc1IEQ5ONVUdBhsRa0E3oYWlNKeTEsztD1criljAHGFDeENVMXTQnhf8U2FVPS71LrGWa0JPXXM2Es+eSvOZqX2+gxZb89jvRMp9irSxe0DLiKcUChnyczEkh7iv3OslYasmQ2Au6CT3o1pRCKmllqbRf2u0l66OskkmsNCeF/zTZmDsUZEjNCOoPQqY15YXH1nPkqadDk5BYTs5KNXONuLlkfRxUGjCEdU4KN2+2YbpxK7Bzh4IMER/Ut85j/rIL6e3tD9UfJyetLMVGx5C8sOQx3FqyPk4qCRjCNieFmwmRYU2uDGtgFyUKMkR8FKYAA5wN+yyWtzFrWfEgw80l6+Ok0oAhLHNSuJkQGebkynKuU9DXJKwUZIjUuGI5K6XyNkpxa8n6OKomYAj6vLk50iXso2ZKXaewtsKEhUaXiAiQ/8ZVanSME8tnL6WxvmHUa+UuWR9nQQcM5XJzpEuURs0UCjBuvWMj967rZHd3H/eu6+TWOzbSeaA/gBKGk4IMESlqcns7icbGUa+VMzoms2T9VW2voHXKWVzV9opQJn26cUML003RK5mEyHzKTYh0c19B0BDX0tRdIiJFuTFdtxtL1nslt7n7VZe2kmxqLP3BIvuIe5N5oYTIJfOmuravsCdXaoirMwoyRKSkcuYaKfbHNWx/dN1IOgxz4qITldwMW2c08RdvuYAHH9/LgcMDJJsncFrjOG6/80k+8kdLy6p32EbNOKUhrs4oyBAJgFtPOX4/LRU7VhSf5t1IOgx74mIhTq5Xse/X1o5entzZS/Pk8WzZ2XvqHFRS77CMmilXVFth/KQgQ8RH1Uxq5cV+3BLFp3k3mruj2mRe6nqVCkAy9T5+Yoju3mOj9l1NvcN4roqJaiuMnxRkiPjkyFNPu7IYWdiWjodoPs270dwd1SbzUgmLpQLGqNbbC1FthfGLRpeI+OTggw+5shiZW4uauTUSIkrDEHO1L5nF+Ib6Ua+V29ztxj78VOx6dTx3hDVb9zsaMRG1entNAUZ+askQ8UEiUceRp57O+145S767sXS8210tUX6qzdfc/apL55Q1uiSIJvNqnpqLXa+LFiZZ/1T+4Ze53SBu11stAfGkIEPEB8PDI0w5Z7GjxchK7cfpomb5eNXVEuUEuNzm7mRyEj09R6vah1fcChALXa/z2prpe+G444DRjXpHMWFYnFOQIeKT6VdczoH7H6h6yfdqlo4v1tXSXEWQEYcEODeCA68DDLcCxELXa06yqaKAsZoAI2oJw1IeBRkiPply7jlVT2oFlU+O5UZXSzGZp9px4xKcPDlc8X68EIemeLcDxEKtEH4GjFFMGJbyKMgQ8VE5k1q5vZ9qu1pK6RroYv2+Tew4vIuFzW0sn7008KnD49IU72WAmO9zfnT/RHX4r5RHQYZIANz641nufqrpaimma6CLz6+/ncGhEwB0HtnLQ3vWBbpGSZya4r0OEIsd1ytRThgW5zSEVaSGZLpaktdczYSz55K85mpX5tdY373pVICRMTh0gg3dj1e132rEbfGqaheqCyMNg40/tWSI1Bi3umwyEok6dhzalfe97Yc6AlkULY5N8W4sVAfhyk+JQ8KwFKcgQ6RMYfojXQ03u2wWNrfReWTvmPcWTZ0XyLmKa1N8NQHiU7t6uX9DZ+jyUzRjZrwpyBBxKIyJjWGxfPZSHtqzblSXSWN9A5fOujiwMkV57o5Syr0ZRyE/RQFGPCnIEHEgjImNfnHyhNkyoYVbVtzEhn2Ps/1QB4umzuPSWRd7dm6clElN8S/RUFEJioIMEQeKJTa2tMUzyHA6u2R2C8850xZw4wVvY0aDN60F5Q5JVVN8PPNTJDoUZIiUkEjUsb23I+97QSU2es3p7JLbep4Z08Lzm92PetLCU02Tf9yuTznimp8i0aAhrCIlDA+P0DJ5Vt73zpo8K5Z/pJ2u9Prw7g2+DV2N25BUP2moqARFLRkiJSQSdTQ1nk5jfQMAzadN4fCLRwBoapgYu+Zmp7NLJhJ1bDu4M+92brfwqMn/JZXUtXVGE595Tzv3b9hT8/kp4i8FGSIlDA+PwHAd1y58Fc8d3c9zR/dz0awlnDlpJseOvxi7m5vT2SWHh0dYPH2+L0NX1eRf/RTp57ZNI9nUWFMBmQRP3SUiDixOLuDnO+5n/d4n6Orbx/q9T/DzHfdjps8PumieqLvwkryzS9adv2zUay+fe+mpFp4Mr4au1nKTfyYf5d51nezu7uPedZ3cesdGOg/0l70vBRjiJ7VkiDjwZM/TeXMPnux5msWTFgdUKu/c113P5KvezvzeZ2h8bheDZ7bxzLQFbOoex+9nVXdxcgG3LL+JDd3eD10N85BUr1sHNARVokpBhkgJiUQdOw89m/e9nYd2k1gQr+bnRKKOp599nt3dJxnfMJ/mM8/lcN9xjvee5OzZY/MfWia00NLW4loORrEbdtiGpDod5lsN5aNIlCnIEHFgZlOSPX378rw+PYDSeCs7/+H4iSG6e4+deq9Y/kO1N7piOQe5N1I/bqqlbt5Oh/lWS/koEmUKMkRKGB4eoe2MVjbvf3rMtNltZ7TG8o+831Ny55sD48EnnuOmN53P1o5eX9fbOPLU0xy+f3XJ1oliw3ybXW7NiPMU6RJvCjJEHFgwZR6XnHkhAycH6HnhEMnTpzJh3AQWTHH3ZhIWfuc/5Ms5WLZ4Bv/6482urrfhpHXiKQetE06H+bolzPkoIsUoyBBxoGVCC1e0XMamA5thpI4ZE6ezdMYFsV63pNL8h0q2z805GN9Qz/DISN5kx4c37+MPr1roeP/gfPin09YJp8N83RS2fBQRJxRkiDjUMqGFlrktNfdH3mldK53HIV/OwcypE+nan3945vau58u6Bk6nIy+3dWJyezu9q1ePCkoSjY1MXrHSUbkqVUvfPYk+BRkiZdIf+bGqXUp8bM7BCLOmN9G5/+iYbWdPO72ssjkd/llu60R96zzaVq2ib91a+q2lyRgmr1jp+ugSkShTkCEiVat2HofcnIMlbVOZdHojv93eMybZcf5ZUxwHeuUO/6y78BISZbRO1LfOo7l1nus5GCJxoSBDRKri1jwOuTkHnQf6WbFkJi+8eJKewwMkmydw+mnjWNQyxXHZyhn+2Xmgn8/+Yj+vz5qE7MRZbUx/+ctKtk4owBDJT0GGiFTF7XkcMtu3zmjiVUtb2LDtAHWk8jQuXTyj7BEVTod/rtnazcDxk/z3dl6ahOzIca7cN463xm9SVxFfKMgQqXFuJLJ6NY+DGyMqnAz/zG2NyZ6ETLNqilROQYZIjXJzSmyv53Go9gZfKljRrJoi3lCQIVKDvJgSOwrzOBQrl2bVFHGfggyRGuTllNjlBhhhCUoyrTHrtx3gqV2HNKumiAsCCTKMMTOAjcBrrC0w+42IeMLvKbEL8WMF03K1zmhi2ZLZ9Pb2hyLwEYk634MMY0wD8HVgwO9ji3gpLE/kpQQxJXYut7prvDrnUbiOIlEQREvGPwFfAz4awLFFXNc10MX6fZvYcXgXC5vbWD57qe9rmpR7sy130im3VdtdU+kU5iLir7qREf8idmPMO4AWa+3fGWMeAN5brLvk5MmhkXHj6v0qnkjZtvU8w9+t/tKYJeA/ccX7WZxc4MvxH969gW0Hd7J4+nxePvfSksd9alcvn/7GWl4/l1GTTs165eW0rbzY8zIDbHr/B/O2pEw8ey4X/8sXin72qV29/L+vrxmToPmZ97Rzbts018sqErC6oAtQDb9bMt4JjBhjrgIuAr5njHmDtbY738aHDx9z9eDJ5CR6esauhRBlqlN1qm1uX71r3agAA2Bw6AQP7lrPNEaPSnC7Xl0DXXx+/e2njt95ZC8PPLuGW5bfVLQl5f4Nnfknneqs463zyytfpXUq1F1zujEl93f/hs68U5jfv2EPyabGssuSK46/UxDPetVCnZLJSQGWpnq+BhnW2ssz/89qycgbYIh4yY2kw0Sijh2HduV9b/uhDhLzvc3RWN+9KW+As6H7cVra8gcZYZl0qtIVTN2awtxPYSyTiF80hFXK+iMYhz+YbiUdDg+PsLC5jc4je8e8t2jqPE/PU6UBTlgmnap0BdOwlN+J7sMDPPLkc2zpOHwqb+TsWZNCVUYRrwUWZFhrrwzq2JJSTsJiGJIb3eLmHBHLZy/loT3rxuRkXDrL29yGagKcsEw6VekKpmEpfyFdA1082vUYzzz/LNMnzaZ1Xiu/WruHBzbt5ZXL5jAyMqxEVakZasmoUfn68x/asy5vf34524ad23NEtExo4ZblN7Gh+3G2H+pg0dR5XDrrYl/OS6UBjtdTgJer3Cd7L8ufSFSXY5f7u7KX52is38zLVr6Ohx4doOf5Y2zZ2csDm/by0RuWKdCQ2FOQUaPK6c+vpO8/rLyYI6JlQgstbS2e52DkO26lAY4fU4B7uW+3y5/dUrd4+nyWzbiookCx0O/KialdjG+YQc/hAZonj6e79xhrtu5XkCGxpyCjBpXTnx90cqMXKk06LCWI81BtgONFmf2cw8KtAKOSUTq5iv2uHBzcS/PkOSSbJ7BlZy8Q3kRVETcpyKhB5fTnB5nc6JVKkw7DLCzXofNAP7fesfFUvsTu7r7Qdw241VJX7HdleuNZ7B84wWmN406dm7Alqop4QUFGjSqnPz+o5EYvVZp0KMWt2dqddw6LsHYNuN1SV+h3pWXcQuoXnMaaLfuAcCWqinhJQUaNKqc/P8jkRq8pwHBPFOewcLulLu/vyuyLGTl6Bkd79tM6c1LgibYiflKQUcPK6c/3I7nxVPLdxugPk61Fu/cfpWVGUyTmsMjmdktd3t+V0+Ctr/Q20VYkjBRkSFl/9LwMMOIyTLYWZXIxLjlnJuMb6kM7h0U+ua0P50yfz9IKR5dkKzQZmkgtUZAhoRCnYbK1KJOLsWbLPtrPm82LgyfpOTxA66xJXLWsJfRdA9mtD9OmNcVuPQyRoCjIkMDFcZhsLcnOxRgeHuGRzc8xvqGe5snj2X/oWGSm0j419LbzeRa3avl4ETckgi6ASCb5Lp+oDpOtJZn1RLJlFl6bd+aUSFy/THfPves62b2vj3vXdXLrHRvpPNAfdNFEIk1BhoTC8tlLaaxvGPVa1IfJ1pL2JbMY31A/6rWw52JkKzb0VkQqp+4SCYXs5LsdhzpY6NMw2VLZ/lEeDeBn2cO2Hko5ojT0NkxlEXFCQYaERib5Lrl8kueJd6VWlY3yqrN+lT13MTE/1kPxQhSWj4/y91Fqm4IMqTmlhstGeTitH2UvtZhYGG7K5Qrz8vFR/j6KKMiQSKrmabnUcNkoDqfNnA+vy+7WYmJhE+bunih+H0UyFGRIpFTbbFxquOy4hYlIDafNPh/LZp3P9t6OvNu5VfY43/Ay3T3JpPfddU5peLdEnYKMCHGrrztqfeYZbjQbl1qr4uTJ4cisOpt7Prr7D7AkuYg9fc+N2daNsuuG5784roIstUVDWCOga6CLOzvu4dYNX+TOjnvoGugKdD9uy00gLKTYU3Q5Sg2XPTe5KO/750xfWNZxvJZ7PgaHTjB+3HjPhgJrPpNgaHi3RJlaMkLOraSvMCaPldP14eZTdKlVZZ8+uIOls8/n+NBxel44RPL0qYyvH8+2g8+weNLiyirrskLnY/3eJ3h128sYGcGTFXPdXkxMSovzKsgSfwoyQs6tPvCw9aUXC3qSnDNmey+W5M63qmwiUcf2Qx10HtlLY30DzadNYeuB7QwOnaB1ylmh6RIodD6GR4YZGYE3tr3ek7J6tZiYW6LaFViKH6sgi3hBQUaIOXl6d2s/fv/hKhb0XNw6NsgAb56ic+udffMeHDrB/hcOnnovbF0Cpc6HV2UN42JitTKPRJi+fyJOKMgIMbee3sOWPFYq6CnEr2bjqHQJBN2MHpYbXhi7AkUkRUFGSGWafd264YXpxlkq6CnGj2bjoG/e5VAzevi6AkXkJQoyQiZfs68bNzy/bpxO+8SrDXq8uqFmyh+Fm3f2uQ5rGb0Wxq5AEXmJgowQKdbs60Yin9s3zuybXLl94mFrLShU/jDeoGol/8CJsHUFishoCjJCpFSzr1t/MKvdT+5N7tzkIr7x+Pd58eRxwHmfeFhaC6LUpx+lsvolTF2BIjKagoyQiEqzb6Gb3NLZ57O2a9Op7crpE/e666OUKPXpR6msfglbq5iIvERBRkhEpdm30E3u+NBxGusbRr0XVHAU1CRfTlQzj0NUAtEghKVVTERGU5ARIk6afYOcbKjYTa7nhUM0nzbFt3klCp2HcrsTsoO7zORbh188wuDQCVfL3zXQxd2PPcG2gzsrzqOISiAaJJ0DkXBRkBEixZp9w5DsV+wmlzx9KlsPbD/1s1d94qXOQyXdCctnL2Vg6EWOnRjg4LFDnJtcxMSGCa6V3808CuUfiEiUKMgImXzNvuVOwe2lQje5l7esYNppUz3tEy91s3Y6Q2q+p93Hnvvtqf129e2jsb6BK1ouc6XcbuZRKP9ARKJEQUZIZd8IK5mC24lKul6K3eQWT1o8Kjhyu2vHyeibfC0tiboEK866mB8/c3feFhAnQUCldfEij0L5ByISFQoyQq7SKbiLqbbrpdhNbnh4xJOuHac363wtLStblnK3vTdvC0jr6XMK7veZw7vomt3F+ucqr4uXeRQKMEQk7BRkhFw1U3Dn42Z+gBuJl+Uca2FzG939B0YlZ8Lom/XYVUIXcnzoeNGWikLn99IzL+Lz66qvi/IoRKRWKciIADdvUl7Ps+Dl/s9NLuLQi4fpSSdnnjZuPE90bx1zHrJbWgBu3fDFvPvLtIDkO79NjRPpOdbrSl0ygc+mA0/w9MGdyqMQkZqhICMC3Er283qeBS/33zXQxdc33TEmOfM9S28oeB4yx8puqcgeppppAcl3fl/Wspxvb/6B47qUytlomdDCxZecQ29vv7o5RKRmKMiICDeS/byeZ8HL/RdqIXn64A4WT1pc9LPLZy/lka4NXDRrCS+ePM7BY4dYklzEOdMXntom3/l1Updy808UYIhILUkEXV8gOM0AAA8oSURBVAApT7U3qZfPWUFT48RRr7mZH7D8zKU01je4uv+SLSSJuqKfb5nQwrsv/iM27XuSJ7q30tW3j8e7t/L1TXfQNdA1atvs87t8dvG6ZPJPfv3sw3Qe2cuvn32Yz6+/fcw+RURqlVoyakT2E/eyMy9gxsTpbHjuCRY0t7mSH5DZ/87nn+U6cw09x3rpONzpSv7B8PAIy2adT3f/gTGtGU5bSJ46uL3s/IpS3VSl8k+8mp01yFlfnQh7+UTEPwoyakC+ER+N9Q383rmvY23XJkZGRmA2FQcCuft/9vkumhoncsuKm5jRMLPqsq/ft4nthzpYklzE+HHjWb/3CYZHhh23kFSTK1Kom6rUPv+v8X42dj/p6uys+bpmWk+fE5obehhmpRWRcFGQUQMKPXE/dXA7e/qeY+fh3VUNM823//7BYzzStZ43tr2+4nLnBi97+p6jsb6BV7e9jJERHLeQuJErkm8+kEL7nDbxDP73mV8zOHTCtdlZCw0NvmLuylPzgwR5Q9cS9CKSj3IyYs7JombwUjO/m/t3ki9RTKHgaGQE3tj2+rLnqnA7V6TQPsfXjx9V7krPbbZC5+LgwCEe2rMu8FyQYl1HIlK71JIRc+UsalbJMFM38iXycXs4rBdrfuTbZ10d/HrXI3nLXCmnq9+6NddJubQEvYgUoiCjBhSazCv3ibvcoMCNfIl8+9uxcRfnTFtAW/Ocirs48iUferHmR+4+7+y4h+GR4bxldiq37E4DxaBu6FqCXkQKUZBRA3KfuOc1tzI4dIK1XZtObVNuUOBWvkSh/XUe2ctlcy6hsb6hrJlOnSQfenHTy+yzmtlZi5XdSaAY5A1dU6eLSD4KMmpE7hN310AXE8dNqLjroFS+RLny7W9t1ybefM61HB44Mqac+VoqwpB8WGm3TKmy5+532sQzGF+fajmC4G/oWoJeRPJRkFFjshcSq7TrwO0++EL7Gx4ZZt3ex/nopTfD/JdWeL2z456Kl2z3QyXn1knZs/e751iq1aNl8uzQ3NC1BL2I5FKQUeMquRm43QfvdH/FnvaLLdkeZK6CE+UGbcPDI5x12lm8se2sUN7Qw1YeEQmOhrBKRdweEupkf8We9jOBSj5hTz6spuxhrpeIiFoypCJu98Fn72/HoQ4W5uzPydO+G8mHQU2JrcRJEYkjBRlSMbf74DP7Sy6fRE/P0VHvOelSqSbwCXpKbCVOikgcKciQqvn15O/kab+SwCcMo1JAiZMiEj8KMiQyynnaL+cmHZZRKRkKMEQkLpT4KZFTX5dg2oRm6uuq//p6ufaKiEitU0uGREZutwbAb3Y/WlW3hqbEFhHxjloyJDK8Wumz3OG4at0QEXFGLRkSCV6v9HnJmRcycHKAnhcOkTx9KhPGTRizTbERKEENfRURCTMFGeIKr2+yXnZrrO/exKN7HqOxvoHm06aw9cB2BodOMHHchFOJn4VGoLxn6Q081bM9sKGvIiJhpiBDquLn/BJeTFiV3UIyOHSC/S8cPPVedgtJoa6ah7vWnQpKghr6KiISVgoypGJ+zy/hxYRVTlpIinXV9LxwiObTppwKTgaHTrBm3wZ+b17hMqlrRURqha9BhjGmAfgWcDYwHvg7a+09fpZB3BPE/BJeTFhVqoWkWCCSPH0qWw9sH/XazkO7SSwYW75tPc+wumOdulZEpGb43ZLxdqDXWnuDMWYa8DigICOCsp/uM7kMh188wuDQCV9WPXVz305aSAoFIuPrx48JtGY2TR9zjLDMKioi4ie/g4wfAT/O+vmkz8c/RU3W1RkeHmFR8zzOnDSTF08e5+CxQ5ybXMRp48YzqaEpcue2VAtJy4QW3rP0Bh7b9wR7+vYxZ8qZzG+ey4+f+t9R2zXWN9B2RuuYfYRtVlERET/4GmRYa/sBjDGTSAUbnyi2fXPzRMaNq3e1DL3s5+HdG9h2cCeLp8/n5XMvZXFygavH8FsyOSmQ454/YPjX9d89dfPs6ttHY30Df7H8T6ouU1B1KmRbzzN8fdMdADSfNoWNz20mQYKls88fM/T1/FlmTPl3bMyf07HjUAfJ5eGqa7nCdq3cEMc6QTzrpTqFm++Jn8aYOcBPga9aa/+z2LaHDx9z9di97OfvVn9pVJP1A8+uiXSTdTI5dsVSv2zu3pb36fzJbsuCCYsq3m+QdSpk9a6XukoySZ5rujby5nOupe94P4zUMWPidJbOuIBpzBxT/kI5HQunzgtdXcsRxmtVrTjWCeJZr1qoU9QDDr8TP2cC9wHvs9b+2s9jAzy8e4OarF3i9eRYYVKorsMjw6zb+zgfvfTm1M9F6uvF8FsRkbDzuyXjY0Az8EljzCfTr73WWjvg9YETiTq2HdyZ97243RT9UEtrfrhR15YJLXziivfz4K71rg2/FREJO79zMj4AfMDPY2YMD4+wePr8mrgp+qWWns7dqOvi5AKmMVMBrYjUjJqajOvlcy/lgWfX1MRN0Q9eTI7llN+jg9ysqwIMEakVNRVkLE4uCOymGFdeTI5VjJ/TmOfyu64iIlFXU0EG6EbhFb8CjDBMaKXvjYiIM4mgCxAU3Siip9iEViIiEj41G2RItJQcMpuo87lEIiJSioIMiYTMMNJ8NDpIRCScFGRIZCyfvZTG+oZRr2l0kIhIeNVc4qdEV5BDZkVEpHwKMiRSNDpIRCQ61F0ikaQAQ0Qk/BRkiIiIiCcUZIiIiIgnFGSIiIiIJxRkiIiIiCcUZIiIiIgnFGSIiIiIJxRkiIiIiCc0GZeERtdAF+v3bWLHxl0sbG5j+eylms1TRCTCFGRIKHQNdPH59befWsq988heHtqzjluW36RAQ0QkotRdIqGwvnvTqQAjY3DoBBu6Hw+oRCIiUi0FGRK4RKKOHYd25X1v+6EOEok6n0skIiJuUJAhgRseHmFhc1ve9xZNnad1SkREIkpBhoTC8tlLaaxvGPVaY30Dl866OKASiYhItZT4KaHQMqGFW5bfxIbux9lxqIOFU+dx6ayLlfQpIhJhCjIkNFomtNDS1kJy+SR6eo4GXRwREamSuktERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBMKMkRERMQTCjJERETEEwoyRERExBN1IyMjQZdBREREYkgtGSIiIuIJBRkiIiLiCQUZIiIi4gkFGSIiIuIJBRkiIiLiCQUZIiIi4olxQRfATcaYFcBnrbVXZr32z4C11n4tZ9sE8FXgQuA48C5r7TM+FteRcuqUfu9x4Ej6x13W2ht9KWiZsutljLkI+DIwROpa/LG1dn/WtpG7VqXqlN4+9Ncqp07nAv8G1AG/Bf7SWjuUtW0krhOUV6/09pG6Vlmv/SGp+rTnbBuJa1VOndLvhf46wZjv31Lgf4Ad6bdvt9b+MGvbCcB/ADOAo8CfWGt7/C5zpWITZBhjPgzcALyQ/jkJfA9YBHwuz0euB06z1rYbY1YCnweu86m4jpRbJ2PMaQDZv5BhlFsv4F9I/dF4whjzHuAjwIeyPhK5a0WJOkXhWuWp0z8AH7PWPmiM+Q7wBuCnWR8J/XWC8usV0WtFOtD9U1LBU67QX6ty6xSF6wR567UU+IK19vMFPnIT8KS19tPGmLcBnwA+4H1J3RGn7pKdwJuyfm4CPg3cUWD7lwO/BLDWrgUu8bJwFSq3ThcCE40x9xlj7k//8Qij3Hq9zVr7RPr/44AXc7aP4rUqVacoXKvcOr05fSNuBGYB+3O2j8J1gvLrFblrZYyZBtwG3Fxg+yhcq3LrFIXrBGO/f8uA3zXGPGiM+aYxZlLO9qeuFfAL4Cofyuia2AQZ1tqfACeyft5lrV1X5COTealZDWDIGBOqlp0K6nQM+CfgGuC9wPfDVifIW699AMaYy4D3Af+c85EoXqtSdQr9tcpTpyFjzFxgKzAdsDkfCf11gorqFalrZYypB74JfJBU83o+ob9WFdQp9NcJxn7/gPXAX1trLwc6gE/lfCT7Wh0FpnheSBfFJsioQB+QHTEmrLUngyqMS7YD/2GtHbHWbgd6gdkBl8kRY8xbga8Bv5unvzGS16pEnSJ5ray1u621C0nV6ws5b0fyOkHJekXtWi0DFgK3Az8AzjXGfDFnm6hdKyd1itp1yviptXZj5v/AxTnvZ1+rScDzfhXMDbUcZDwCXAuQblZ7MtjiuOKdpPpWMcacSSoC3hdoiRwwxryd1NP+ldbajjybRO5aOahT5K6VMeYeY8zC9I9HgeGcTSJ3ncBRvSJ1ray16621S9K5CW8DnrLW5nYxROpaOaxTpK5TlnuNMcvT/381sDHn/VPXCngt8JBfBXND6JqSvGaM+R6pxJmfAq8xxjxKKokolFnITmTV6ZvAd4wxDwMjwDtD/nSSaQb9EtAJ3GmMAVhtrf1UVK+VwzpF7lqR6g//jjFmkFTT9LsgFr9TpeoVxWuVVwyu1RgxuE43AV9Jf/+6gT8DMMbcB7yOVOvNd9P1GgT+MKiCVkKrsIqIiIgnarm7RERERDykIENEREQ8oSDj/7d3x6xRRFEYht9F7FKIjZVki8BByP6ABGERrLe0DxgQDKRIFZLKf5BmhSBsIaQIWAlplfRpUgROt/4AKyWBpLG4s2Ywwe6urPM+3c6c4lbLNzOX+0mSpCoMGZIkqQpDhiRJqsKQIQmAiOhHxPRfr0PS/8OQIUmSqujcYVySoOl0eA+sAk+Ac2C3dX8ZmFDqpS8pVeDnEbEB7FAOOzoDtjLz55yXL2lB+CZD6qZ14Doz14AV4BG3RxcDjIFPmblKaf7dj4gBsAcMM3NAqar+s8xJkn4zZEgdlJmnwDgi3gIHlPKppdbIEPjYzJ5k5qvm2ufM/N7MHFK6FiTpXn4ukTooIkbAO0rAmFAqzr+1Rm5asz3gGXcfSnr4HyLpL3yTIXXTS+A4MyeU6ugXwIPW/VNK2+Vs9hD4Cowi4nFzfRP4MpfVSlpIFqRJHdTsrzhqfl4DU+AKeJ6Z/Yh4CnygbAqdbfy8iIjXwDbwkLLx801m/pj3+iUtBkOGJEmqws8lkiSpCkOGJEmqwpAhSZKqMGRIkqQqDBmSJKkKQ4YkSarCkCFJkqowZEiSpCp+AVhSgRo/ASNTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a5ff7df470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(x_vars = [\"alco\"], y_vars = [\"color_int\"], data = drink, hue = \"cultivar\", size = 7)\n",
    "plt.title(\"Scatterplot between alcohol and color intensity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.(b)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xvars = drink[[\"alco\", \"malic\", \"tot_phen\", \"color_int\"]].values\n",
    "yvals = drink[\"cultivar\"].values\n",
    "\n",
    "k = 4\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 22)\n",
    "kf.get_n_splits(Xvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_simulation(penalty_param, c):\n",
    "    \n",
    "    k_ind = 0\n",
    "    MSE = np.zeros(k)\n",
    "    \n",
    "    for train_index, test_index in kf.split(Xvars):\n",
    "        \n",
    "        X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "        y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "\n",
    "        LogReg = LogisticRegression(penalty = penalty_param, C = c, fit_intercept = True,\n",
    "                                    solver = \"saga\", multi_class = \"multinomial\")\n",
    "        LogReg.fit(X_train, y_train)\n",
    "        y_pred = LogReg.predict(X_test)\n",
    "        \n",
    "        error = y_test != y_pred\n",
    "        MSE[k_ind] = error.mean()\n",
    "        k_ind += 1\n",
    "        \n",
    "    return MSE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\liaoa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "MSE_l1_total = []\n",
    "MSE_l2_total = []\n",
    "c_param = np.linspace(0.01, 3, 300)\n",
    "\n",
    "for c in c_param:\n",
    "    MSE_l1_total += [log_simulation(\"l1\", c)]\n",
    "    MSE_l2_total += [log_simulation(\"l2\", c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log = pd.DataFrame(np.column_stack([c_param, MSE_l1_total, MSE_l2_total]), \n",
    "                          columns = [\"c_value\", \"MSE_l1\", \"MSE_l2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_value</th>\n",
       "      <th>MSE_l1</th>\n",
       "      <th>MSE_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.50</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.03</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.04</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.05</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.06</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.07</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.08</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.09</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1.10</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.11</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.12</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.13</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.14</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.15</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.16</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     c_value  MSE_l1    MSE_l2\n",
       "149     1.50   0.125  0.125000\n",
       "101     1.02   0.125  0.130682\n",
       "102     1.03   0.125  0.130682\n",
       "103     1.04   0.125  0.130682\n",
       "104     1.05   0.125  0.130682\n",
       "105     1.06   0.125  0.130682\n",
       "106     1.07   0.125  0.130682\n",
       "107     1.08   0.125  0.130682\n",
       "108     1.09   0.125  0.130682\n",
       "109     1.10   0.125  0.130682\n",
       "110     1.11   0.125  0.130682\n",
       "111     1.12   0.125  0.130682\n",
       "112     1.13   0.125  0.130682\n",
       "113     1.14   0.125  0.130682\n",
       "114     1.15   0.125  0.130682\n",
       "115     1.16   0.125  0.130682\n",
       "99      1.00   0.125  0.130682\n",
       "98      0.99   0.125  0.130682\n",
       "97      0.98   0.125  0.130682\n",
       "96      0.97   0.125  0.130682\n",
       "80      0.81   0.125  0.130682\n",
       "81      0.82   0.125  0.130682\n",
       "82      0.83   0.125  0.130682\n",
       "83      0.84   0.125  0.130682\n",
       "84      0.85   0.125  0.130682"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_log.sort_values([\"MSE_l1\"]).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_value</th>\n",
       "      <th>MSE_l1</th>\n",
       "      <th>MSE_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.50</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2.04</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2.03</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2.02</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.01</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.99</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2.05</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.98</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.96</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.95</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.94</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.93</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.92</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.91</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.97</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2.06</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2.07</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2.08</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2.23</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2.22</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2.21</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2.20</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2.19</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2.18</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     c_value    MSE_l1  MSE_l2\n",
       "149     1.50  0.125000   0.125\n",
       "203     2.04  0.130682   0.125\n",
       "202     2.03  0.130682   0.125\n",
       "201     2.02  0.130682   0.125\n",
       "200     2.01  0.130682   0.125\n",
       "199     2.00  0.130682   0.125\n",
       "198     1.99  0.130682   0.125\n",
       "204     2.05  0.130682   0.125\n",
       "197     1.98  0.130682   0.125\n",
       "195     1.96  0.130682   0.125\n",
       "194     1.95  0.130682   0.125\n",
       "193     1.94  0.130682   0.125\n",
       "192     1.93  0.130682   0.125\n",
       "191     1.92  0.130682   0.125\n",
       "190     1.91  0.130682   0.125\n",
       "196     1.97  0.130682   0.125\n",
       "205     2.06  0.130682   0.125\n",
       "206     2.07  0.130682   0.125\n",
       "207     2.08  0.130682   0.125\n",
       "222     2.23  0.130682   0.125\n",
       "221     2.22  0.130682   0.125\n",
       "220     2.21  0.130682   0.125\n",
       "219     2.20  0.130682   0.125\n",
       "218     2.19  0.130682   0.125\n",
       "217     2.18  0.130682   0.125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_log.sort_values([\"MSE_l2\"]).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to play with penalty parameter, the only method we can choose is \"saga\", although using newton-cg method can obtain lowerer MSE. The minimized overall MSE is 0.125, with penalty = \"l1\" and c in [0.49, 1.58]; or with penalty = \"l2\" and c in [1.25, 3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.(c)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_simulation(estimators, depth, samples):\n",
    "    Rand = RandomForestClassifier(n_estimators = estimators, max_depth = depth, \n",
    "                                  min_samples_leaf = samples,\n",
    "                                  random_state = 22, bootstrap = True, oob_score = True)\n",
    "    Rand.fit(Xvars, yvals)\n",
    "    \n",
    "    return 1 - Rand.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_rand_total = []\n",
    "estimators_total = []\n",
    "depth_total = []\n",
    "samples_total = []\n",
    "\n",
    "estimators = np.linspace(10, 100, 20)\n",
    "depth = np.linspace(1, 10, 10)\n",
    "samples = np.linspace(2, 20, 10)\n",
    "\n",
    "for e in estimators:\n",
    "    for d in depth:\n",
    "        for s in samples:\n",
    "            MSE_rand_total += [rand_simulation(int(e), int(d), int(s))]\n",
    "            estimators_total += [int(e)]\n",
    "            depth_total += [int(d)]\n",
    "            samples_total += [int(s)]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rand = pd.DataFrame(\n",
    "    np.column_stack([estimators_total, depth_total, samples_total, MSE_rand_total]), \n",
    "    columns = [\"n_estimators\", \"max_depth\", \"min_samples_leaf\", \"MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>90.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>85.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>95.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>90.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>85.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>90.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>85.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>85.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>95.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>95.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>85.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>95.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>90.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>95.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>85.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.056818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_estimators  max_depth  min_samples_leaf       MSE\n",
       "1790          90.0       10.0               2.0  0.056818\n",
       "1940         100.0        5.0               2.0  0.056818\n",
       "1650          85.0        6.0               2.0  0.056818\n",
       "1340          71.0        5.0               2.0  0.056818\n",
       "1880          95.0        9.0               2.0  0.056818\n",
       "1750          90.0        6.0               2.0  0.056818\n",
       "1670          85.0        8.0               2.0  0.056818\n",
       "1780          90.0        9.0               2.0  0.056818\n",
       "1690          85.0       10.0               2.0  0.056818\n",
       "1970         100.0        8.0               2.0  0.056818\n",
       "1640          85.0        5.0               2.0  0.056818\n",
       "1870          95.0        8.0               2.0  0.056818\n",
       "1740          90.0        5.0               2.0  0.056818\n",
       "1950         100.0        6.0               2.0  0.056818\n",
       "1860          95.0        7.0               2.0  0.056818\n",
       "1660          85.0        7.0               2.0  0.056818\n",
       "1890          95.0       10.0               2.0  0.056818\n",
       "1980         100.0        9.0               2.0  0.056818\n",
       "1960         100.0        7.0               2.0  0.056818\n",
       "1990         100.0       10.0               2.0  0.056818\n",
       "1850          95.0        6.0               2.0  0.056818\n",
       "1770          90.0        8.0               2.0  0.056818\n",
       "1840          95.0        5.0               2.0  0.056818\n",
       "1680          85.0        9.0               2.0  0.056818\n",
       "1760          90.0        7.0               2.0  0.056818"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rand.sort_values([\"MSE\"]).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimized overall MSE is 0.056818, with n_estimators in [70, 100], max_depth in [6, 10], min_samples_leaf = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.(d)\n",
    "from sklearn import svm\n",
    "\n",
    "def svm_simulation(C, g):\n",
    "    \n",
    "    k_ind = 0\n",
    "    MSE = np.zeros(k)\n",
    "\n",
    "    for train_index, test_index in kf.split(Xvars):\n",
    "\n",
    "        X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "        y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "\n",
    "        svc = svm.SVC(kernel = \"rbf\", C = c, gamma = g)\n",
    "        svc.fit(X_train, y_train)\n",
    "        y_pred = svc.predict(X_test)\n",
    "\n",
    "        error = y_test != y_pred\n",
    "        MSE[k_ind] = error.mean()\n",
    "\n",
    "        k_ind += 1\n",
    "\n",
    "        return MSE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_svm_total = []\n",
    "C_total = []\n",
    "gamma_total = []\n",
    "\n",
    "C = np.linspace(1, 100, 100)\n",
    "gamma = np.linspace(0.05, 1, 20)\n",
    "\n",
    "for c in C:\n",
    "    for g in gamma:\n",
    "        MSE_svm_total += [svm_simulation(c, g)]\n",
    "        C_total += [c]\n",
    "        gamma_total += [g]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_svm = pd.DataFrame(np.column_stack([C_total, gamma_total, MSE_svm_total]), \n",
    "                          columns = [\"C\", \"gamma\", \"MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  gamma       MSE\n",
       "23    2.0   0.20  0.005682\n",
       "43    3.0   0.20  0.005682\n",
       "42    3.0   0.15  0.005682\n",
       "61    4.0   0.10  0.005682\n",
       "62    4.0   0.15  0.005682\n",
       "81    5.0   0.10  0.005682\n",
       "24    2.0   0.25  0.005682\n",
       "121   7.0   0.10  0.005682\n",
       "101   6.0   0.10  0.005682\n",
       "93    5.0   0.70  0.011364\n",
       "92    5.0   0.65  0.011364\n",
       "360  19.0   0.05  0.011364\n",
       "80    5.0   0.05  0.011364\n",
       "79    4.0   1.00  0.011364\n",
       "380  20.0   0.05  0.011364\n",
       "77    4.0   0.90  0.011364\n",
       "75    4.0   0.80  0.011364\n",
       "74    4.0   0.75  0.011364\n",
       "64    4.0   0.25  0.011364\n",
       "63    4.0   0.20  0.011364\n",
       "60    4.0   0.05  0.011364\n",
       "59    3.0   1.00  0.011364\n",
       "78    4.0   0.95  0.011364\n",
       "76    4.0   0.85  0.011364\n",
       "94    5.0   0.75  0.011364"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_svm.sort_values([\"MSE\"]).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimized overall MSE is 0.005682, with cost in [2,7] and gamma in [0.10, 0.25]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.(e)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def mlp_simulation(h, ac, al):\n",
    "    \n",
    "    k_ind = 0\n",
    "    MSE = np.zeros(k)\n",
    "\n",
    "    for train_index, test_index in kf.split(Xvars):\n",
    "\n",
    "        X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "        y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "\n",
    "        mlp = MLPClassifier(hidden_layer_sizes = h, activation = ac, alpha = al)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        y_pred = mlp.predict(X_test)\n",
    "\n",
    "        error = y_test != y_pred\n",
    "        MSE[k_ind] = error.mean()\n",
    "\n",
    "        k_ind += 1\n",
    "\n",
    "        return MSE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\liaoa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "MSE_mlp_total = []\n",
    "hidden_total = []\n",
    "activation_total = []\n",
    "alpha_total = []\n",
    "\n",
    "hidden = np.linspace(50, 500, 10)\n",
    "hidden = [(int(h),) for h in hidden]\n",
    "activation = np.array([\"identity\", \"logistic\", \"tanh\", \"relu\"])\n",
    "alpha = np.logspace(-3, 3, 7)\n",
    " \n",
    "for h in hidden:\n",
    "    for ac in activation:\n",
    "        for al in alpha:\n",
    "            MSE_mlp_total += [mlp_simulation(h, ac, al)]\n",
    "            hidden_total += [h]\n",
    "            activation_total += [ac]\n",
    "            alpha_total += [al]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mlp = pd.DataFrame(np.column_stack([hidden_total, activation_total, alpha_total, MSE_mlp_total]), \n",
    "                          columns = [\"hidden_layer\", \"activation\", \"alpha\", \"MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layer</th>\n",
       "      <th>activation</th>\n",
       "      <th>alpha</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>450</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>350</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>500</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>500</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>350</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>350</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>450</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>450</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>350</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>450</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>450</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>400</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>450</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>400</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>150</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>400</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>300</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>300</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>300</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>400</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>300</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>400</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>300</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011363636363636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_layer activation  alpha                   MSE\n",
       "238          450       tanh  0.001  0.011363636363636364\n",
       "183          350       tanh   0.01  0.011363636363636364\n",
       "267          500       tanh   0.01  0.011363636363636364\n",
       "266          500       tanh  0.001  0.011363636363636364\n",
       "182          350       tanh  0.001  0.011363636363636364\n",
       "191          350       relu    0.1  0.011363636363636364\n",
       "240          450       tanh    0.1  0.011363636363636364\n",
       "241          450       tanh    1.0  0.011363636363636364\n",
       "184          350       tanh    0.1  0.011363636363636364\n",
       "246          450       relu   0.01  0.011363636363636364\n",
       "248          450       relu    1.0  0.011363636363636364\n",
       "220          400       relu    1.0  0.011363636363636364\n",
       "239          450       tanh   0.01  0.011363636363636364\n",
       "219          400       relu    0.1  0.011363636363636364\n",
       "70           150       tanh  0.001  0.011363636363636364\n",
       "212          400       tanh    0.1  0.011363636363636364\n",
       "155          300       tanh   0.01  0.011363636363636364\n",
       "156          300       tanh    0.1  0.011363636363636364\n",
       "157          300       tanh    1.0  0.011363636363636364\n",
       "211          400       tanh   0.01  0.011363636363636364\n",
       "274          500       relu   0.01  0.011363636363636364\n",
       "161          300       relu  0.001  0.011363636363636364\n",
       "210          400       tanh  0.001  0.011363636363636364\n",
       "275          500       relu    0.1  0.011363636363636364\n",
       "164          300       relu    1.0  0.011363636363636364"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_mlp.sort_values([\"MSE\"]).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimized overall MSE is 0.011363636363636364, with hidden layer size in [350, 400], activation in {tanh, relu} and alpha in {0.001, 0,01, 0,01, 1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best combination for LogisticRegression is:\n",
      "     c_value  MSE_l1  MSE_l2\n",
      "149      1.5   0.125   0.125\n",
      "\n",
      "The best combination for RandomForestClassifier is:\n",
      "      n_estimators  max_depth  min_samples_leaf       MSE\n",
      "1790          90.0       10.0               2.0  0.056818\n",
      "\n",
      "The best combination for SupportVectorMachine is:\n",
      "      C  gamma       MSE\n",
      "23  2.0    0.2  0.005682\n",
      "\n",
      "The best combination for MLPClassifier is:\n",
      "    hidden_layer activation  alpha                   MSE\n",
      "238          450       tanh  0.001  0.011363636363636364\n"
     ]
    }
   ],
   "source": [
    "#1.(f)\n",
    "print(\"The best combination for LogisticRegression is:\")\n",
    "print(result_log.sort_values([\"MSE_l1\"]).head(1))\n",
    "print(\"\")\n",
    "print(\"The best combination for RandomForestClassifier is:\")\n",
    "print(result_rand.sort_values([\"MSE\"]).head(1))\n",
    "print(\"\")\n",
    "print(\"The best combination for SupportVectorMachine is:\")\n",
    "print(result_svm.sort_values([\"MSE\"]).head(1))\n",
    "print(\"\")\n",
    "print(\"The best combination for MLPClassifier is:\")\n",
    "print(result_mlp.sort_values([\"MSE\"]).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.(f)\n",
    "I believe that the support vector machine is the best predictor of cultivar, because it has the lowest MSE. The second best is neural network, followed by random forest. The logistics regression is the worst one among these four models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
