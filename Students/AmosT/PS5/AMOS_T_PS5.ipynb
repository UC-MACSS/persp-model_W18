{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 5 \n",
    "### Tyler Amos\n",
    "### MACSS 30100\n",
    "#### 19 February 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "sb.set_style('whitegrid')\n",
    "\n",
    "coolindex_link = 'https://raw.githubusercontent.com/UC-MACSS/persp-model_W18/master/ProblemSets/PS5/data/CoolIndex.txt'\n",
    "strongdrink_link = 'https://raw.githubusercontent.com/UC-MACSS/persp-model_W18/master/ProblemSets/PS5/data/strongdrink.txt'\n",
    "cool_index = pd.read_csv(coolindex_link, header=None, names = ['age','coolness'])\n",
    "strong_drink = pd.read_csv(strongdrink_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COEFFICIENTS AND INTERCEPTS\n",
      "INTERCEPTS\n",
      "[-24.0108148  22.8025761   1.2082387]\n",
      "\n",
      "COEFFICIENTS\n",
      "[[ 1.70038994e+00 -2.65604001e-01  1.22389318e+00  2.27585993e-02\n",
      "  -8.45998037e-06]\n",
      " [-1.46805313e+00 -3.33053748e-01  6.64013944e-01 -9.22712974e-01\n",
      "  -1.76923783e-05]\n",
      " [-2.32336811e-01  5.98657749e-01 -1.88790712e+00  8.99954375e-01\n",
      "   2.61523587e-05]]\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      1.00      0.93        13\n",
      "          2       1.00      0.90      0.95        21\n",
      "          3       1.00      1.00      1.00        10\n",
      "\n",
      "avg / total       0.96      0.95      0.96        44\n",
      "\n",
      "ERROR RATES\n",
      "Cultivar 1:  0.13\n",
      "Cultivar 2:  0\n",
      "Cultivar 3:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_var = ['cultivar']\n",
    "x_var = ['alco', 'malic', 'tot_phen', 'color_int']\n",
    "\n",
    "x_poly_strong_drink = strong_drink[x_var].copy()\n",
    "x_poly_strong_drink['constant'] = 1 # Add constant\n",
    "y_poly_strong_drink = np.ravel(strong_drink[y_var])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_poly_strong_drink, y_poly_strong_drink, test_size = 0.25, random_state=20)\n",
    "multi_log = LogisticRegression(multi_class='multinomial', solver ='newton-cg')\n",
    "multi_log.fit(x_train, y_train)\n",
    "y_pred = multi_log.predict(x_test)\n",
    "\n",
    "print(\"\\nCOEFFICIENTS AND INTERCEPTS\")\n",
    "print(\"INTERCEPTS\")\n",
    "print(multi_log.intercept_)\n",
    "print(\"\\nCOEFFICIENTS\")\n",
    "print(multi_log.coef_)\n",
    "print(\"\\nCLASSIFICATION REPORT\")\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)\n",
    "print(\"ERROR RATES\")\n",
    "print(\"Cultivar 1: \", 1-.87)\n",
    "print(\"Cultivar 2: \", 1-1)\n",
    "print(\"Cultivar 3: \", 1-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is best at predicting Cultivar 3. We can say that Cultivars 2 and 3 are equally well identified (precision), but some Cultivar 2 cases are incorrectly labelled as another, presumably Cultivar 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cultivar\n",
       "1    59\n",
       "2    71\n",
       "3    46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_drink.groupby(y_var).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent that the best-predicted categories are in fact those with the most values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Leave One Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from R. Evans notes\n",
    "xvars = x_poly_strong_drink.values\n",
    "yvals = y_poly_strong_drink # This is already a Numpy array\n",
    "N_loo = xvars.shape[0]\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(xvars)\n",
    "error_vec = np.zeros(N_loo)\n",
    "\n",
    "results_df = DataFrame()\n",
    "y_test_list = []\n",
    "y_pred_list = []\n",
    "indicator_error = []\n",
    "for train_index, test_index in loo.split(xvars):\n",
    "    x_train, x_test = xvars[train_index], xvars[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    multi_log = LogisticRegression(multi_class='multinomial', solver ='newton-cg')\n",
    "    multi_log.fit(x_train, y_train)\n",
    "    y_pred = multi_log.predict(x_test)\n",
    "    y_test_list.append(y_test[0])\n",
    "    y_pred_list.append(y_pred[0])\n",
    "    indicator_error.append(1 if y_test[0] == y_pred else 0)\n",
    "results_df['y_pred'] = y_pred_list\n",
    "results_df['y_test'] = y_test_list\n",
    "results_df['error'] = indicator_error\n",
    "    \n",
    "print(\"\\nCLASSIFICATION REPORT\")\n",
    "class_report = classification_report(results_df['y_test'], results_df['y_pred'])\n",
    "print(class_report)\n",
    "\n",
    "print(\"ERROR RATES\")\n",
    "print(\"Cultivar 1: \", 1-.90)\n",
    "print(\"Cultivar 2: \", 1-.91)\n",
    "print(\"Cultivar 3: \", 1-.96)\n",
    "\n",
    "print(\"\\nMSE\")\n",
    "print(\"LOOCV \", results_df['error'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rates have decreased relative to part (a). In part (a), the error rates were as high as 0.13. However, with Leave One Out, the error rates are slightly smaller $\\approx 0.09$ for all Cultivars. However, we also see higher errors for Cultivars 2 and 3. This seems more plausible than part (a), as the errors are distributed more evenly across the cultivars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k = 4\n",
    "xvars = x_poly_strong_drink.values\n",
    "yvals = y_poly_strong_drink # This is already a Numpy array\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=10)\n",
    "kf.get_n_splits(xvars)\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "y_test_list = []\n",
    "y_pred_list = []\n",
    "indicator_error = []\n",
    "results_df = DataFrame()\n",
    "y_test_list = []\n",
    "y_pred_list = []\n",
    "indicator_error = []\n",
    "for train_index, test_index in kf.split(xvars):\n",
    "    print('k index=', k_ind)\n",
    "    x_train, x_test = xvars[train_index], xvars[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    multi_log = LogisticRegression(multi_class='multinomial', solver ='newton-cg')\n",
    "    multi_log.fit(x_train, y_train)\n",
    "    y_pred = multi_log.predict(x_test)\n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred) ** 2).mean()\n",
    "    print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    k_ind += 1\n",
    "    \n",
    "MSE_kf = MSE_vec_kf.mean()\n",
    "print('\\nK-FOLD MSE ', MSE_kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These error rates are slightly higher than (a) and (b). \n",
    "\n",
    "\n",
    "\n",
    "# 2. Splines and Interpolation\n",
    "\n",
    "# a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_index.plot(kind = 'scatter', x = 'age', y = 'coolness', title = 'Coolness Index Values by Age')\n",
    "plt.xlabel('Age of Individual Surveyed')\n",
    "plt.ylabel('Coolness Index Value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Stepwise Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool = cool_index['coolness']\n",
    "age = cool_index['age']\n",
    "age_bin1 = ((age >= 11) & (age < 22)).astype(int)\n",
    "age_bin2 = ((age >= 22) & (age < 40)).astype(int)\n",
    "age_bin3 = ((age >= 40) & (age < 59)).astype(int)\n",
    "age_bin4 = ((age >= 59) & (age < 77)).astype(int)\n",
    "age_bin5 = ((age >= 77) & (age < 95)).astype(int)\n",
    "X_step = pd.DataFrame(dict(age_bin1=age_bin1, age_bin2=age_bin2,\n",
    "                           age_bin3=age_bin3, age_bin4=age_bin4,\n",
    "                           age_bin5=age_bin5))\n",
    "reg2 = sm.OLS(endog=cool, exog=X_step, missing='drop')\n",
    "reg2_results = reg2.fit()\n",
    "print(reg2_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_index.plot(kind = 'scatter', x = 'age', y = 'coolness', color = \"grey\", title = 'Coolness Index Values by Age', label = \"Raw Data\")\n",
    "plt.xlabel('Age of Individual Surveyed')\n",
    "plt.ylabel('Coolness Index Value')\n",
    "plt.step([22,40, 59, 77, 95], reg2_results.params, color = \"blue\", label = \"Stepwise Estimation\")\n",
    "plt.legend()\n",
    "print(\"COEFFICIENTS\")\n",
    "print(reg2_results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTED COOLNESS OF 73-YEAR-OLD, SPLINE WITH k= 1\", reg2_results.params[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import LSQUnivariateSpline\n",
    "knots  = [22,40,59,77]\n",
    "spl = LSQUnivariateSpline(age.values, cool.values, knots, k=1)\n",
    "cool_index.plot(kind = 'scatter', x = 'age', y = 'coolness', color = \"grey\", title = 'Coolness Index Values by Age', label = \"Raw Data (a)\")\n",
    "plt.xlabel('Age of Individual Surveyed')\n",
    "plt.ylabel('Coolness Index Value')\n",
    "plt.step([22,40, 59, 77, 95], reg2_results.params, color = \"blue\", label = \"Stepwise Estimation (b)\")\n",
    "plt.plot(age.values, spl(age.values), color = \"yellow\", label = \"Spline, k =1 (c)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTED COOLNESS OF 73-YEAR-OLD, SPLINE WITH k= 1\", spl(73))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knots  = [22,40,59,77]\n",
    "spl2 = LSQUnivariateSpline(age.values, cool.values, knots, k=3)\n",
    "cool_index.plot(kind = 'scatter', x = 'age', y = 'coolness', color = \"grey\", title = 'Coolness Index Values by Age', label = \"Raw Data (a)\")\n",
    "plt.xlabel('Age of Individual Surveyed')\n",
    "plt.ylabel('Coolness Index Value')\n",
    "plt.step([22,40, 59, 77, 95], reg2_results.params, color = \"blue\", label = \"Stepwise Estimation (b)\")\n",
    "plt.plot(age.values, spl2(age.values), color = \"yellow\", label = \"Spline, k = 3(c)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PREDICTED COOLNESS OF 73-YEAR-OLD, SPLINE WITH k = 3\", spl(73))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
