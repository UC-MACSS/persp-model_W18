{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 7\n",
    "\n",
    "Ariel Boyarsky\n",
    "\n",
    "aboyarsky@uchciago.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneOut, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Classifier “horse” race (10 points). For this problem, you will use the 397\n",
    "observations from the Auto.csv dataset.1 This dataset includes 397 observations\n",
    "on miles per gallon (mpg), number of cylinders (cylinders), engine displacement\n",
    "(displacement), horsepower (horsepower), vehicle weight (weight), acceleration\n",
    "(acceleration), vehicle year (year), vehicle origin (origin), and\n",
    "vehicle name (name). We will study the factors that make miles per gallon\n",
    "high or low. Create a binary variable mpg high that equals 1 if mpg high≥\n",
    "median(mpg high) and equals either 0 if mpg high< median(mpg high)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dta = pd.read_csv(\"Auto.csv\", na_values='?')\n",
    "dta = dta.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mpg_level(mpg):\n",
    "    med = np.median(dta.mpg)\n",
    "    if mpg >= med:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "dta['mpg_high'] = dta.apply(lambda row: mpg_level(row['mpg']), axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Use sklearn.linear model.LogisticRegression to fit a logistic model\n",
    "of mpg high on features number of cylinders (cyl), engine displacement\n",
    "(dspl), horsepower (hpwr), vehicle weight (wgt), acceleration (accl), vehicle\n",
    "year (yr), vehicle origin (orgn). Make sure to include a constant term.\n",
    "Fit the model using k-fold cross validation with k = 4 folds.\n",
    "\n",
    "Report the MSE of the model as the average MSE across the k = 4 test\n",
    "sets, and report the error rates for each category of mpg high as the average\n",
    "error rate for that category across the k = 4 test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>mpg_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "   origin                       name  mpg_high  \n",
       "0       1  chevrolet chevelle malibu         0  \n",
       "1       1          buick skylark 320         0  \n",
       "2       1         plymouth satellite         0  \n",
       "3       1              amc rebel sst         0  \n",
       "4       1                ford torino         0  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dta[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']].values\n",
    "y = dta['mpg_high'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k index= 0\n",
      "MSE for test set 0  is 0.0918367346939\n",
      "Error rate (low, 0):  0.0576923076923\n",
      "Error rate (high, 1):  0.130434782609\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.942     0.891     0.916        55\n",
      "          1      0.870     0.930     0.899        43\n",
      "\n",
      "avg / total      0.910     0.908     0.908        98\n",
      "\n",
      "k index= 1\n",
      "MSE for test set 1  is 0.102040816327\n",
      "Error rate (low, 0):  0.122448979592\n",
      "Error rate (high, 1):  0.0816326530612\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.878     0.915     0.896        47\n",
      "          1      0.918     0.882     0.900        51\n",
      "\n",
      "avg / total      0.899     0.898     0.898        98\n",
      "\n",
      "k index= 2\n",
      "MSE for test set 2  is 0.132653061224\n",
      "Error rate (low, 0):  0.152173913043\n",
      "Error rate (high, 1):  0.115384615385\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.848     0.867     0.857        45\n",
      "          1      0.885     0.868     0.876        53\n",
      "\n",
      "avg / total      0.868     0.867     0.867        98\n",
      "\n",
      "k index= 3\n",
      "MSE for test set 3  is 0.102040816327\n",
      "Error rate (low, 0):  0.046511627907\n",
      "Error rate (high, 1):  0.145454545455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.953     0.837     0.891        49\n",
      "          1      0.855     0.959     0.904        49\n",
      "\n",
      "avg / total      0.904     0.898     0.898        98\n",
      "\n",
      " avg low error rate:  0.0947067070586 \n",
      " AVG high error rate:  0.118226649127 \n",
      " Average MSE:  0.107142857143\n"
     ]
    }
   ],
   "source": [
    "k=4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=15)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_test_vec = np.array([])\n",
    "y_pred_vec = np.array([])\n",
    "e_0 = np.zeros(k)\n",
    "e_1 = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print('k index=', k_ind)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_test_vec = np.append(y_test_vec, y_test)\n",
    "    LogReg = LogisticRegression(fit_intercept=True)\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    y_pred_vec = np.append(y_pred_vec, y_pred)\n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred) ** 2).mean()\n",
    "    err0 = ((y_pred==0)*(np.abs(y_test-y_pred))).sum() / (y_pred==0).sum()\n",
    "    e_0[k_ind] = (err0)\n",
    "    err1 = ((y_pred==1)*(np.abs(y_test-y_pred))).sum() / (y_pred==1).sum()\n",
    "    e_1[k_ind] = (err1)\n",
    "    print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    print('Error rate (low, 0): ', err0)\n",
    "    print('Error rate (high, 1): ', err1)\n",
    "    print('\\n',classification_report(y_test, y_pred, digits=3))\n",
    "    k_ind += 1\n",
    "\n",
    "MSE_kf = MSE_vec_kf.mean()\n",
    "MSE_kf_std = MSE_vec_kf.std()\n",
    "print(' avg low error rate: ', e_0.mean(), '\\n AVG high error rate: ', e_1.mean(), '\\n Average MSE: ', MSE_vec_kf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use sklearn.ensemble.RandomForestClassifier to fit a random forest\n",
    "model of mpg high on max features=2 out of the seven possible features\n",
    "used in part (a). Set n estimators=20, set bootstrap=True, set\n",
    "oob score=True, and set random state=25. Report the MSE of the random\n",
    "forest model as the MSE from the .oob prediction object, and report\n",
    "the error rates for each category of mpg high from the .oob prediction\n",
    "object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=True, random_state=25,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20, max_features=2, bootstrap=True,\n",
    "                                  oob_score=True, random_state=25)\n",
    "forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 0.0714285714286\n",
      "MSE for low category (0) =  0.0578947368421\n",
      "MSE for low category (0) =  0.0841584158416\n"
     ]
    }
   ],
   "source": [
    "forest.score(X, y)\n",
    "MSE_df = pd.DataFrame({'ypred': forest.oob_decision_function_.T[1], 'y': y})\n",
    "MSE_df['ypred'] = MSE_df['ypred'].apply(lambda x: 1 if int(x>=0.5) else 0)\n",
    "MSE = mean_squared_error(MSE_df['y'], MSE_df['ypred'])\n",
    "MSE_0 = mean_squared_error(MSE_df['y'].where(MSE_df.ypred<0.5).dropna(), MSE_df['ypred'].where(MSE_df.ypred<0.5).dropna())\n",
    "MSE_1 = mean_squared_error(MSE_df['y'].where(MSE_df.ypred>0.5).dropna(), MSE_df['ypred'].where(MSE_df.ypred>0.5).dropna())\n",
    "print('MSE=', MSE)\n",
    "print('MSE for low category (0) = ', MSE_0)\n",
    "print('MSE for low category (0) = ', MSE_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "c.Use sklearn.svm.SVC to fit a support vector machines model of mpg high\n",
    "with a Gaussian radial basis function kernel kernel=’rbf’ on the seven\n",
    "features used in part (a). Set the penalty parameter to C=1 and set\n",
    "gamma=0.2. Fit the model using k-fold cross validation with k = 4 folds\n",
    "exactly as in part (a).\n",
    "\n",
    "\n",
    "Report the MSE of the model as the average MSE across the k = 4 test\n",
    "sets, and report the error rates for each category of mpg high as the average\n",
    "error rate for that category across the k = 4 test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k index= 0\n",
      "MSE for test set 0  is 0.540816326531\n",
      "Error rate (low, 0):  0.0\n",
      "Error rate (high, 1):  0.552083333333\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      1.000     0.036     0.070        55\n",
      "          1      0.448     1.000     0.619        43\n",
      "\n",
      "avg / total      0.758     0.459     0.311        98\n",
      "\n",
      "k index= 1\n",
      "MSE for test set 1  is 0.520408163265\n",
      "Error rate (low, 0):  0.520408163265\n",
      "Error rate (high, 1):  nan\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.480     1.000     0.648        47\n",
      "          1      0.000     0.000     0.000        51\n",
      "\n",
      "avg / total      0.230     0.480     0.311        98\n",
      "\n",
      "k index= 2\n",
      "MSE for test set 2  is 0.520408163265\n",
      "Error rate (low, 0):  0.53125\n",
      "Error rate (high, 1):  0.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.469     1.000     0.638        45\n",
      "          1      1.000     0.038     0.073        53\n",
      "\n",
      "avg / total      0.756     0.480     0.332        98\n",
      "\n",
      "k index= 3\n",
      "MSE for test set 3  is 0.448979591837\n",
      "Error rate (low, 0):  0.47311827957\n",
      "Error rate (high, 1):  0.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.527     1.000     0.690        49\n",
      "          1      1.000     0.102     0.185        49\n",
      "\n",
      "avg / total      0.763     0.551     0.438        98\n",
      "\n",
      " avg low error rate:  0.381194110709 \n",
      " AVG high error rate:  0.184027777778 \n",
      " Average MSE:  0.507653061224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "k=4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=15)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_test_vec = np.array([])\n",
    "y_pred_vec = np.array([])\n",
    "e_0 = np.zeros(k)\n",
    "e_1 = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print('k index=', k_ind)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_test_vec = np.append(y_test_vec, y_test)\n",
    "    svc = svm.SVC(kernel='rbf', gamma = 0.2, C=1)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    y_pred_vec = np.append(y_pred_vec, y_pred)\n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred) ** 2).mean()\n",
    "    err0 = ((y_pred==0)*(np.abs(y_test-y_pred))).sum() / (y_pred==0).sum()\n",
    "    e_0[k_ind] = (err0)\n",
    "    err1 = ((y_pred==1)*(np.abs(y_test-y_pred))).sum() / (y_pred==1).sum()\n",
    "    e_1[k_ind] = (err1)\n",
    "    print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    print('Error rate (low, 0): ', err0)\n",
    "    print('Error rate (high, 1): ', err1)\n",
    "    print('\\n',classification_report(y_test, y_pred, digits=3))\n",
    "    k_ind += 1\n",
    "\n",
    "MSE_kf = MSE_vec_kf.mean()\n",
    "MSE_kf_std = MSE_vec_kf.std()\n",
    "print(' avg low error rate: ', e_0[~np.isnan(e_0)].mean(), '\\n AVG high error rate: ', e_1[~np.isnan(e_1)].mean(), '\\n Average MSE: ', MSE_vec_kf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. Which of the above three models do you think is the best predictor of\n",
    "mpg high? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on the above results it is clear that the the *Random Forest is the best model*. This is because the error rates for this model are the lowest. The MSE is also lowest on this model.The SVM is the least accurate of the three and the logistic regression model is the next best after the random forest. Notice that MSE on the SVM is $\\approx0.507$ while on the Logit model it is $\\approx0.107$ and on the random forest it is $\\approx0.071$. This trend also continues in error rates in which  the random forest has by farthe lowest high and low mpg error rates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
