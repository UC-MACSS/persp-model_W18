{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('Auto.csv', na_values='?')\n",
    "auto = auto.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>mpg_median</th>\n",
       "      <th>mpg_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "   origin                       name  mpg_median  mpg_high  \n",
       "0       1  chevrolet chevelle malibu       22.75         0  \n",
       "1       1          buick skylark 320       22.75         0  \n",
       "2       1         plymouth satellite       22.75         0  \n",
       "3       1              amc rebel sst       22.75         0  \n",
       "4       1                ford torino       22.75         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto['mpg_median'] = auto['mpg'].median()\n",
    "auto['mpg_high'] = auto['mpg'] > auto['mpg_median']\n",
    "auto['mpg_high'] = auto['mpg_high'].apply(int)\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvals = auto['mpg_high'].values\n",
    "Xvals = auto[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']].values\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, random_state=15, shuffle=True)\n",
    "kf.get_n_splits(Xvals)\n",
    "Logit_err_0 = np.zeros(k)\n",
    "Logit_err_1 = np.zeros(k)\n",
    "Logit_MSE_VEC = np.zeros(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If k index= 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.92        55\n",
      "          1       0.87      0.93      0.90        43\n",
      "\n",
      "avg / total       0.91      0.91      0.91        98\n",
      "\n",
      "The error rate(category 0) is 0.057692307692307696\n",
      "The error rate(category 1) is 0.13043478260869565\n",
      "The MSE is 0.09183673469387756\n",
      "If k index= 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90        47\n",
      "          1       0.92      0.88      0.90        51\n",
      "\n",
      "avg / total       0.90      0.90      0.90        98\n",
      "\n",
      "The error rate(category 0) is 0.12244897959183673\n",
      "The error rate(category 1) is 0.08163265306122448\n",
      "The MSE is 0.10204081632653061\n",
      "If k index= 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86        45\n",
      "          1       0.88      0.87      0.88        53\n",
      "\n",
      "avg / total       0.87      0.87      0.87        98\n",
      "\n",
      "The error rate(category 0) is 0.15217391304347827\n",
      "The error rate(category 1) is 0.11538461538461539\n",
      "The MSE is 0.1326530612244898\n",
      "If k index= 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.84      0.89        49\n",
      "          1       0.85      0.96      0.90        49\n",
      "\n",
      "avg / total       0.90      0.90      0.90        98\n",
      "\n",
      "The error rate(category 0) is 0.046511627906976744\n",
      "The error rate(category 1) is 0.14545454545454545\n",
      "The MSE is 0.10204081632653061\n",
      "\n",
      " k-Fold Reults:\n",
      "The average error rate(category 0) is 0.09470670705864986\n",
      "The average error rate(category 1) is 0.11822664912727025\n",
      "The average MSE of the model is 0.10714285714285715\n"
     ]
    }
   ],
   "source": [
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvals):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print('If k index=', k_ind + 1)\n",
    "    X_train, X_test = Xvals[train_index], Xvals[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    LogReg = LogisticRegression(fit_intercept=True)\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    err = y_test != y_pred\n",
    "    Logit_MSE_VEC[k_ind] = err.mean()\n",
    "    Logit_err_0[k_ind] = ((y_pred == 0) * err).sum() / (y_pred == 0).sum() \n",
    "    Logit_err_1[k_ind] = ((y_pred == 1) * err).sum() / (y_pred == 1).sum() \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('The error rate(category 0) is', Logit_err_0[k_ind])\n",
    "    print('The error rate(category 1) is', Logit_err_1[k_ind])\n",
    "    print('The MSE is', Logit_MSE_VEC[k_ind])\n",
    "    k_ind += 1\n",
    "print('\\n k-Fold Reults:')\n",
    "print('The average error rate(category 0) is', Logit_err_0.mean())\n",
    "print('The average error rate(category 1) is', Logit_err_1.mean())\n",
    "print('The average MSE of the model is', Logit_MSE_VEC.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.91      0.93       196\n",
      "          1       0.92      0.94      0.93       196\n",
      "\n",
      "avg / total       0.93      0.93      0.93       392\n",
      "\n",
      "The error rate(category 0) is 0.05789473684210526\n",
      "The error rate(category 1) is 0.08415841584158416\n",
      "The MSE of the model is 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=20, max_features=2, bootstrap=True,oob_score=True, random_state=25)\n",
    "RF.fit(Xvals, yvals)\n",
    "oob_prediction = RF.oob_decision_function_.T[1]\n",
    "MSE_RF = pd.DataFrame({'pred' : oob_prediction, 'yvals': yvals})\n",
    "MSE_RF['pred'] = MSE_RF['pred'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "print(classification_report(MSE_RF['yvals'], MSE_RF['pred']))\n",
    "error = (MSE_RF['pred'] != MSE_RF['yvals']).apply(int)\n",
    "RF_err_0 = ((MSE_RF['pred'] == 0) * error).sum() / (MSE_RF['pred'] == 0).sum() \n",
    "RF_err_1 = ((MSE_RF['pred'] == 1) * error).sum() / (MSE_RF['pred'] == 1).sum() \n",
    "print('The error rate(category 0) is', RF_err_0.mean())\n",
    "print('The error rate(category 1) is', RF_err_1.mean())\n",
    "print('The MSE of the model is', error.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If k index= 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      1.000     0.036     0.070        55\n",
      "          1      0.448     1.000     0.619        43\n",
      "\n",
      "avg / total      0.758     0.459     0.311        98\n",
      "\n",
      "The error rate(category 0) is 0.0\n",
      "The error rate(category 1) is 0.5520833333333334\n",
      "The MSE is 0.5408163265306123\n",
      "\n",
      "If k index= 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.480     1.000     0.648        47\n",
      "          1      0.000     0.000     0.000        51\n",
      "\n",
      "avg / total      0.230     0.480     0.311        98\n",
      "\n",
      "The error rate(category 0) is 0.5204081632653061\n",
      "The error rate(category 1) is nan\n",
      "The MSE is 0.5204081632653061\n",
      "\n",
      "If k index= 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.469     1.000     0.638        45\n",
      "          1      1.000     0.038     0.073        53\n",
      "\n",
      "avg / total      0.756     0.480     0.332        98\n",
      "\n",
      "The error rate(category 0) is 0.53125\n",
      "The error rate(category 1) is 0.0\n",
      "The MSE is 0.5204081632653061\n",
      "\n",
      "If k index= 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.527     1.000     0.690        49\n",
      "          1      1.000     0.102     0.185        49\n",
      "\n",
      "avg / total      0.763     0.551     0.438        98\n",
      "\n",
      "The error rate(category 0) is 0.4731182795698925\n",
      "The error rate(category 1) is 0.0\n",
      "The MSE is 0.4489795918367347\n",
      "\n",
      "k-Fold Reults:\n",
      "The average error rate(category 0) is 0.38119411070879966\n",
      "The average error rate(category 1) is 0.1840277777777778\n",
      "The average MSE of the model is 0.5076530612244898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xinyu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\xinyu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "SVC_err_0 = np.zeros(k)\n",
    "SVC_err_1 = np.zeros(k)\n",
    "SVC_MSE_VEC = np.zeros(k)\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvals):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print('\\nIf k index=', k_ind + 1)\n",
    "    X_train, X_test = Xvals[train_index], Xvals[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    svc = svm.SVC(kernel='rbf', gamma=0.2, C=1)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    err = y_test != y_pred\n",
    "    SVC_MSE_VEC[k_ind] = err.mean()\n",
    "    SVC_err_0[k_ind] = ((y_pred == 0) * err).sum() / (y_pred == 0).sum() \n",
    "    SVC_err_1[k_ind] = ((y_pred == 1) * err).sum() / (y_pred == 1).sum() \n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print('The error rate(category 0) is', SVC_err_0[k_ind])\n",
    "    print('The error rate(category 1) is', SVC_err_1[k_ind])\n",
    "    print('The MSE is', SVC_MSE_VEC[k_ind])\n",
    "    k_ind += 1\n",
    "print('\\nk-Fold Reults:')\n",
    "SVC_err_1 = SVC_err_1[~np.isnan(SVC_err_1)]\n",
    "print('The average error rate(category 0) is', SVC_err_0.mean())\n",
    "print('The average error rate(category 1) is', SVC_err_1.mean())\n",
    "print('The average MSE of the model is', SVC_MSE_VEC.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice here, we encounter in k=2, the prediction in SVM is always 0 which lead to our calculation of the error rate of category 1 problematic.To avoid the problem, I just erased this case, and get a average of only 3 fold for error rate of category 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (d) Compariosn\n",
    "\n",
    "According to the results of this case, the random forest has the lowest error rates and lowest MSE for both model. Thus I would say it is best fit for this dataset, SVM is the worst fitted model for the dataset, while Logit is in between. The reason for this I would assume is our feature variables has a mixture of categorical and continous feature. Potentially there are some outlier in the data, thus might heavily influence the performance of SVM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
