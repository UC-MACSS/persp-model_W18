{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "cmap1 = matplotlib.cm.get_cmap('summer')\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>dspl</th>\n",
       "      <th>hpwr</th>\n",
       "      <th>wgt</th>\n",
       "      <th>accl</th>\n",
       "      <th>yr</th>\n",
       "      <th>org</th>\n",
       "      <th>name</th>\n",
       "      <th>const</th>\n",
       "      <th>mpg_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl   dspl   hpwr   wgt  accl  yr  org                       name  \\\n",
       "0  18.0    8  307.0  130.0  3504  12.0  70    1  chevrolet chevelle malibu   \n",
       "1  15.0    8  350.0  165.0  3693  11.5  70    1          buick skylark 320   \n",
       "2  18.0    8  318.0  150.0  3436  11.0  70    1         plymouth satellite   \n",
       "3  16.0    8  304.0  150.0  3433  12.0  70    1              amc rebel sst   \n",
       "4  17.0    8  302.0  140.0  3449  10.5  70    1                ford torino   \n",
       "\n",
       "   const  mpg_high  \n",
       "0    1.0         0  \n",
       "1    1.0         0  \n",
       "2    1.0         0  \n",
       "3    1.0         0  \n",
       "4    1.0         0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autodf = pd.read_csv('Auto.csv', delimiter = ',', header = 0, \\\n",
    "                     names = ['mpg', 'cyl', 'dspl', 'hpwr', 'wgt', 'accl', 'yr', 'org', \n",
    "                              'name'], na_values = '?')\n",
    "autodf['hpwr'] = autodf['hpwr'].apply(pd.to_numeric, errors = 'coerce')\n",
    "mpg_median = autodf['mpg'].median()\n",
    "autodf['mpg_high'] = autodf['mpg'] >= mpg_median\n",
    "autodf['mpg_high'] = autodf['mpg_high'].astype(int)\n",
    "autodf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.213308\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>mpg_high</td>     <th>  No. Observations:  </th>  <td>   392</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   385</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 04 Mar 2018</td> <th>  Pseudo R-squ.:     </th>  <td>0.6923</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>22:20:23</td>     <th>  Log-Likelihood:    </th> <td> -83.617</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -271.71</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.654e-78</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>  <td>   -0.2029</td> <td>    0.402</td> <td>   -0.505</td> <td> 0.613</td> <td>   -0.990</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dspl</th> <td>   -0.0018</td> <td>    0.011</td> <td>   -0.167</td> <td> 0.867</td> <td>   -0.024</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hpwr</th> <td>   -0.0761</td> <td>    0.021</td> <td>   -3.643</td> <td> 0.000</td> <td>   -0.117</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wgt</th>  <td>   -0.0029</td> <td>    0.001</td> <td>   -3.047</td> <td> 0.002</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>accl</th> <td>   -0.2304</td> <td>    0.116</td> <td>   -1.982</td> <td> 0.047</td> <td>   -0.458</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr</th>   <td>    0.2637</td> <td>    0.043</td> <td>    6.182</td> <td> 0.000</td> <td>    0.180</td> <td>    0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>org</th>  <td>    0.2602</td> <td>    0.336</td> <td>    0.773</td> <td> 0.439</td> <td>   -0.399</td> <td>    0.920</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               mpg_high   No. Observations:                  392\n",
       "Model:                          Logit   Df Residuals:                      385\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Sun, 04 Mar 2018   Pseudo R-squ.:                  0.6923\n",
       "Time:                        22:20:23   Log-Likelihood:                -83.617\n",
       "converged:                       True   LL-Null:                       -271.71\n",
       "                                        LLR p-value:                 3.654e-78\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "cyl           -0.2029      0.402     -0.505      0.613      -0.990       0.584\n",
       "dspl          -0.0018      0.011     -0.167      0.867      -0.024       0.020\n",
       "hpwr          -0.0761      0.021     -3.643      0.000      -0.117      -0.035\n",
       "wgt           -0.0029      0.001     -3.047      0.002      -0.005      -0.001\n",
       "accl          -0.2304      0.116     -1.982      0.047      -0.458      -0.003\n",
       "yr             0.2637      0.043      6.182      0.000       0.180       0.347\n",
       "org            0.2602      0.336      0.773      0.439      -0.399       0.920\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogitModel1 = sm.Logit(endog = autodf['mpg_high'], exog = autodf[['cyl', 'dspl', 'hpwr',\\\n",
    "                                                  'wgt', 'accl', 'yr', 'org']], missing = 'drop')\n",
    "result1 = LogitModel1.fit(fit_intercept = True)\n",
    "result1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k index= 0\n",
      "MSE for test set 0  is 0.0918367346939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.92        55\n",
      "          1       0.87      0.93      0.90        43\n",
      "\n",
      "avg / total       0.91      0.91      0.91        98\n",
      "\n",
      "k index= 1\n",
      "MSE for test set 1  is 0.102040816327\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90        47\n",
      "          1       0.92      0.88      0.90        51\n",
      "\n",
      "avg / total       0.90      0.90      0.90        98\n",
      "\n",
      "k index= 2\n",
      "MSE for test set 2  is 0.132653061224\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86        45\n",
      "          1       0.88      0.87      0.88        53\n",
      "\n",
      "avg / total       0.87      0.87      0.87        98\n",
      "\n",
      "k index= 3\n",
      "MSE for test set 3  is 0.102040816327\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.84      0.89        49\n",
      "          1       0.85      0.96      0.90        49\n",
      "\n",
      "avg / total       0.90      0.90      0.90        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autodf.dropna(inplace = True)\n",
    "X = autodf[['const', 'cyl', 'dspl', 'hpwr','wgt', 'accl', 'yr', 'org']]\n",
    "Xvars = X.values\n",
    "y = autodf['mpg_high']\n",
    "yvals = y.values\n",
    "k = 4\n",
    "kf_log = KFold(n_splits=4, shuffle=True, random_state=15)\n",
    "\n",
    "kf_log.get_n_splits(Xvars)\n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf_log.split(Xvars):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print('k index=', k_ind)\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    LogReg = LogisticRegression(fit_intercept = True)\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred) ** 2).mean()\n",
    "    print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    k_ind += 1\n",
    "\n",
    "MSE_kf1 = MSE_vec_kf.mean()\n",
    "MSE_kf_std1 = MSE_vec_kf.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE k-fold= 0.107142857143 test estimate MSE standard err= 0.015306122449\n",
      "The error rate for j = 0 is: 0.09499999999999997\n",
      "The error rate for j = 1 is: 0.12\n"
     ]
    }
   ],
   "source": [
    "print('test estimate MSE k-fold=', MSE_kf1,\n",
    "      'test estimate MSE standard err=', MSE_kf_std1)\n",
    "print('The error rate for j = 0 is:', 1 - (0.94 + 0.88 + 0.85 + 0.95) / 4)\n",
    "print('The error rate for j = 1 is:', 1 - (0.87 + 0.92 + 0.88 + 0.85) / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Xb = autodf[['cyl', 'dspl', 'hpwr','wgt', 'accl', 'yr', 'org']]\n",
    "Xvarsb = Xb.values\n",
    "auto_tree = RandomForestClassifier(n_estimators=20, max_features=2, bootstrap=True,\n",
    "                           oob_score=True, random_state=25)\n",
    "\n",
    "auto_tree.fit(Xvarsb, yvals)\n",
    "y_oob = auto_tree.oob_decision_function_\n",
    "y_pred2 = []\n",
    "for item in y_oob: \n",
    "    y_pred2.append(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame({'ypred': y_pred2, 'yvals': yvals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.91      0.93       196\n",
      "          1       0.92      0.94      0.93       196\n",
      "\n",
      "avg / total       0.93      0.93      0.93       392\n",
      "\n",
      "MSE= 0.0714285714286\n",
      "MSE for class 0 is: 0.0578947368421\n",
      "MSE for class 1 is: 0.0841584158416\n"
     ]
    }
   ],
   "source": [
    "y_df['ypred'] = y_df['ypred'].apply(lambda x:1 if x>= 0.5 else 0)\n",
    "MSE2 = mean_squared_error(y_df['yvals'], y_df['ypred'])\n",
    "ypred_0 = y_df[y_df['ypred'] < 0.5]\n",
    "MSE_0 = mean_squared_error(ypred_0['yvals'], ypred_0['ypred'])\n",
    "ypred_1 = y_df[y_df['ypred'] >= 0.5]\n",
    "MSE_1 = mean_squared_error(ypred_1['yvals'], ypred_1['ypred'])\n",
    "print(classification_report(yvals, y_df['ypred']))\n",
    "print('MSE=', MSE2)\n",
    "print('MSE for class 0 is:', MSE_0)\n",
    "print('MSE for class 1 is:', MSE_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "C = 1.0  # SVM regularization parameter\n",
    "model_svm = svm.SVC(kernel='rbf', gamma=0.2, C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k index= 0\n",
      "MSE for test set 0  is 0.540816326531\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07        55\n",
      "          1       0.45      1.00      0.62        43\n",
      "\n",
      "avg / total       0.76      0.46      0.31        98\n",
      "\n",
      "k index= 1\n",
      "MSE for test set 1  is 0.520408163265\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      1.00      0.65        47\n",
      "          1       0.00      0.00      0.00        51\n",
      "\n",
      "avg / total       0.23      0.48      0.31        98\n",
      "\n",
      "k index= 2\n",
      "MSE for test set 2  is 0.520408163265\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      1.00      0.64        45\n",
      "          1       1.00      0.04      0.07        53\n",
      "\n",
      "avg / total       0.76      0.48      0.33        98\n",
      "\n",
      "k index= 3\n",
      "MSE for test set 3  is 0.448979591837\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      1.00      0.69        49\n",
      "          1       1.00      0.10      0.19        49\n",
      "\n",
      "avg / total       0.76      0.55      0.44        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kf_svm = KFold(n_splits=4, shuffle=True, random_state=15)\n",
    "\n",
    "kf_svm.get_n_splits(Xvarsb)\n",
    "SVM_error_0 = np.zeros(k)\n",
    "SVM_error_1 = np.zeros(k)\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf_svm.split(Xvars):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print('k index=', k_ind)\n",
    "    X_train, X_test = Xvarsb[train_index], Xvarsb[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    model_svm = svm.SVC(kernel='rbf', gamma=0.2, C=1.0)\n",
    "    model_svm.fit(X_train, y_train)\n",
    "    y_pred = model_svm.predict(X_test)\n",
    "    MSE_vec_kf[k_ind] = (y_test != y_pred).mean()\n",
    "    print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    k_ind += 1\n",
    "\n",
    "MSE_kf3 = MSE_vec_kf.mean()\n",
    "MSE_kf_std3 = MSE_vec_kf.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate for class 0 is: 0.38\n",
      "The error rate for class 1 is: 0.38749999999999996\n",
      "The average MSE for the dataset is: 0.507653061224 std = 0.0348846794163\n"
     ]
    }
   ],
   "source": [
    "print(\"The error rate for class 0 is:\", 1 - (1.00 + 0.48 + 0.47 + 0.53)/4)\n",
    "print(\"The error rate for class 1 is:\", 1 - (0.45 + 0.00 + 1.00 + 1.00)/4)\n",
    "print(\"The average MSE for the dataset is:\", MSE_kf3, \"std =\", MSE_kf_std3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Regressor: MSE = 0.10714285714285715, error rate for class 0 is: 0.09499999999999997, error rate for class 1 is : 0.12\n",
      "Random Forest Classifier: MSE = 0.07142857142857142, error rate for class 0 is: 0.05789473684210526, error rate for class 1 is : 0.08415841584158416\n",
      "SVC: MSE = 0.5076530612244898, error rate for class 0 is: 0.38, error rate for class 1 is : 0.38749999999999996\n"
     ]
    }
   ],
   "source": [
    "print(\"Logit Regressor: MSE = {}, \\\n",
    "error rate for class 0 is: {}, \\\n",
    "error rate for class 1 is : {}\".format(MSE_kf1, 0.09499999999999997, 0.12))\n",
    "print(\"Random Forest Classifier: MSE = {}, \\\n",
    "error rate for class 0 is: {}, \\\n",
    "error rate for class 1 is : {}\".format(MSE2, MSE_0, MSE_1))\n",
    "print(\"SVC: MSE = {}, \\\n",
    "error rate for class 0 is: {}, \\\n",
    "error rate for class 1 is : {}\".format(MSE_kf3, 0.38, 0.38749999999999996))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross val score for Random Forest Classifier is: [ 0.70408163  0.87755102  0.89795918  0.76530612]\n",
      "cross val score for SVC is: [ 0.5         0.51020408  0.51020408  0.5       ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print('cross val score for Random Forest Classifier is:', cross_val_score(auto_tree, X, y, cv = 4))\n",
    "print('cross val score for SVC is:', cross_val_score(model_svm, X, y, cv = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing MSE, we could see that Random Forest Classifier has the smallest MSE(0.07143), SVC has the largest MSE(0.50765), and the Logit Regressor in between(0.10714). We can see that Random Forest has the lowest error rates for both class 0 and class 1 (mpg_high = 0 and mpg_high = 1). That there is a mixture of categorical and continuous features might be the reason why Random Forest Classifier is better here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
