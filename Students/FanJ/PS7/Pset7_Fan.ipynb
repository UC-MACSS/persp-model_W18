{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS7\n",
    "Jingwen Fan\n",
    "\n",
    "## 1a).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pylab import rcParams\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('Auto.csv', na_values='?')\n",
    "auto.dropna(inplace=True)\n",
    "auto.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['horsepower'] = auto['horsepower'].convert_objects(convert_numeric = True)\n",
    "auto['mpg_high'] = auto['mpg'].apply(lambda x: 1 if x >= auto['mpg'].median() else 0).astype('category')\n",
    "X = auto[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "              'acceleration', 'year', 'origin']].values\n",
    "y= auto['mpg_high'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When k index= 0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.942     0.891     0.916        55\n",
      "          1      0.870     0.930     0.899        43\n",
      "\n",
      "avg / total      0.910     0.908     0.908        98\n",
      "\n",
      "error rate (category 0) is 0.057692307692307696 , error rate (category 1) is 0.13043478260869565\n",
      "The MSE of the model is 0.09183673469387756\n",
      "\n",
      "When k index= 1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.878     0.915     0.896        47\n",
      "          1      0.918     0.882     0.900        51\n",
      "\n",
      "avg / total      0.899     0.898     0.898        98\n",
      "\n",
      "error rate (category 0) is 0.12244897959183673 , error rate (category 1) is 0.08163265306122448\n",
      "The MSE of the model is 0.10204081632653061\n",
      "\n",
      "When k index= 2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.848     0.867     0.857        45\n",
      "          1      0.885     0.868     0.876        53\n",
      "\n",
      "avg / total      0.868     0.867     0.867        98\n",
      "\n",
      "error rate (category 0) is 0.15217391304347827 , error rate (category 1) is 0.11538461538461539\n",
      "The MSE of the model is 0.1326530612244898\n",
      "\n",
      "When k index= 3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.953     0.837     0.891        49\n",
      "          1      0.855     0.959     0.904        49\n",
      "\n",
      "avg / total      0.904     0.898     0.898        98\n",
      "\n",
      "error rate (category 0) is 0.046511627906976744 , error rate (category 1) is 0.14545454545454545\n",
      "The MSE of the model is 0.10204081632653061\n",
      "\n",
      "\n",
      "k-fold resuts:\n",
      "The average error rate (category 0) is 0.09470670705864986 , std is 0.044059462275132855\n",
      "The average error rate (category 1) is 0.11822664912727025 , std is 0.023651609698841367\n",
      "The average MSE of the model is 0.10714285714285715 , std is 0.015306122448979593\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits=k, random_state=15, shuffle=True)\n",
    "kf.get_n_splits(Xvars)\n",
    "LogGeneral_error_0 = np.zeros(k)\n",
    "LogGeneral_error_1 = np.zeros(k)\n",
    "LogGeneral_MSE = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('When k index=', k_ind)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    LogReg = LogisticRegression(fit_intercept=True)\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    error = y_test != y_pred\n",
    "    error_all_class = error.mean()\n",
    "    error_0 = ((y_pred == 0) * error).sum() / (y_pred == 0).sum() \n",
    "    error_1 = ((y_pred == 1) * error).sum() / (y_pred == 1).sum() \n",
    "    LogGeneral_error_0[k_ind] = error_0\n",
    "    LogGeneral_error_1[k_ind] = error_1\n",
    "    LogGeneral_MSE[k_ind] = error_all_class\n",
    "    print('\\n',classification_report(y_test, y_pred, digits=3))\n",
    "    print('error rate (category 0) is', error_0,\n",
    "          ', error rate (category 1) is', error_1)\n",
    "    print('The MSE of the model is', error_all_class)\n",
    "    print()\n",
    "    k_ind += 1\n",
    "\n",
    "\n",
    "print('\\nk-fold resuts:')\n",
    "print('The average error rate (category 0) is', LogGeneral_error_0.mean(), ', std is', LogGeneral_error_0.std())\n",
    "print('The average error rate (category 1) is', LogGeneral_error_1.mean(), ', std is', LogGeneral_error_1.std())\n",
    "print('The average MSE of the model is', LogGeneral_MSE.mean(), ', std is', LogGeneral_MSE.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=True, random_state=25, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20, max_features=2, bootstrap=True,\n",
    "                                  oob_score=True, random_state=25)\n",
    "forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 0.07142857142857142\n",
      "MSE for low category (0) =  0.05789473684210526\n",
      "MSE for high category (1) =  0.08415841584158416\n"
     ]
    }
   ],
   "source": [
    "forest.score(X, y)\n",
    "MSE_df = pd.DataFrame({'ypred': forest.oob_decision_function_.T[1], 'y': y})\n",
    "MSE_df['ypred'] = MSE_df['ypred'].apply(lambda x: 1 if int(x>=0.5) else 0)\n",
    "MSE = mean_squared_error(MSE_df['y'], MSE_df['ypred'])\n",
    "MSE_0 = mean_squared_error(MSE_df['y'].where(MSE_df.ypred<0.5).dropna(), MSE_df['ypred'].where(MSE_df.ypred<0.5).dropna())\n",
    "MSE_1 = mean_squared_error(MSE_df['y'].where(MSE_df.ypred>0.5).dropna(), MSE_df['ypred'].where(MSE_df.ypred>0.5).dropna())\n",
    "print('MSE=', MSE)\n",
    "print('MSE for low category (0) = ', MSE_0)\n",
    "print('MSE for high category (1) = ', MSE_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When k index= 0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      1.000     0.036     0.070        55\n",
      "          1      0.448     1.000     0.619        43\n",
      "\n",
      "avg / total      0.758     0.459     0.311        98\n",
      "\n",
      "error rate (category 0) is 0.0\n",
      "error rate (category 1) is 0.5520833333333334\n",
      "The MSE of the model is 0.5408163265306123\n",
      "\n",
      "When k index= 1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.480     1.000     0.648        47\n",
      "          1      0.000     0.000     0.000        51\n",
      "\n",
      "avg / total      0.230     0.480     0.311        98\n",
      "\n",
      "error rate (category 0) is 0.5204081632653061\n",
      "error rate (category 1): NA (all predicted values are 0)\n",
      "The MSE of the model is 0.5204081632653061\n",
      "\n",
      "When k index= 2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.469     1.000     0.638        45\n",
      "          1      1.000     0.038     0.073        53\n",
      "\n",
      "avg / total      0.756     0.480     0.332        98\n",
      "\n",
      "error rate (category 0) is 0.53125\n",
      "error rate (category 1) is 0.0\n",
      "The MSE of the model is 0.5204081632653061\n",
      "\n",
      "When k index= 3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.527     1.000     0.690        49\n",
      "          1      1.000     0.102     0.185        49\n",
      "\n",
      "avg / total      0.763     0.551     0.438        98\n",
      "\n",
      "error rate (category 0) is 0.4731182795698925\n",
      "error rate (category 1) is 0.0\n",
      "The MSE of the model is 0.4489795918367347\n",
      "\n",
      "\n",
      "k-fold resuts:\n",
      "The average error rate (category 0) is 0.38119411070879966 , std is 0.22116528050309686\n",
      "The average error rate (category 1) is 0.1840277777777778 , std is 0.26025457918671546\n",
      "The average MSE of the model is 0.5076530612244898 , std is 0.03488467941626875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, random_state=15, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "SVMGeneral_error_0 = np.zeros(k)\n",
    "SVMGeneral_error_1 = np.zeros(k)\n",
    "SVMGeneral_MSE = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('When k index=', k_ind)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    svc = svm.SVC(kernel='rbf', gamma = 0.2, C=1)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    error = y_test != y_pred\n",
    "    error_all_class = error.mean()\n",
    "    error_0 = ((y_pred == 0) * error).sum() / (y_pred == 0).sum() \n",
    "    error_1 = ((y_pred == 1) * error).sum() / (y_pred == 1).sum()\n",
    "    SVMGeneral_error_0[k_ind] = error_0\n",
    "    SVMGeneral_error_1[k_ind] = error_1\n",
    "    SVMGeneral_MSE[k_ind] = error_all_class\n",
    "\n",
    "    print('\\n',classification_report(y_test, y_pred, digits=3))\n",
    "    if (y_pred == 0).sum() != 0:\n",
    "        print('error rate (category 0) is', error_0)\n",
    "    else:\n",
    "        print('error rate (category 0): NA (all predicted values are 1)')\n",
    "    \n",
    "    if (y_pred == 1).sum() != 0:\n",
    "        print('error rate (category 1) is', error_1)\n",
    "    else:\n",
    "        print('error rate (category 1): NA (all predicted values are 0)')\n",
    "    \n",
    "    print('The MSE of the model is', error_all_class)\n",
    "    print()\n",
    "    k_ind += 1\n",
    "\n",
    "\n",
    "print('\\nk-fold resuts:')\n",
    "SVMGeneral_error_0 = SVMGeneral_error_0[~np.isnan(SVMGeneral_error_0)]\n",
    "print('The average error rate (category 0) is', SVMGeneral_error_0.mean(), ', std is', SVMGeneral_error_0.std())\n",
    "SVMGeneral_error_1 = SVMGeneral_error_1[~np.isnan(SVMGeneral_error_1)]\n",
    "print('The average error rate (category 1) is', SVMGeneral_error_1.mean(), ', std is', SVMGeneral_error_1.std())\n",
    "print('The average MSE of the model is', SVMGeneral_MSE.mean(), ', std is', SVMGeneral_MSE.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is the best model with the lowest error rate and MSE, while SVM has the worst."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
