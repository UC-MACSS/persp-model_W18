{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Zhiyu FU **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,mean_squared_error, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv(\"Auto.csv\", na_values = \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[:,\"mpg_high\"] = auto.mpg>=auto.mpg.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto.loc[:,\"cylinders\":\"origin\"].values\n",
    "y = auto.mpg_high.astype(\"int\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_log = KFold(n_splits=4, shuffle = True, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = np.copy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.92        55\n",
      "          1       0.87      0.93      0.90        43\n",
      "\n",
      "avg / total       0.91      0.91      0.91        98\n",
      "\n",
      "MSE = 0.09183673469387756\n",
      "The error rate for class 0 is 0.057692307692307696\n",
      "The error rate for class 1 is 0.13043478260869565\n",
      "k = 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90        47\n",
      "          1       0.92      0.88      0.90        51\n",
      "\n",
      "avg / total       0.90      0.90      0.90        98\n",
      "\n",
      "MSE = 0.10204081632653061\n",
      "The error rate for class 0 is 0.12244897959183673\n",
      "The error rate for class 1 is 0.08163265306122448\n",
      "k = 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86        45\n",
      "          1       0.88      0.87      0.88        53\n",
      "\n",
      "avg / total       0.87      0.87      0.87        98\n",
      "\n",
      "MSE = 0.1326530612244898\n",
      "The error rate for class 0 is 0.15217391304347827\n",
      "The error rate for class 1 is 0.11538461538461539\n",
      "k = 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.84      0.89        49\n",
      "          1       0.85      0.96      0.90        49\n",
      "\n",
      "avg / total       0.90      0.90      0.90        98\n",
      "\n",
      "MSE = 0.10204081632653061\n",
      "The error rate for class 0 is 0.046511627906976744\n",
      "The error rate for class 1 is 0.14545454545454545\n"
     ]
    }
   ],
   "source": [
    "ind = 1\n",
    "log_error = np.empty((2, 4))\n",
    "for train_index, test_index in kf_log.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(\"k = {}\".format(ind))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"MSE = {}\".format(mean_squared_error(y_test, y_pred)))\n",
    "    error = y_pred != y_test\n",
    "    error_0 = ((y_pred == 0) * error).sum() / (y_pred == 0).sum() \n",
    "    error_1 = ((y_pred == 1) * error).sum() / (y_pred == 1).sum() \n",
    "    print(\"The error rate for class 0 is {}\".format(error_0))\n",
    "    print(\"The error rate for class 1 is {}\".format(error_1))\n",
    "    log_error[:, ind-1] = (error_0, error_1)\n",
    "    ind += 1\n",
    "    y_est[test_index] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision, recall, f1-score and MSE for each test set are as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.88      0.89       196\n",
      "          1       0.88      0.91      0.89       196\n",
      "\n",
      "avg / total       0.89      0.89      0.89       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all test sets, for mpg_high == 0, the precision is 0.91, the recall is 0.88, and the f1-score is 0.89; for mpg_high == 1, the precision is 0.88, the recall is 0.91, and the f1-score is 0.89.\n",
    "On Average, the precision, recall, and f1-score are all 0.89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10714285714285714"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, y_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE across all test sets are 0.107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error rate for class 0 and class are as follows, respectively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.09470671,  0.11822665])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The average error rate for class 0 and class are as follows, respectively.\")\n",
    "log_error.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_features=2, n_estimators=20, bootstrap=True, oob_score=True, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X, y)\n",
    "y_est2 = forest.oob_decision_function_\n",
    "y_est2 = (y_est2[:,0] <= y_est2[:,1]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.91      0.93       196\n",
      "          1       0.92      0.94      0.93       196\n",
      "\n",
      "avg / total       0.93      0.93      0.93       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_est2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mpg_high == 0, the precision is 0.94, the recall is 0.91, and the f1-score is 0.93; for mpg_high == 1, the precision is 0.92, the recall is 0.94, and the f1-score is 0.93.\n",
    "On Average, the precision, recall, and f1-score are all 0.93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071428571428571425"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, y_est2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE across all test sets are 0.071."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y_est2 != y\n",
    "error_0 = ((y_est2 == 0) * error).sum() / (y_est2 == 0).sum() \n",
    "error_1 = ((y_est2 == 1) * error).sum() / (y_est2 == 1).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate 0 category is 0.0578947368421\n",
      "The error rate for the 1 category is 0.0841584158416\n"
     ]
    }
   ],
   "source": [
    "print(\"The error rate 0 category is\", error_0)\n",
    "print(\"The error rate for the 1 category is\", error_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SVC(kernel = \"rbf\", C = 1, gamma = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "log_error = np.empty((2, 4))\n",
    "y_est3 = np.zeros(y.shape)\n",
    "ind = 0\n",
    "kf_svm = KFold(n_splits=4, shuffle=True, random_state=15)\n",
    "for train_index, test_index in kf_svm.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    s.fit(X_train, y_train)\n",
    "    y_pred = s.predict(X_test)\n",
    "    error = y_pred != y_test\n",
    "    error_0 = ((y_pred == 0) * error).sum() / (y_pred == 0).sum() \n",
    "    error_1 = ((y_pred == 1) * error).sum() / (y_pred == 1).sum() \n",
    "    log_error[:, ind] = (error_0, error_1)\n",
    "    ind += 1\n",
    "    y_est3[test_index] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.73      0.59       196\n",
      "          1       0.49      0.26      0.33       196\n",
      "\n",
      "avg / total       0.49      0.49      0.46       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_est3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mpg_high == 0, the precision is 0.49, the recall is 0.73, and the f1-score is 0.59; for mpg_high == 1, the precision is 0.49, the recall is 0.26, and the f1-score is 0.33.\n",
    "On Average, the precision and recall are 0.49 and f1-score is 0.46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50765306122448983"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, y_est3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE across all test sets are 0.5076."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error rate for class 0 and class 1 are as follows, respectively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.38119411,  0.18402778])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The average error rate for class 0 and class 1 are as follows, respectively.\")\n",
    "np.nanmean(log_error, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest classifier has the best predictive power. It outperforms other two in all measure of prediction (precision, recall, f1 score, error rate, and mean square error)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
