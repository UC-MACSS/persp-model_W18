{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kanyao Han         \n",
    "MACS 30100\n",
    "\n",
    "\n",
    "# PS 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\python\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pylab import rcParams\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      5\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('Auto.csv', na_values='?')\n",
    "auto.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = auto.dropna()\n",
    "auto.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto.drop(['name'], 1)\n",
    "auto['horsepower'] = auto['horsepower'].convert_objects(convert_numeric = True)\n",
    "auto['mpg_high'] = auto['mpg'].apply(lambda x: 1 if x >= auto['mpg'].median() else 0).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvars = auto[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "              'acceleration', 'year', 'origin']].values\n",
    "yvals = auto['mpg_high'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When k index= 0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.942     0.891     0.916        55\n",
      "          1      0.870     0.930     0.899        43\n",
      "\n",
      "avg / total      0.910     0.908     0.908        98\n",
      "\n",
      "error rate (category 0) is 0.057692307692307696 , error rate (category 1) is 0.13043478260869565\n",
      "The MSE of the model is 0.09183673469387756\n",
      "\n",
      "When k index= 1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.878     0.915     0.896        47\n",
      "          1      0.918     0.882     0.900        51\n",
      "\n",
      "avg / total      0.899     0.898     0.898        98\n",
      "\n",
      "error rate (category 0) is 0.12244897959183673 , error rate (category 1) is 0.08163265306122448\n",
      "The MSE of the model is 0.10204081632653061\n",
      "\n",
      "When k index= 2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.848     0.867     0.857        45\n",
      "          1      0.885     0.868     0.876        53\n",
      "\n",
      "avg / total      0.868     0.867     0.867        98\n",
      "\n",
      "error rate (category 0) is 0.15217391304347827 , error rate (category 1) is 0.11538461538461539\n",
      "The MSE of the model is 0.1326530612244898\n",
      "\n",
      "When k index= 3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.953     0.837     0.891        49\n",
      "          1      0.855     0.959     0.904        49\n",
      "\n",
      "avg / total      0.904     0.898     0.898        98\n",
      "\n",
      "error rate (category 0) is 0.046511627906976744 , error rate (category 1) is 0.14545454545454545\n",
      "The MSE of the model is 0.10204081632653061\n",
      "\n",
      "\n",
      "k-fold resuts:\n",
      "The average error rate (category 0) is 0.09470670705864986 , std is 0.044059462275132855\n",
      "The average error rate (category 1) is 0.11822664912727025 , std is 0.023651609698841367\n",
      "The average MSE of the model is 0.10714285714285715 , std is 0.015306122448979593\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits=k, random_state=15, shuffle=True)\n",
    "kf.get_n_splits(Xvars)\n",
    "LogGeneral_error_0 = np.zeros(k)\n",
    "LogGeneral_error_1 = np.zeros(k)\n",
    "LogGeneral_MSE = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    print('When k index=', k_ind)\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    LogReg = LogisticRegression(fit_intercept=True)\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    error = y_test != y_pred\n",
    "    error_all_class = error.mean()\n",
    "    error_0 = ((y_pred == 0) * error).sum() / (y_pred == 0).sum() \n",
    "    error_1 = ((y_pred == 1) * error).sum() / (y_pred == 1).sum() \n",
    "    LogGeneral_error_0[k_ind] = error_0\n",
    "    LogGeneral_error_1[k_ind] = error_1\n",
    "    LogGeneral_MSE[k_ind] = error_all_class\n",
    "    print('\\n',classification_report(y_test, y_pred, digits=3))\n",
    "    print('error rate (category 0) is', error_0,\n",
    "          ', error rate (category 1) is', error_1)\n",
    "    print('The MSE of the model is', error_all_class)\n",
    "    print()\n",
    "    k_ind += 1\n",
    "\n",
    "\n",
    "print('\\nk-fold resuts:')\n",
    "print('The average error rate (category 0) is', LogGeneral_error_0.mean(), ', std is', LogGeneral_error_0.std())\n",
    "print('The average error rate (category 1) is', LogGeneral_error_1.mean(), ', std is', LogGeneral_error_1.std())\n",
    "print('The average MSE of the model is', LogGeneral_MSE.mean(), ', std is', LogGeneral_MSE.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=20, max_features=2, bootstrap=True,\n",
    "                           oob_score=True, random_state=25)\n",
    "\n",
    "RF.fit(Xvars, yvals)\n",
    "Decision = RF.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Coding Technique</span>\n",
    "<span style=\"color:red\"> Since RandomForestClassifier does not have the attribute \".oob_prediction\", I use \"oob decision function\" to calculate the OOB prediction. It is worth noting that when we use the \"oob decision function\", we must transform some decimal values as 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get oob prediction\n",
    "oob_prediction = Decision.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_RF = pd.DataFrame({'pred' : oob_prediction, 'yvals': yvals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform it as binary category\n",
    "MSE_RF['pred'] = MSE_RF['pred'].apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_all = mean_squared_error(MSE_RF['yvals'], MSE_RF['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_RF_0 = MSE_RF[MSE_RF['pred'] < 0.5]\n",
    "MSE_0 = mean_squared_error(MSE_RF_0['yvals'], MSE_RF_0['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate for category 0 is 0.05789473684210526\n",
      "The error rate for category 1 is 0.08415841584158416\n",
      "The MSE of the model is 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "MSE_RF_1 = MSE_RF[MSE_RF['pred'] >= 0.5]\n",
    "MSE_1 = mean_squared_error(MSE_RF_1['yvals'], MSE_RF_1['pred'])\n",
    "print('The error rate for category 0 is', MSE_0)\n",
    "print('The error rate for category 1 is', MSE_1)\n",
    "print('The MSE of the model is', MSE_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When k index= 0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      1.000     0.036     0.070        55\n",
      "          1      0.448     1.000     0.619        43\n",
      "\n",
      "avg / total      0.758     0.459     0.311        98\n",
      "\n",
      "error rate (category 0) is 0.0\n",
      "error rate (category 1) is 0.5520833333333334\n",
      "The MSE of the model is 0.5408163265306123\n",
      "\n",
      "When k index= 1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.480     1.000     0.648        47\n",
      "          1      0.000     0.000     0.000        51\n",
      "\n",
      "avg / total      0.230     0.480     0.311        98\n",
      "\n",
      "error rate (category 0) is 0.5204081632653061\n",
      "error rate (category 1): NA (all predicted values are 0)\n",
      "The MSE of the model is 0.5204081632653061\n",
      "\n",
      "When k index= 2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.469     1.000     0.638        45\n",
      "          1      1.000     0.038     0.073        53\n",
      "\n",
      "avg / total      0.756     0.480     0.332        98\n",
      "\n",
      "error rate (category 0) is 0.53125\n",
      "error rate (category 1) is 0.0\n",
      "The MSE of the model is 0.5204081632653061\n",
      "\n",
      "When k index= 3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0      0.527     1.000     0.690        49\n",
      "          1      1.000     0.102     0.185        49\n",
      "\n",
      "avg / total      0.763     0.551     0.438        98\n",
      "\n",
      "error rate (category 0) is 0.4731182795698925\n",
      "error rate (category 1) is 0.0\n",
      "The MSE of the model is 0.4489795918367347\n",
      "\n",
      "\n",
      "k-fold resuts:\n",
      "The average error rate (category 0) is 0.38119411070879966 , std is 0.22116528050309686\n",
      "The average error rate (category 1) is 0.1840277777777778 , std is 0.26025457918671546\n",
      "The average MSE of the model is 0.5076530612244898 , std is 0.03488467941626875\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits=k, random_state=15, shuffle=True)\n",
    "kf.get_n_splits(Xvars)\n",
    "SVMGeneral_error_0 = np.zeros(k)\n",
    "SVMGeneral_error_1 = np.zeros(k)\n",
    "SVMGeneral_MSE = np.zeros(k)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    print('When k index=', k_ind)\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    svc = svm.SVC(kernel='rbf', gamma = 0.2, C=1)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    error = y_test != y_pred\n",
    "    error_all_class = error.mean()\n",
    "    error_0 = ((y_pred == 0) * error).sum() / (y_pred == 0).sum() \n",
    "    error_1 = ((y_pred == 1) * error).sum() / (y_pred == 1).sum()\n",
    "    SVMGeneral_error_0[k_ind] = error_0\n",
    "    SVMGeneral_error_1[k_ind] = error_1\n",
    "    SVMGeneral_MSE[k_ind] = error_all_class\n",
    "\n",
    "    print('\\n',classification_report(y_test, y_pred, digits=3))\n",
    "    if (y_pred == 0).sum() != 0:\n",
    "        print('error rate (category 0) is', error_0)\n",
    "    else:\n",
    "        print('error rate (category 0): NA (all predicted values are 1)')\n",
    "    \n",
    "    if (y_pred == 1).sum() != 0:\n",
    "        print('error rate (category 1) is', error_1)\n",
    "    else:\n",
    "        print('error rate (category 1): NA (all predicted values are 0)')\n",
    "    \n",
    "    print('The MSE of the model is', error_all_class)\n",
    "    print()\n",
    "    k_ind += 1\n",
    "\n",
    "\n",
    "print('\\nk-fold resuts:')\n",
    "SVMGeneral_error_0 = SVMGeneral_error_0[~np.isnan(SVMGeneral_error_0)]\n",
    "print('The average error rate (category 0) is', SVMGeneral_error_0.mean(), ', std is', SVMGeneral_error_0.std())\n",
    "SVMGeneral_error_1 = SVMGeneral_error_1[~np.isnan(SVMGeneral_error_1)]\n",
    "print('The average error rate (category 1) is', SVMGeneral_error_1.mean(), ', std is', SVMGeneral_error_1.std())\n",
    "print('The average MSE of the model is', SVMGeneral_MSE.mean(), ', std is', SVMGeneral_MSE.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Coding Technique</span>\n",
    "<span style=\"color:red\"> Since this SVM model is very bad, sometimes all predicted values for each category will be 1 or 0. It will bring value of **nan** when we caculate error rates for category 1 or 0. Therefore, I write an \"if statement\" in K-fold, and remove the value of **nan** (if any) when I caclulate the average error rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Comparison        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Logit</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model MSE</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.507653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Category 0</td>\n",
       "      <td>0.094707</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>0.381194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Category 1</td>\n",
       "      <td>0.118227</td>\n",
       "      <td>0.084158</td>\n",
       "      <td>0.184028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index     Logit        RF       SVM\n",
       "0   Model MSE  0.107143  0.071429  0.507653\n",
       "1  Category 0  0.094707  0.057895  0.381194\n",
       "2  Category 1  0.118227  0.084158  0.184028"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logit_MSE = [LogGeneral_MSE.mean(), LogGeneral_error_0.mean(), LogGeneral_error_1.mean()]\n",
    "RF_MSE = [MSE_all, MSE_0, MSE_1]\n",
    "SVM_MSE = [SVMGeneral_MSE.mean(), SVMGeneral_error_0.mean(), SVMGeneral_error_1.mean()]\n",
    "Index = [\"Model MSE\", \"Category 0\", \"Category 1\"]\n",
    "Com = pd.DataFrame({'Logit':Logit_MSE, 'RF':RF_MSE, 'SVM':SVM_MSE},\n",
    "                       index = Index)\n",
    "Com.reset_index(inplace=True)\n",
    "Com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Error Rate/MSE')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFPCAYAAADZdBBWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a3ad5f29b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(Com['index'], Com['SVM'], label='SVM')\n",
    "plt.bar(Com['index'], Com['Logit'], label='Logit')\n",
    "plt.bar(Com['index'], Com['RF'], label='RF')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Comparison', fontsize = 15)\n",
    "plt.xlabel('MSE Type')\n",
    "plt.ylabel(\"Error Rate/MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> According to the results from the three models, the random forest model has the lowest error rates for category 0, category 1 and all categories. **It is seemingly the best predictive model.** On the contrary, SVM model has the incredibly high error rates for all parts.\n",
    "    \n",
    "<span style=\"color:blue\"> However, we must note that the MSEs in the random forest model are computed by OOB prediction and we don't use traditional cross-validation. OOB MSEs are based on bootstrap aggregation so that the MSEs computed in this way would typically be lower than those in traditional cross-validation. Since the OOB MSEs are usually strongly positively correlated with the cross-validation MSEs, we can use them to select models if and only if all selections are based on OOB MSEs. Therefore, it is not suitable to directly compare cross-validation MSEs and OOB MSEs, especially in the situation where the OOB MSEs of one model are not much larger than the cross-validation MSEs of another model. Therefore, the random forest model is probably, but not necessairly, better than the logistic model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
