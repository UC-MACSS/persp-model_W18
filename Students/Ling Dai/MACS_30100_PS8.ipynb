{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACS 30100\n",
    "### Ling Dai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingdai/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "sb.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cultivar   alco  malic   ash   alk  magn  tot_phen  flav  nonfl_phen  \\\n",
       "0         1  14.23   1.71  2.43  15.6   127      2.80  3.06        0.28   \n",
       "1         1  13.20   1.78  2.14  11.2   100      2.65  2.76        0.26   \n",
       "2         1  13.16   2.36  2.67  18.6   101      2.80  3.24        0.30   \n",
       "3         1  14.37   1.95  2.50  16.8   113      3.85  3.49        0.24   \n",
       "4         1  13.24   2.59  2.87  21.0   118      2.80  2.69        0.39   \n",
       "\n",
       "   proanth  color_int   hue  OD280rat  proline  \n",
       "0     2.29       5.64  1.04      3.92     1065  \n",
       "1     1.28       4.38  1.05      3.40     1050  \n",
       "2     2.81       5.68  1.03      3.17     1185  \n",
       "3     2.18       7.80  0.86      3.45     1480  \n",
       "4     1.82       4.32  1.04      2.93      735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "strongdrink = pd.read_csv('strongdrink.txt', header = 0)\n",
    "strongdrink.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAFgCAYAAABKY1XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPJOfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 401.625x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sb.lmplot('alco','color_int', fit_reg=False, data=strongdrink, hue = 'cultivar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingdai/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(strongdrink[['alco', 'malic', 'tot_phen', 'color_int']])\n",
    "y = strongdrink['cultivar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingdai/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/lingdai/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>MSE</th>\n",
       "      <th>penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>8.50</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>8.47</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>6.20</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>6.21</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>4.04</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C       MSE penalty\n",
       "7320  8.50  0.068182      l2\n",
       "7308  8.47  0.068182      l2\n",
       "2440  6.20  0.068182      l1\n",
       "2444  6.21  0.068182      l1\n",
       "5536  4.04  0.068182      l2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "kf_mlog = KFold(n_splits=4, shuffle=True, random_state=22)\n",
    "penalty_list = []\n",
    "C_list = []\n",
    "MSE_list = []\n",
    "\n",
    "for penalty in ['l1', 'l2']:\n",
    "    for C in np.arange(0.1,10,0.01):\n",
    "        for train, test in kf_mlog.split(X):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "            reg = LR(multi_class='multinomial',solver='saga',\n",
    "                     penalty = 'l1',C = C).fit(X_train, y_train)\n",
    "            y_pred = reg.predict(X_test)\n",
    "            penalty_list.append(penalty)\n",
    "            C_list.append(C)\n",
    "            MSE_list.append(((y_test - y_pred) ** 2).mean())\n",
    "\n",
    "MSE_df = pd.DataFrame({'penalty':penalty_list,\n",
    "                       'C':C_list,\n",
    "                       'MSE':MSE_list})\n",
    "\n",
    "MSE_df = MSE_df.sort_values(by=['MSE'])\n",
    "MSE_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because only 'saga' solver supports both 'l1' and 'l2' penalty among all multinomial solvers, I used 'saga' as the solver in 1(b). I tested both 'l1' and 'l2' for penalty, and all values from 0.1 to 10 (with step size = 0.1) for C. A minimun MSE of 0.068182 was achieved by several models wit different combinations of parameters: penalty = 'l2', C = 6.94; penalty = 'l2', C = 6.37; penalty = 'l1', C = 4.54; penalty = 'l1', C = 8.75, penalty = 'l1', C = 4.55."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvals = strongdrink[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "yvals = strongdrink['cultivar'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.068182</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.068182</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.068182</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.068182</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.068182</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MSE  max_depth  min_samples_leaf  n_estimator\n",
       "239  0.068182          5                 8          250\n",
       "92   0.068182          3                12          100\n",
       "197  0.068182          3                11          200\n",
       "68   0.068182          4                 7          100\n",
       "87   0.068182          3                11          100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators_list = []\n",
    "min_samples_leaf_list = []\n",
    "max_depth_list = []\n",
    "MSE_list = []\n",
    "\n",
    "for n_estimators in range(50,300,50):\n",
    "    for min_samples_leaf in range(5,16):\n",
    "        for max_depth in range(1,6):\n",
    "            RF = RandomForestClassifier(n_estimators = n_estimators,\n",
    "                                        min_samples_leaf = min_samples_leaf,\n",
    "                                        max_depth = max_depth, bootstrap=True, \n",
    "                                        oob_score=True, random_state=22)\n",
    "            RF.fit(Xvals, yvals)\n",
    "            n_estimators_list.append(n_estimators)\n",
    "            max_depth_list.append(max_depth)\n",
    "            min_samples_leaf_list.append(min_samples_leaf)\n",
    "            MSE_list.append(1 - RF.oob_score_)\n",
    "\n",
    "MSE_df = pd.DataFrame({'n_estimator':n_estimators_list,\n",
    "                       'max_depth':max_depth_list,\n",
    "                       'min_samples_leaf':min_samples_leaf_list,\n",
    "                       'MSE':MSE_list})\n",
    "\n",
    "MSE_df = MSE_df.sort_values(by=['MSE'])\n",
    "MSE_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random forest classifier, I tried all values between 50 and 300 (step size = 50) for n_estimators, all values from 5 to 15 (step size = 1) for min_samples_leaf, and all values from 1 to 5 (step size = 1) for depth. A minimun MSE of 0.068182 was achieved by several models wit different combinations of parameters: max_depth = 5, min_samples_leaf = 8, n_estimator = 250; max_depth = 3, min_samples_leaf = 12, n_estimator = 100; max_depth = 3, min_samples_leaf = 11, n_estimator = 200; max_depth = 3, min_samples_leaf = 11, n_estimator = 100..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>cost</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MSE  cost  gamma\n",
       "0     0.045455  0.25   0.05\n",
       "2740  0.045455  1.50   1.75\n",
       "2744  0.045455  1.75   1.75\n",
       "2748  0.045455  2.00   1.75\n",
       "2752  0.045455  2.25   1.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "gamma_list = []\n",
    "cost_list = []\n",
    "MSE_list = []\n",
    "\n",
    "for gamma in np.arange(0.05,2.05,0.05):\n",
    "    for cost in np.arange(0.25,5.25,0.25):\n",
    "        for train, test in kf_mlog.split(X):\n",
    "            X_train = X.iloc[train]\n",
    "            y_train = y.iloc[train]\n",
    "            X_test = X.iloc[test]\n",
    "            y_test = y.iloc[test]\n",
    "            svc = SVC(kernel='rbf', gamma = gamma, C=C)\n",
    "            svc.fit(X_train, y_train)\n",
    "            y_pred = svc.predict(X_test)\n",
    "            gamma_list.append(gamma)\n",
    "            cost_list.append(cost)\n",
    "            MSE_list.append(((y_test - y_pred) ** 2).mean())\n",
    "\n",
    "MSE_df = pd.DataFrame({'gamma':gamma_list,\n",
    "                       'cost':cost_list,\n",
    "                       'MSE':MSE_list})\n",
    "\n",
    "MSE_df = MSE_df.sort_values(by=['MSE'])\n",
    "MSE_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random SVC, I tried all values between 0.05 and 2.0 (step size = 0.05) for gamma, all values from 0.25 to 5.0 (step size = 0.25) for cost. A minimun MSE of 0.068182 was achieved by several models wit different combinations of parameters: gamma = 1.75, cost = 1.50; gamma = 1.75, cost = 1.75; gamma = 1.75, cost = 2.00; gamma = 1.75, cost = 2.25..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>activation</th>\n",
       "      <th>alpha</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.25</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.20</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.35</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.90</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.50</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSE activation  alpha  hidden_layer_sizes\n",
       "1788  0.0       tanh   0.25                 400\n",
       "2540  0.0       relu   0.20                 300\n",
       "2668  0.0       relu   0.35                 400\n",
       "3100  0.0       relu   0.90                 300\n",
       "2792  0.0       relu   0.50                 450"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "alpha_list = []\n",
    "hidden_layer_sizes_list = []\n",
    "MSE_list = []\n",
    "activation_list = []\n",
    "\n",
    "for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "    for alpha in np.arange(0.05,1.05,0.05):\n",
    "        for hidden_layer_sizes in range(50,550,50):\n",
    "            for train, test in kf_mlog.split(X):\n",
    "                X_train = X.iloc[train]\n",
    "                y_train = y.iloc[train]\n",
    "                X_test = X.iloc[test]\n",
    "                y_test = y.iloc[test]\n",
    "                mlp = MLPClassifier(activation=activation, solver='lbfgs',\n",
    "                                    alpha=alpha, hidden_layer_sizes = hidden_layer_sizes)\n",
    "                mlp.fit(X_train, y_train)\n",
    "                y_pred = mlp.predict(X_test)\n",
    "                activation_list.append(activation)\n",
    "                alpha_list.append(alpha)\n",
    "                hidden_layer_sizes_list.append(hidden_layer_sizes)\n",
    "                MSE_list.append(((y_test - y_pred) ** 2).mean())\n",
    "\n",
    "MSE_df = pd.DataFrame({'activation':activation_list,\n",
    "                       'alpha':alpha_list,\n",
    "                       'hidden_layer_sizes':hidden_layer_sizes_list,\n",
    "                       'MSE':MSE_list})\n",
    "\n",
    "MSE_df = MSE_df.sort_values(by=['MSE'])\n",
    "MSE_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MLP, I tried four different kinds of activation functions, namely 'identity', 'logistic', 'tanh', and 'relu'. I also tested all values from 0.05 to 1.0 (step size = 0.05) for alpha, and all values from 50 to 500 (step size = 50). A minimun MSE of 0 was achieved by several models wit different combinations of parameters: alpha = 0.20, activation = 'relu', hidden_layer_sizes = 400; alpha = 0.20, activation = 'relu', hidden_layer_sizes = 350..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the minimun test MSE achieved by the models above, the MLP classifier was the best predictor of cultivar, because several MLP model with different combinations of parameter settings achieved MSE of 0.0, which means all the predictions were correct for these models. The second best predictor in this case is SVM, with a minimun MSE of 0.0045455. Multinomial logistic regression and random forest seemed to have similar accuracy on predicting cultivar: both of them had a minimun MSE of 0.068182.\n",
    "\n",
    "However, we can't complete rule out the possibility that the lower MSEs achieved by MLP classifier and SVM were in part due to the choice of step sizes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
