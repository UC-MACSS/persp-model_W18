{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laurence Warner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. Inspiration drawn from: Beth Bailey, Shuting Chen, Alexander Tyan, Fu Zhiyu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cultivar   alco  malic   ash   alk  magn  tot_phen  flav  nonfl_phen  \\\n",
       "0         1  14.23   1.71  2.43  15.6   127      2.80  3.06        0.28   \n",
       "1         1  13.20   1.78  2.14  11.2   100      2.65  2.76        0.26   \n",
       "2         1  13.16   2.36  2.67  18.6   101      2.80  3.24        0.30   \n",
       "3         1  14.37   1.95  2.50  16.8   113      3.85  3.49        0.24   \n",
       "4         1  13.24   2.59  2.87  21.0   118      2.80  2.69        0.39   \n",
       "\n",
       "   proanth  color_int   hue  OD280rat  proline  \n",
       "0     2.29       5.64  1.04      3.92     1065  \n",
       "1     1.28       4.38  1.05      3.40     1050  \n",
       "2     2.81       5.68  1.03      3.17     1185  \n",
       "3     2.18       7.80  0.86      3.45     1480  \n",
       "4     1.82       4.32  1.04      2.93      735  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/strongdrink.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x1a09d180f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = data.groupby(by = \"cultivar\")\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5WAYhmHkYcrBMAzDyOP/A0ZjGvMoAyDbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a09bb9320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, group in groups:\n",
    "    plt.scatter(group.alco, group.color_int, label = name)\n",
    "plt.title(\"Scatterplot of Color Intensity against Alcohol by Cultivar\")\n",
    "plt.xlabel(\"Alcohol\")\n",
    "plt.ylabel(\"Color Intensity\")\n",
    "leg = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "y = data[['cultivar']].values\n",
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_c(c): \n",
    "    mse_splits = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        log_reg = LogisticRegression(multi_class='multinomial', \n",
    "                                     fit_intercept=True, solver='newton-cg', C=c)\n",
    "        log_reg.fit(X_train, y_train)\n",
    "        y_pred = log_reg.predict(X_test)\n",
    "        mse = ((y_test != y_pred) ** 2).mean()\n",
    "\n",
    "        mse_splits.append(mse)\n",
    "\n",
    "        mse_splits\n",
    "\n",
    "        mse = np.mean(mse_splits) \n",
    "        mse\n",
    "\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_c = np.arange?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_c = np.arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01,  0.02,  0.03,  0.04,  0.05,  0.06,  0.07,  0.08,  0.09,\n",
       "        0.1 ,  0.11,  0.12,  0.13,  0.14,  0.15,  0.16,  0.17,  0.18,\n",
       "        0.19,  0.2 ,  0.21,  0.22,  0.23,  0.24,  0.25,  0.26,  0.27,\n",
       "        0.28,  0.29,  0.3 ,  0.31,  0.32,  0.33,  0.34,  0.35,  0.36,\n",
       "        0.37,  0.38,  0.39,  0.4 ,  0.41,  0.42,  0.43,  0.44,  0.45,\n",
       "        0.46,  0.47,  0.48,  0.49,  0.5 ,  0.51,  0.52,  0.53,  0.54,\n",
       "        0.55,  0.56,  0.57,  0.58,  0.59,  0.6 ,  0.61,  0.62,  0.63,\n",
       "        0.64,  0.65,  0.66,  0.67,  0.68,  0.69,  0.7 ,  0.71,  0.72,\n",
       "        0.73,  0.74,  0.75,  0.76,  0.77,  0.78,  0.79,  0.8 ,  0.81,\n",
       "        0.82,  0.83,  0.84,  0.85,  0.86,  0.87,  0.88,  0.89,  0.9 ,\n",
       "        0.91,  0.92,  0.93,  0.94,  0.95,  0.96,  0.97,  0.98])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_c = np.arange(0.01, 0.99, 0.01)\n",
    "cand_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 0.01, mse = 0.13636363636363635\n",
      "c = 0.02, mse = 0.06818181818181818\n",
      "c = 0.03, mse = 0.045454545454545456\n",
      "c = 0.12, mse = 0.022727272727272728\n"
     ]
    }
   ],
   "source": [
    "m = 100\n",
    "for c in cand_c:\n",
    "    mse = mse_c(c)\n",
    "    s = \"c = {}, mse = {}\".format(c, mse)\n",
    "    if mse < m:\n",
    "        print(s)\n",
    "        m = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of values in my range, c = 0.12 is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest possible MSE is: 0.0227\n"
     ]
    }
   ],
   "source": [
    "print(\"lowest possible MSE is:\", round(mse_c(0.12), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand_forest(n_estimators, max_depth, min_samples_leaf):\n",
    "    rand_forest = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                        max_depth=max_depth,\n",
    "                                        min_samples_leaf=min_samples_leaf,\n",
    "                                        max_features='sqrt', bootstrap=True,\n",
    "                                        oob_score=True, random_state=22)\n",
    "    rand_forest.fit(X, y)\n",
    "\n",
    "    oob = rand_forest.oob_score_\n",
    "    return oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_est = np.arange(50, 150, 10)\n",
    "depth = np.arange(2, 10)\n",
    "samples = np.arange(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 50, d = 2, s= 2, mse = 0.9090909090909091\n",
      "n = 50, d = 2, s= 7, mse = 0.9034090909090909\n",
      "n = 80, d = 2, s= 8, mse = 0.8977272727272727\n"
     ]
    }
   ],
   "source": [
    "min_mse = 100000\n",
    "for n in n_est:\n",
    "    for d in depth:\n",
    "        for s in samples:\n",
    "            mse = rand_forest(n, d, s)\n",
    "            if mse < min_mse:\n",
    "                min_mse = mse\n",
    "                s = \"n = {}, d = {}, s= {}, mse = {}\".format(n, d, s, mse)\n",
    "                print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum is bottom one listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "clf_svm = KFold(n_splits=k, random_state=22, shuffle=True)\n",
    "clf_svm.get_n_splits(X)\n",
    "MSE = np.zeros(k)\n",
    "MSE_C = pd.DataFrame({\"C\" : np.zeros(50),\n",
    "                      \"G\" : np.zeros(50),\n",
    "                      \"MSE\" : np.zeros(50)})\n",
    "MSE_SVM = MSE_C[:0]\n",
    "\n",
    "for g in range(50):\n",
    "    for c in range(50):\n",
    "        k_ind = int(0)\n",
    "        for train_index, test_index in clf_svm.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            svc = svm.SVC(kernel='rbf', gamma = (g/20 + 0.05),\n",
    "                          C=c/20 + 0.05)\n",
    "            svc.fit(X_train, y_train)\n",
    "            y_pred = svc.predict(X_test)\n",
    "            error = y_test != y_pred\n",
    "            MSE[k_ind] = error.mean()\n",
    "            k_ind += 1\n",
    "        MSE_C['C'][c] = c/20 + 0.05\n",
    "        MSE_C['G'][c] = g/20 + 0.05\n",
    "        MSE_C['MSE'][c] =  MSE.mean()\n",
    "    MSE_SVM = pd.concat([MSE_SVM, MSE_C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>G</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1.15</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.051136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.95</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.051136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C     G       MSE\n",
       "1618  0.95  1.65  0.045455\n",
       "1669  1.00  1.70  0.045455\n",
       "1668  0.95  1.70  0.045455\n",
       "1622  1.15  1.65  0.051136\n",
       "188   1.95  0.20  0.051136"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_SVM.index = range(len(MSE_SVM))\n",
    "MSE_SVM.sort_values(['MSE']).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min: c = 0.95, G = 1.65. Gives an MSE of 0.04546."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurencewarner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/laurencewarner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/laurencewarner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/laurencewarner/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "clf_mlp = KFold(n_splits=k, random_state=22, shuffle=True)\n",
    "clf_mlp.get_n_splits(X)\n",
    "MSE = np.zeros(k)\n",
    "activ = np.array(['identity', 'logistic', 'tanh', 'relu'])\n",
    "MSE_al = pd.DataFrame({'activation' : np.zeros(10),\n",
    "                       'hidden layer' : np.zeros(10),\n",
    "                       'alpha' : np.zeros(10),\n",
    "                       'MSE':np.zeros(10)})\n",
    "MSE_mlp = MSE_al[:0]\n",
    "\n",
    "for ac in range(4):\n",
    "    for h in range(8):\n",
    "        for al in range(10):\n",
    "            k_ind = int(0)\n",
    "            for train_index, test_index in clf_mlp.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                mlp = MLPClassifier(activation=activ[ac], solver='lbfgs',\n",
    "                                    alpha=(al/20 + 0.05), \n",
    "                                    hidden_layer_sizes = ((50 * (h + 1)),))\n",
    "                mlp.fit(X_train, y_train)\n",
    "                y_pred = mlp.predict(X_test)\n",
    "                error = y_test != y_pred\n",
    "                MSE[k_ind] = error.mean()\n",
    "                k_ind += 1\n",
    "            MSE_al['activation'][al] = activ[ac]\n",
    "            MSE_al['hidden layer'][al] = 50 * (h + 1)\n",
    "            MSE_al['alpha'][al] = al/20 + 0.05\n",
    "            MSE_al['MSE'][al] =  MSE.mean()\n",
    "        MSE_mlp = pd.concat([MSE_mlp, MSE_al])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>activation</th>\n",
       "      <th>alpha</th>\n",
       "      <th>hidden layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.034091</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.039773</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.30</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.039773</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.50</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.039773</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.45</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.50</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.10</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.30</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.45</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.20</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.05</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.35</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.05</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.20</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.40</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.35</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.20</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.45</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.25</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.35</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.10</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.05</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.051136</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.45</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MSE activation  alpha  hidden layer\n",
       "249  0.034091       relu   0.50          50.0\n",
       "295  0.039773       relu   0.30         300.0\n",
       "269  0.039773       relu   0.50         150.0\n",
       "308  0.039773       relu   0.45         350.0\n",
       "319  0.045455       relu   0.50         400.0\n",
       "281  0.045455       relu   0.10         250.0\n",
       "292  0.045455       relu   0.15         300.0\n",
       "195  0.045455       tanh   0.30         200.0\n",
       "298  0.045455       relu   0.45         300.0\n",
       "303  0.045455       relu   0.20         350.0\n",
       "220  0.045455       tanh   0.05         350.0\n",
       "164  0.045455       tanh   0.25          50.0\n",
       "256  0.045455       relu   0.35         100.0\n",
       "120  0.045455   logistic   0.05         250.0\n",
       "283  0.051136       relu   0.20         250.0\n",
       "197  0.051136       tanh   0.40         200.0\n",
       "196  0.051136       tanh   0.35         200.0\n",
       "163  0.051136       tanh   0.20          50.0\n",
       "318  0.051136       relu   0.45         400.0\n",
       "194  0.051136       tanh   0.25         200.0\n",
       "276  0.051136       relu   0.35         200.0\n",
       "221  0.051136       tanh   0.10         350.0\n",
       "274  0.051136       relu   0.25         200.0\n",
       "80   0.051136   logistic   0.05          50.0\n",
       "188  0.051136       tanh   0.45         150.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_mlp.index = range(len(MSE_mlp))\n",
    "MSE_mlp.sort_values(['MSE']).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best when activation = relu, alpha = 0.5, hidden layer = 50. Gives MSE: 0.0341"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4, not 3 models. \n",
    "Best is: logistic regression because it has lowest MSE. I think it is because there is not a huge amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 4)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 176 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be noted that my Random Forest MSE is 2 orders of magnitude larger: so probably not correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
