{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set #7\n",
    "## MACS 30100 Dr. Evans\n",
    "## By Cooper Nederhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classifier \"horse\" race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "path = \"../../../ProblemSets/PS7\"\n",
    "file = \"Auto.csv\"\n",
    "\n",
    "df = pd.read_csv(path+\"/\"+file,na_values=\"?\")\n",
    "df['mpg_high'] = (df['mpg'] >= df['mpg'].median()).astype(int)\n",
    "df['const'] = 1\n",
    "df.dropna(how='any', inplace=True)\n",
    "x_var_names = [x for x in df.columns if 'mpg' not in x and x != 'name']\n",
    "Xvars = df[x_var_names].values\n",
    "yvals = df['mpg_high'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Fit a logistic model including a constant. Do k-folds validation with k=4 folds. Report MSE as average MSE across k=4 test sets. Report error rates for each category of mpg_high as the average error rate across k=4 test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:461: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/optimize/linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "logit_mse = []\n",
    "logit_predicted = np.array([])\n",
    "logit_observed = np.array([])\n",
    "\n",
    "k = 4\n",
    "k_ind = 0\n",
    "logit_kf = KFold(n_splits=k, shuffle=True, random_state=10) \n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "\n",
    "for train_index, test_index in logit_kf.split(Xvars):\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    logit = LogisticRegression(solver='newton-cg')    \n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = logit.predict(X_test)\n",
    "    logit_mse.append( ((y_test - y_pred) ** 2).mean()  )\n",
    "    \n",
    "    # Append results\n",
    "    logit_predicted = np.append(logit_predicted, y_pred)\n",
    "    logit_observed = np.append(logit_observed, y_test)\n",
    "    \n",
    "    k_ind += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit avg MSE across k = 4 is:  0.1020408163265306\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.88      0.90       196\n",
      "        1.0       0.88      0.92      0.90       196\n",
      "\n",
      "avg / total       0.90      0.90      0.90       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_avg_mse = np.mean(logit_mse)\n",
    "logit_classification = classification_report(logit_observed, logit_predicted)\n",
    "print(\"Logit avg MSE across k = 4 is: \", logit_avg_mse)\n",
    "\n",
    "# Run classification report on our result sets\n",
    "print(logit_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Fit RandomForestClassifier with max_features=2 out of the 7 possible features. Set n_estimators=20, boostrap=True, oob_score=True, and random_state=25. Report MSE as the MSE from the .oob_prediction object and report the error rates for each category of mpg_high from .oob_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=20, n_jobs=1, oob_score=True, random_state=25,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_alt_names = [x for x in x_var_names if x != 'const']\n",
    "Xvars_no_const = df[x_alt_names].values\n",
    "\n",
    "rand_forest = RandomForestRegressor(n_estimators=20, max_features=2, bootstrap=True,\n",
    "                                  oob_score=True, random_state=25)\n",
    "rand_forest.fit(Xvars_no_const, yvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE is:  0.058269344926686846\n"
     ]
    }
   ],
   "source": [
    "rand_forest.score(Xvars_no_const, yvals)\n",
    "rand_forest_pred = rand_for.oob_prediction_\n",
    "rand_forest_mse = mean_squared_error(yvals, rand_forest_pred)\n",
    "print(\"Random Forest MSE is: \", rand_forest_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Fit a SVM with radial basis function kernel (kernel = 'rbf'), C=1, and gamma=0.2. Repeat k-fold cross validation as in part a. Report MSE and error rates across k=4 test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "svm_mse = []\n",
    "svm_predicted = np.array([])\n",
    "svm_observed = np.array([])\n",
    "\n",
    "k = 4\n",
    "k_ind = 0\n",
    "svm_kf = KFold(n_splits=k, shuffle=True, random_state=10) \n",
    "\n",
    "MSE_svm_kf = np.zeros(k)\n",
    "\n",
    "for train_index, test_index in svm_kf.split(Xvars_no_const):\n",
    "    X_train, X_test = Xvars_no_const[train_index], Xvars_no_const[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    svm_auto = svm.SVC(kernel='rbf', C=1, gamma=0.2)    \n",
    "    svm_auto.fit(Xvars_no_const, yvals)\n",
    "    \n",
    "    y_pred = svm_auto.predict(X_test)\n",
    "    svm_mse.append( ((y_test - y_pred) ** 2).mean()  )\n",
    "    \n",
    "    # Append results\n",
    "    svm_predicted = np.append(svm_predicted, y_pred)\n",
    "    svm_observed = np.append(svm_observed, y_test)\n",
    "    \n",
    "    k_ind += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM avg MSE across k = 4 is:  0.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       196\n",
      "        1.0       1.00      1.00      1.00       196\n",
      "\n",
      "avg / total       1.00      1.00      1.00       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_avg_mse = np.mean(svm_mse)\n",
    "svm_classification = classification_report(svm_observed, svm_predicted)\n",
    "print(\"SVM avg MSE across k = 4 is: \", svm_avg_mse)\n",
    "\n",
    "# Run classification report on our result sets\n",
    "print(svm_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Which is the best predictor of mpg_high? Why?\n",
    "Based on the out-of-sample predictive power of each model, the SVM is the best predictor. It has 100% precision (0% error) while the logit has 9% and 12% error and the random forest has non-perfect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
