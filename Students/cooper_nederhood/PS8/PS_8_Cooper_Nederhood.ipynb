{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set #8\n",
    "# MACS 30100 Dr. Evans\n",
    "## By Cooper Nederhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cultivar   alco  malic   ash   alk  magn  tot_phen  flav  nonfl_phen  \\\n",
       "0         1  14.23   1.71  2.43  15.6   127      2.80  3.06        0.28   \n",
       "1         1  13.20   1.78  2.14  11.2   100      2.65  2.76        0.26   \n",
       "2         1  13.16   2.36  2.67  18.6   101      2.80  3.24        0.30   \n",
       "3         1  14.37   1.95  2.50  16.8   113      3.85  3.49        0.24   \n",
       "4         1  13.24   2.59  2.87  21.0   118      2.80  2.69        0.39   \n",
       "\n",
       "   proanth  color_int   hue  OD280rat  proline  \n",
       "0     2.29       5.64  1.04      3.92     1065  \n",
       "1     1.28       4.38  1.05      3.40     1050  \n",
       "2     2.81       5.68  1.03      3.17     1185  \n",
       "3     2.18       7.80  0.86      3.45     1480  \n",
       "4     1.82       4.32  1.04      2.93      735  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "path = \"../../../ProblemSets/PS8/data/\"\n",
    "file = \"strongdrink.txt\"\n",
    "df = pd.read_csv(path+file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1a): Scatterplot of alco and color_int for each of the 3 cultivars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f216fcaa208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is_1 = df.cultivar == 1\n",
    "is_2 = df.cultivar == 2\n",
    "is_3 = df.cultivar == 3\n",
    "\n",
    "plt.scatter(df[is_1].alco, df[is_1].color_int, color='r', label=\"Cult 1\")\n",
    "plt.scatter(df[is_2].alco, df[is_2].color_int, color='b', label=\"Cult 2\")\n",
    "plt.scatter(df[is_3].alco, df[is_3].color_int, color='g', label=\"Cult 3\")\n",
    "plt.xlabel(\"Alcohol\")\n",
    "plt.ylabel(\"Color intensity\")\n",
    "plt.title(\"Alcohol and color intensity by cultivar\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_variable_names = ['alco', 'malic', 'tot_phen', 'color_int']\n",
    "y_name = ['cultivar']\n",
    "Xvars = df[x_variable_names].values\n",
    "yvals = df[y_name].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1b): Uses sklearn to fit multinomial logit. Use k-fold cross validation to estimate MSE. Play with param values of penalty and C to get lowest possible k-fold MSE. Report the MSE and param results from this procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits = k, random_state=22, shuffle=True)\n",
    "\n",
    "mse_logit = np.zeros(k)\n",
    "mse_list = []\n",
    "\n",
    "# iterate over possible values of C\n",
    "for c_test in np.linspace(.01, 5, 100):\n",
    "    \n",
    "    k_ind = 0\n",
    "    c_mse_splits = []\n",
    "    for train_index, test_index in kf.split(Xvars):\n",
    "        \n",
    "        X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "        y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "        \n",
    "        log_reg = LogisticRegression(multi_class='multinomial', \n",
    "                                     fit_intercept=True, solver='newton-cg', C=c_test)\n",
    "        log_reg.fit(X_train, y_train)\n",
    "        y_pred = log_reg.predict(X_test)\n",
    "        mse = ((y_test != y_pred) ** 2).mean()\n",
    "        \n",
    "        c_mse_splits.append(mse)\n",
    "    assert len(c_mse_splits) == 4\n",
    "    \n",
    "    c_mse = np.mean(c_mse_splits)    \n",
    "    results = (c_mse, c_test)\n",
    "    \n",
    "    mse_list.append( results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6411415289256198, 0.01),\n",
       " (0.6450154958677686, 0.06040404040404041),\n",
       " (0.6472107438016529, 0.11080808080808081),\n",
       " (0.6474690082644629, 0.6652525252525253),\n",
       " (0.6474690082644629, 0.7156565656565658),\n",
       " (0.6474690082644629, 0.7660606060606061),\n",
       " (0.6474690082644629, 0.8164646464646466),\n",
       " (0.6474690082644629, 0.866868686868687),\n",
       " (0.6474690082644629, 0.9172727272727274),\n",
       " (0.6474690082644629, 0.9676767676767678)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_list.sort()\n",
    "mse_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default value for C=1, so I run the k-folds analysis from .01 to 5. The output MSE is not very sensitive to C but I find a min MSE of .6411 at C=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1c): Use sklearn to fit the model in part b using a Random Forest classifier with bootstrap = True, oob_score=True, and random_state=22. Use OOB cross-validation to get MSE. Play with param values of n_estimators, max_depth, min_sample_leaf. Report the MSE and param values from this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_est=10, min_sample=1, max_d=1\n",
      "n_est=10, min_sample=1, max_d=2\n",
      "n_est=10, min_sample=1, max_d=3\n",
      "n_est=10, min_sample=1, max_d=4\n",
      "n_est=10, min_sample=1, max_d=5\n",
      "n_est=10, min_sample=1, max_d=6\n",
      "n_est=10, min_sample=1, max_d=7\n",
      "n_est=10, min_sample=1, max_d=8\n",
      "n_est=10, min_sample=1, max_d=9\n",
      "n_est=10, min_sample=2, max_d=1\n",
      "n_est=10, min_sample=2, max_d=2\n",
      "n_est=10, min_sample=2, max_d=3\n",
      "n_est=10, min_sample=2, max_d=4\n",
      "n_est=10, min_sample=2, max_d=5\n",
      "n_est=10, min_sample=2, max_d=6\n",
      "n_est=10, min_sample=2, max_d=7\n",
      "n_est=10, min_sample=2, max_d=8\n",
      "n_est=10, min_sample=2, max_d=9\n",
      "n_est=10, min_sample=3, max_d=1\n",
      "n_est=10, min_sample=3, max_d=2\n",
      "n_est=10, min_sample=3, max_d=3\n",
      "n_est=10, min_sample=3, max_d=4\n",
      "n_est=10, min_sample=3, max_d=5\n",
      "n_est=10, min_sample=3, max_d=6\n",
      "n_est=10, min_sample=3, max_d=7\n",
      "n_est=10, min_sample=3, max_d=8\n",
      "n_est=10, min_sample=3, max_d=9\n",
      "n_est=10, min_sample=4, max_d=1\n",
      "n_est=10, min_sample=4, max_d=2\n",
      "n_est=10, min_sample=4, max_d=3\n",
      "n_est=10, min_sample=4, max_d=4\n",
      "n_est=10, min_sample=4, max_d=5\n",
      "n_est=10, min_sample=4, max_d=6\n",
      "n_est=10, min_sample=4, max_d=7\n",
      "n_est=10, min_sample=4, max_d=8\n",
      "n_est=10, min_sample=4, max_d=9\n",
      "n_est=10, min_sample=5, max_d=1\n",
      "n_est=10, min_sample=5, max_d=2\n",
      "n_est=10, min_sample=5, max_d=3\n",
      "n_est=10, min_sample=5, max_d=4\n",
      "n_est=10, min_sample=5, max_d=5\n",
      "n_est=10, min_sample=5, max_d=6\n",
      "n_est=10, min_sample=5, max_d=7\n",
      "n_est=10, min_sample=5, max_d=8\n",
      "n_est=10, min_sample=5, max_d=9\n",
      "n_est=10, min_sample=6, max_d=1\n",
      "n_est=10, min_sample=6, max_d=2\n",
      "n_est=10, min_sample=6, max_d=3\n",
      "n_est=10, min_sample=6, max_d=4\n",
      "n_est=10, min_sample=6, max_d=5\n",
      "n_est=10, min_sample=6, max_d=6\n",
      "n_est=10, min_sample=6, max_d=7\n",
      "n_est=10, min_sample=6, max_d=8\n",
      "n_est=10, min_sample=6, max_d=9\n",
      "n_est=10, min_sample=7, max_d=1\n",
      "n_est=10, min_sample=7, max_d=2\n",
      "n_est=10, min_sample=7, max_d=3\n",
      "n_est=10, min_sample=7, max_d=4\n",
      "n_est=10, min_sample=7, max_d=5\n",
      "n_est=10, min_sample=7, max_d=6\n",
      "n_est=10, min_sample=7, max_d=7\n",
      "n_est=10, min_sample=7, max_d=8\n",
      "n_est=10, min_sample=7, max_d=9\n",
      "n_est=10, min_sample=8, max_d=1\n",
      "n_est=10, min_sample=8, max_d=2\n",
      "n_est=10, min_sample=8, max_d=3\n",
      "n_est=10, min_sample=8, max_d=4\n",
      "n_est=10, min_sample=8, max_d=5\n",
      "n_est=10, min_sample=8, max_d=6\n",
      "n_est=10, min_sample=8, max_d=7\n",
      "n_est=10, min_sample=8, max_d=8\n",
      "n_est=10, min_sample=8, max_d=9\n",
      "n_est=10, min_sample=9, max_d=1\n",
      "n_est=10, min_sample=9, max_d=2\n",
      "n_est=10, min_sample=9, max_d=3\n",
      "n_est=10, min_sample=9, max_d=4\n",
      "n_est=10, min_sample=9, max_d=5\n",
      "n_est=10, min_sample=9, max_d=6\n",
      "n_est=10, min_sample=9, max_d=7\n",
      "n_est=10, min_sample=9, max_d=8\n",
      "n_est=10, min_sample=9, max_d=9\n",
      "n_est=35, min_sample=1, max_d=1\n",
      "n_est=35, min_sample=1, max_d=2\n",
      "n_est=35, min_sample=1, max_d=3\n",
      "n_est=35, min_sample=1, max_d=4\n",
      "n_est=35, min_sample=1, max_d=5\n",
      "n_est=35, min_sample=1, max_d=6\n",
      "n_est=35, min_sample=1, max_d=7\n",
      "n_est=35, min_sample=1, max_d=8\n",
      "n_est=35, min_sample=1, max_d=9\n",
      "n_est=35, min_sample=2, max_d=1\n",
      "n_est=35, min_sample=2, max_d=2\n",
      "n_est=35, min_sample=2, max_d=3\n",
      "n_est=35, min_sample=2, max_d=4\n",
      "n_est=35, min_sample=2, max_d=5\n",
      "n_est=35, min_sample=2, max_d=6\n",
      "n_est=35, min_sample=2, max_d=7\n",
      "n_est=35, min_sample=2, max_d=8\n",
      "n_est=35, min_sample=2, max_d=9\n",
      "n_est=35, min_sample=3, max_d=1\n",
      "n_est=35, min_sample=3, max_d=2\n",
      "n_est=35, min_sample=3, max_d=3\n",
      "n_est=35, min_sample=3, max_d=4\n",
      "n_est=35, min_sample=3, max_d=5\n",
      "n_est=35, min_sample=3, max_d=6\n",
      "n_est=35, min_sample=3, max_d=7\n",
      "n_est=35, min_sample=3, max_d=8\n",
      "n_est=35, min_sample=3, max_d=9\n",
      "n_est=35, min_sample=4, max_d=1\n",
      "n_est=35, min_sample=4, max_d=2\n",
      "n_est=35, min_sample=4, max_d=3\n",
      "n_est=35, min_sample=4, max_d=4\n",
      "n_est=35, min_sample=4, max_d=5\n",
      "n_est=35, min_sample=4, max_d=6\n",
      "n_est=35, min_sample=4, max_d=7\n",
      "n_est=35, min_sample=4, max_d=8\n",
      "n_est=35, min_sample=4, max_d=9\n",
      "n_est=35, min_sample=5, max_d=1\n",
      "n_est=35, min_sample=5, max_d=2\n",
      "n_est=35, min_sample=5, max_d=3\n",
      "n_est=35, min_sample=5, max_d=4\n",
      "n_est=35, min_sample=5, max_d=5\n",
      "n_est=35, min_sample=5, max_d=6\n",
      "n_est=35, min_sample=5, max_d=7\n",
      "n_est=35, min_sample=5, max_d=8\n",
      "n_est=35, min_sample=5, max_d=9\n",
      "n_est=35, min_sample=6, max_d=1\n",
      "n_est=35, min_sample=6, max_d=2\n",
      "n_est=35, min_sample=6, max_d=3\n",
      "n_est=35, min_sample=6, max_d=4\n",
      "n_est=35, min_sample=6, max_d=5\n",
      "n_est=35, min_sample=6, max_d=6\n",
      "n_est=35, min_sample=6, max_d=7\n",
      "n_est=35, min_sample=6, max_d=8\n",
      "n_est=35, min_sample=6, max_d=9\n",
      "n_est=35, min_sample=7, max_d=1\n",
      "n_est=35, min_sample=7, max_d=2\n",
      "n_est=35, min_sample=7, max_d=3\n",
      "n_est=35, min_sample=7, max_d=4\n",
      "n_est=35, min_sample=7, max_d=5\n",
      "n_est=35, min_sample=7, max_d=6\n",
      "n_est=35, min_sample=7, max_d=7\n",
      "n_est=35, min_sample=7, max_d=8\n",
      "n_est=35, min_sample=7, max_d=9\n",
      "n_est=35, min_sample=8, max_d=1\n",
      "n_est=35, min_sample=8, max_d=2\n",
      "n_est=35, min_sample=8, max_d=3\n",
      "n_est=35, min_sample=8, max_d=4\n",
      "n_est=35, min_sample=8, max_d=5\n",
      "n_est=35, min_sample=8, max_d=6\n",
      "n_est=35, min_sample=8, max_d=7\n",
      "n_est=35, min_sample=8, max_d=8\n",
      "n_est=35, min_sample=8, max_d=9\n",
      "n_est=35, min_sample=9, max_d=1\n",
      "n_est=35, min_sample=9, max_d=2\n",
      "n_est=35, min_sample=9, max_d=3\n",
      "n_est=35, min_sample=9, max_d=4\n",
      "n_est=35, min_sample=9, max_d=5\n",
      "n_est=35, min_sample=9, max_d=6\n",
      "n_est=35, min_sample=9, max_d=7\n",
      "n_est=35, min_sample=9, max_d=8\n",
      "n_est=35, min_sample=9, max_d=9\n",
      "n_est=60, min_sample=1, max_d=1\n",
      "n_est=60, min_sample=1, max_d=2\n",
      "n_est=60, min_sample=1, max_d=3\n",
      "n_est=60, min_sample=1, max_d=4\n",
      "n_est=60, min_sample=1, max_d=5\n",
      "n_est=60, min_sample=1, max_d=6\n",
      "n_est=60, min_sample=1, max_d=7\n",
      "n_est=60, min_sample=1, max_d=8\n",
      "n_est=60, min_sample=1, max_d=9\n",
      "n_est=60, min_sample=2, max_d=1\n",
      "n_est=60, min_sample=2, max_d=2\n",
      "n_est=60, min_sample=2, max_d=3\n",
      "n_est=60, min_sample=2, max_d=4\n",
      "n_est=60, min_sample=2, max_d=5\n",
      "n_est=60, min_sample=2, max_d=6\n",
      "n_est=60, min_sample=2, max_d=7\n",
      "n_est=60, min_sample=2, max_d=8\n",
      "n_est=60, min_sample=2, max_d=9\n",
      "n_est=60, min_sample=3, max_d=1\n",
      "n_est=60, min_sample=3, max_d=2\n",
      "n_est=60, min_sample=3, max_d=3\n",
      "n_est=60, min_sample=3, max_d=4\n",
      "n_est=60, min_sample=3, max_d=5\n",
      "n_est=60, min_sample=3, max_d=6\n",
      "n_est=60, min_sample=3, max_d=7\n",
      "n_est=60, min_sample=3, max_d=8\n",
      "n_est=60, min_sample=3, max_d=9\n",
      "n_est=60, min_sample=4, max_d=1\n",
      "n_est=60, min_sample=4, max_d=2\n",
      "n_est=60, min_sample=4, max_d=3\n",
      "n_est=60, min_sample=4, max_d=4\n",
      "n_est=60, min_sample=4, max_d=5\n",
      "n_est=60, min_sample=4, max_d=6\n",
      "n_est=60, min_sample=4, max_d=7\n",
      "n_est=60, min_sample=4, max_d=8\n",
      "n_est=60, min_sample=4, max_d=9\n",
      "n_est=60, min_sample=5, max_d=1\n",
      "n_est=60, min_sample=5, max_d=2\n",
      "n_est=60, min_sample=5, max_d=3\n",
      "n_est=60, min_sample=5, max_d=4\n",
      "n_est=60, min_sample=5, max_d=5\n",
      "n_est=60, min_sample=5, max_d=6\n",
      "n_est=60, min_sample=5, max_d=7\n",
      "n_est=60, min_sample=5, max_d=8\n",
      "n_est=60, min_sample=5, max_d=9\n",
      "n_est=60, min_sample=6, max_d=1\n",
      "n_est=60, min_sample=6, max_d=2\n",
      "n_est=60, min_sample=6, max_d=3\n",
      "n_est=60, min_sample=6, max_d=4\n",
      "n_est=60, min_sample=6, max_d=5\n",
      "n_est=60, min_sample=6, max_d=6\n",
      "n_est=60, min_sample=6, max_d=7\n",
      "n_est=60, min_sample=6, max_d=8\n",
      "n_est=60, min_sample=6, max_d=9\n",
      "n_est=60, min_sample=7, max_d=1\n",
      "n_est=60, min_sample=7, max_d=2\n",
      "n_est=60, min_sample=7, max_d=3\n",
      "n_est=60, min_sample=7, max_d=4\n",
      "n_est=60, min_sample=7, max_d=5\n",
      "n_est=60, min_sample=7, max_d=6\n",
      "n_est=60, min_sample=7, max_d=7\n",
      "n_est=60, min_sample=7, max_d=8\n",
      "n_est=60, min_sample=7, max_d=9\n",
      "n_est=60, min_sample=8, max_d=1\n",
      "n_est=60, min_sample=8, max_d=2\n",
      "n_est=60, min_sample=8, max_d=3\n",
      "n_est=60, min_sample=8, max_d=4\n",
      "n_est=60, min_sample=8, max_d=5\n",
      "n_est=60, min_sample=8, max_d=6\n",
      "n_est=60, min_sample=8, max_d=7\n",
      "n_est=60, min_sample=8, max_d=8\n",
      "n_est=60, min_sample=8, max_d=9\n",
      "n_est=60, min_sample=9, max_d=1\n",
      "n_est=60, min_sample=9, max_d=2\n",
      "n_est=60, min_sample=9, max_d=3\n",
      "n_est=60, min_sample=9, max_d=4\n",
      "n_est=60, min_sample=9, max_d=5\n",
      "n_est=60, min_sample=9, max_d=6\n",
      "n_est=60, min_sample=9, max_d=7\n",
      "n_est=60, min_sample=9, max_d=8\n",
      "n_est=60, min_sample=9, max_d=9\n",
      "n_est=85, min_sample=1, max_d=1\n",
      "n_est=85, min_sample=1, max_d=2\n",
      "n_est=85, min_sample=1, max_d=3\n",
      "n_est=85, min_sample=1, max_d=4\n",
      "n_est=85, min_sample=1, max_d=5\n",
      "n_est=85, min_sample=1, max_d=6\n",
      "n_est=85, min_sample=1, max_d=7\n",
      "n_est=85, min_sample=1, max_d=8\n",
      "n_est=85, min_sample=1, max_d=9\n",
      "n_est=85, min_sample=2, max_d=1\n",
      "n_est=85, min_sample=2, max_d=2\n",
      "n_est=85, min_sample=2, max_d=3\n",
      "n_est=85, min_sample=2, max_d=4\n",
      "n_est=85, min_sample=2, max_d=5\n",
      "n_est=85, min_sample=2, max_d=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_est=85, min_sample=2, max_d=7\n",
      "n_est=85, min_sample=2, max_d=8\n",
      "n_est=85, min_sample=2, max_d=9\n",
      "n_est=85, min_sample=3, max_d=1\n",
      "n_est=85, min_sample=3, max_d=2\n",
      "n_est=85, min_sample=3, max_d=3\n",
      "n_est=85, min_sample=3, max_d=4\n",
      "n_est=85, min_sample=3, max_d=5\n",
      "n_est=85, min_sample=3, max_d=6\n",
      "n_est=85, min_sample=3, max_d=7\n",
      "n_est=85, min_sample=3, max_d=8\n",
      "n_est=85, min_sample=3, max_d=9\n",
      "n_est=85, min_sample=4, max_d=1\n",
      "n_est=85, min_sample=4, max_d=2\n",
      "n_est=85, min_sample=4, max_d=3\n",
      "n_est=85, min_sample=4, max_d=4\n",
      "n_est=85, min_sample=4, max_d=5\n",
      "n_est=85, min_sample=4, max_d=6\n",
      "n_est=85, min_sample=4, max_d=7\n",
      "n_est=85, min_sample=4, max_d=8\n",
      "n_est=85, min_sample=4, max_d=9\n",
      "n_est=85, min_sample=5, max_d=1\n",
      "n_est=85, min_sample=5, max_d=2\n",
      "n_est=85, min_sample=5, max_d=3\n",
      "n_est=85, min_sample=5, max_d=4\n",
      "n_est=85, min_sample=5, max_d=5\n",
      "n_est=85, min_sample=5, max_d=6\n",
      "n_est=85, min_sample=5, max_d=7\n",
      "n_est=85, min_sample=5, max_d=8\n",
      "n_est=85, min_sample=5, max_d=9\n",
      "n_est=85, min_sample=6, max_d=1\n",
      "n_est=85, min_sample=6, max_d=2\n",
      "n_est=85, min_sample=6, max_d=3\n",
      "n_est=85, min_sample=6, max_d=4\n",
      "n_est=85, min_sample=6, max_d=5\n",
      "n_est=85, min_sample=6, max_d=6\n",
      "n_est=85, min_sample=6, max_d=7\n",
      "n_est=85, min_sample=6, max_d=8\n",
      "n_est=85, min_sample=6, max_d=9\n",
      "n_est=85, min_sample=7, max_d=1\n",
      "n_est=85, min_sample=7, max_d=2\n",
      "n_est=85, min_sample=7, max_d=3\n",
      "n_est=85, min_sample=7, max_d=4\n",
      "n_est=85, min_sample=7, max_d=5\n",
      "n_est=85, min_sample=7, max_d=6\n",
      "n_est=85, min_sample=7, max_d=7\n",
      "n_est=85, min_sample=7, max_d=8\n",
      "n_est=85, min_sample=7, max_d=9\n",
      "n_est=85, min_sample=8, max_d=1\n",
      "n_est=85, min_sample=8, max_d=2\n",
      "n_est=85, min_sample=8, max_d=3\n",
      "n_est=85, min_sample=8, max_d=4\n",
      "n_est=85, min_sample=8, max_d=5\n",
      "n_est=85, min_sample=8, max_d=6\n",
      "n_est=85, min_sample=8, max_d=7\n",
      "n_est=85, min_sample=8, max_d=8\n",
      "n_est=85, min_sample=8, max_d=9\n",
      "n_est=85, min_sample=9, max_d=1\n",
      "n_est=85, min_sample=9, max_d=2\n",
      "n_est=85, min_sample=9, max_d=3\n",
      "n_est=85, min_sample=9, max_d=4\n",
      "n_est=85, min_sample=9, max_d=5\n",
      "n_est=85, min_sample=9, max_d=6\n",
      "n_est=85, min_sample=9, max_d=7\n",
      "n_est=85, min_sample=9, max_d=8\n",
      "n_est=85, min_sample=9, max_d=9\n",
      "n_est=110, min_sample=1, max_d=1\n",
      "n_est=110, min_sample=1, max_d=2\n",
      "n_est=110, min_sample=1, max_d=3\n",
      "n_est=110, min_sample=1, max_d=4\n",
      "n_est=110, min_sample=1, max_d=5\n",
      "n_est=110, min_sample=1, max_d=6\n",
      "n_est=110, min_sample=1, max_d=7\n",
      "n_est=110, min_sample=1, max_d=8\n",
      "n_est=110, min_sample=1, max_d=9\n",
      "n_est=110, min_sample=2, max_d=1\n",
      "n_est=110, min_sample=2, max_d=2\n",
      "n_est=110, min_sample=2, max_d=3\n",
      "n_est=110, min_sample=2, max_d=4\n",
      "n_est=110, min_sample=2, max_d=5\n",
      "n_est=110, min_sample=2, max_d=6\n",
      "n_est=110, min_sample=2, max_d=7\n",
      "n_est=110, min_sample=2, max_d=8\n",
      "n_est=110, min_sample=2, max_d=9\n",
      "n_est=110, min_sample=3, max_d=1\n",
      "n_est=110, min_sample=3, max_d=2\n",
      "n_est=110, min_sample=3, max_d=3\n",
      "n_est=110, min_sample=3, max_d=4\n",
      "n_est=110, min_sample=3, max_d=5\n",
      "n_est=110, min_sample=3, max_d=6\n",
      "n_est=110, min_sample=3, max_d=7\n",
      "n_est=110, min_sample=3, max_d=8\n",
      "n_est=110, min_sample=3, max_d=9\n",
      "n_est=110, min_sample=4, max_d=1\n",
      "n_est=110, min_sample=4, max_d=2\n",
      "n_est=110, min_sample=4, max_d=3\n",
      "n_est=110, min_sample=4, max_d=4\n",
      "n_est=110, min_sample=4, max_d=5\n",
      "n_est=110, min_sample=4, max_d=6\n",
      "n_est=110, min_sample=4, max_d=7\n",
      "n_est=110, min_sample=4, max_d=8\n",
      "n_est=110, min_sample=4, max_d=9\n",
      "n_est=110, min_sample=5, max_d=1\n",
      "n_est=110, min_sample=5, max_d=2\n",
      "n_est=110, min_sample=5, max_d=3\n",
      "n_est=110, min_sample=5, max_d=4\n",
      "n_est=110, min_sample=5, max_d=5\n",
      "n_est=110, min_sample=5, max_d=6\n",
      "n_est=110, min_sample=5, max_d=7\n",
      "n_est=110, min_sample=5, max_d=8\n",
      "n_est=110, min_sample=5, max_d=9\n",
      "n_est=110, min_sample=6, max_d=1\n",
      "n_est=110, min_sample=6, max_d=2\n",
      "n_est=110, min_sample=6, max_d=3\n",
      "n_est=110, min_sample=6, max_d=4\n",
      "n_est=110, min_sample=6, max_d=5\n",
      "n_est=110, min_sample=6, max_d=6\n",
      "n_est=110, min_sample=6, max_d=7\n",
      "n_est=110, min_sample=6, max_d=8\n",
      "n_est=110, min_sample=6, max_d=9\n",
      "n_est=110, min_sample=7, max_d=1\n",
      "n_est=110, min_sample=7, max_d=2\n",
      "n_est=110, min_sample=7, max_d=3\n",
      "n_est=110, min_sample=7, max_d=4\n",
      "n_est=110, min_sample=7, max_d=5\n",
      "n_est=110, min_sample=7, max_d=6\n",
      "n_est=110, min_sample=7, max_d=7\n",
      "n_est=110, min_sample=7, max_d=8\n",
      "n_est=110, min_sample=7, max_d=9\n",
      "n_est=110, min_sample=8, max_d=1\n",
      "n_est=110, min_sample=8, max_d=2\n",
      "n_est=110, min_sample=8, max_d=3\n",
      "n_est=110, min_sample=8, max_d=4\n",
      "n_est=110, min_sample=8, max_d=5\n",
      "n_est=110, min_sample=8, max_d=6\n",
      "n_est=110, min_sample=8, max_d=7\n",
      "n_est=110, min_sample=8, max_d=8\n",
      "n_est=110, min_sample=8, max_d=9\n",
      "n_est=110, min_sample=9, max_d=1\n",
      "n_est=110, min_sample=9, max_d=2\n",
      "n_est=110, min_sample=9, max_d=3\n",
      "n_est=110, min_sample=9, max_d=4\n",
      "n_est=110, min_sample=9, max_d=5\n",
      "n_est=110, min_sample=9, max_d=6\n",
      "n_est=110, min_sample=9, max_d=7\n",
      "n_est=110, min_sample=9, max_d=8\n",
      "n_est=110, min_sample=9, max_d=9\n",
      "n_est=135, min_sample=1, max_d=1\n",
      "n_est=135, min_sample=1, max_d=2\n",
      "n_est=135, min_sample=1, max_d=3\n",
      "n_est=135, min_sample=1, max_d=4\n",
      "n_est=135, min_sample=1, max_d=5\n",
      "n_est=135, min_sample=1, max_d=6\n",
      "n_est=135, min_sample=1, max_d=7\n",
      "n_est=135, min_sample=1, max_d=8\n",
      "n_est=135, min_sample=1, max_d=9\n",
      "n_est=135, min_sample=2, max_d=1\n",
      "n_est=135, min_sample=2, max_d=2\n",
      "n_est=135, min_sample=2, max_d=3\n",
      "n_est=135, min_sample=2, max_d=4\n",
      "n_est=135, min_sample=2, max_d=5\n",
      "n_est=135, min_sample=2, max_d=6\n",
      "n_est=135, min_sample=2, max_d=7\n",
      "n_est=135, min_sample=2, max_d=8\n",
      "n_est=135, min_sample=2, max_d=9\n",
      "n_est=135, min_sample=3, max_d=1\n",
      "n_est=135, min_sample=3, max_d=2\n",
      "n_est=135, min_sample=3, max_d=3\n",
      "n_est=135, min_sample=3, max_d=4\n",
      "n_est=135, min_sample=3, max_d=5\n",
      "n_est=135, min_sample=3, max_d=6\n",
      "n_est=135, min_sample=3, max_d=7\n",
      "n_est=135, min_sample=3, max_d=8\n",
      "n_est=135, min_sample=3, max_d=9\n",
      "n_est=135, min_sample=4, max_d=1\n",
      "n_est=135, min_sample=4, max_d=2\n",
      "n_est=135, min_sample=4, max_d=3\n",
      "n_est=135, min_sample=4, max_d=4\n",
      "n_est=135, min_sample=4, max_d=5\n",
      "n_est=135, min_sample=4, max_d=6\n",
      "n_est=135, min_sample=4, max_d=7\n",
      "n_est=135, min_sample=4, max_d=8\n",
      "n_est=135, min_sample=4, max_d=9\n",
      "n_est=135, min_sample=5, max_d=1\n",
      "n_est=135, min_sample=5, max_d=2\n",
      "n_est=135, min_sample=5, max_d=3\n",
      "n_est=135, min_sample=5, max_d=4\n",
      "n_est=135, min_sample=5, max_d=5\n",
      "n_est=135, min_sample=5, max_d=6\n",
      "n_est=135, min_sample=5, max_d=7\n",
      "n_est=135, min_sample=5, max_d=8\n",
      "n_est=135, min_sample=5, max_d=9\n",
      "n_est=135, min_sample=6, max_d=1\n",
      "n_est=135, min_sample=6, max_d=2\n",
      "n_est=135, min_sample=6, max_d=3\n",
      "n_est=135, min_sample=6, max_d=4\n",
      "n_est=135, min_sample=6, max_d=5\n",
      "n_est=135, min_sample=6, max_d=6\n",
      "n_est=135, min_sample=6, max_d=7\n",
      "n_est=135, min_sample=6, max_d=8\n",
      "n_est=135, min_sample=6, max_d=9\n",
      "n_est=135, min_sample=7, max_d=1\n",
      "n_est=135, min_sample=7, max_d=2\n",
      "n_est=135, min_sample=7, max_d=3\n",
      "n_est=135, min_sample=7, max_d=4\n",
      "n_est=135, min_sample=7, max_d=5\n",
      "n_est=135, min_sample=7, max_d=6\n",
      "n_est=135, min_sample=7, max_d=7\n",
      "n_est=135, min_sample=7, max_d=8\n",
      "n_est=135, min_sample=7, max_d=9\n",
      "n_est=135, min_sample=8, max_d=1\n",
      "n_est=135, min_sample=8, max_d=2\n",
      "n_est=135, min_sample=8, max_d=3\n",
      "n_est=135, min_sample=8, max_d=4\n",
      "n_est=135, min_sample=8, max_d=5\n",
      "n_est=135, min_sample=8, max_d=6\n",
      "n_est=135, min_sample=8, max_d=7\n",
      "n_est=135, min_sample=8, max_d=8\n",
      "n_est=135, min_sample=8, max_d=9\n",
      "n_est=135, min_sample=9, max_d=1\n",
      "n_est=135, min_sample=9, max_d=2\n",
      "n_est=135, min_sample=9, max_d=3\n",
      "n_est=135, min_sample=9, max_d=4\n",
      "n_est=135, min_sample=9, max_d=5\n",
      "n_est=135, min_sample=9, max_d=6\n",
      "n_est=135, min_sample=9, max_d=7\n",
      "n_est=135, min_sample=9, max_d=8\n",
      "n_est=135, min_sample=9, max_d=9\n",
      "n_est=160, min_sample=1, max_d=1\n",
      "n_est=160, min_sample=1, max_d=2\n",
      "n_est=160, min_sample=1, max_d=3\n",
      "n_est=160, min_sample=1, max_d=4\n",
      "n_est=160, min_sample=1, max_d=5\n",
      "n_est=160, min_sample=1, max_d=6\n",
      "n_est=160, min_sample=1, max_d=7\n",
      "n_est=160, min_sample=1, max_d=8\n",
      "n_est=160, min_sample=1, max_d=9\n",
      "n_est=160, min_sample=2, max_d=1\n",
      "n_est=160, min_sample=2, max_d=2\n",
      "n_est=160, min_sample=2, max_d=3\n",
      "n_est=160, min_sample=2, max_d=4\n",
      "n_est=160, min_sample=2, max_d=5\n",
      "n_est=160, min_sample=2, max_d=6\n",
      "n_est=160, min_sample=2, max_d=7\n",
      "n_est=160, min_sample=2, max_d=8\n",
      "n_est=160, min_sample=2, max_d=9\n",
      "n_est=160, min_sample=3, max_d=1\n",
      "n_est=160, min_sample=3, max_d=2\n",
      "n_est=160, min_sample=3, max_d=3\n",
      "n_est=160, min_sample=3, max_d=4\n",
      "n_est=160, min_sample=3, max_d=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_est=160, min_sample=3, max_d=6\n",
      "n_est=160, min_sample=3, max_d=7\n",
      "n_est=160, min_sample=3, max_d=8\n",
      "n_est=160, min_sample=3, max_d=9\n",
      "n_est=160, min_sample=4, max_d=1\n",
      "n_est=160, min_sample=4, max_d=2\n",
      "n_est=160, min_sample=4, max_d=3\n",
      "n_est=160, min_sample=4, max_d=4\n",
      "n_est=160, min_sample=4, max_d=5\n",
      "n_est=160, min_sample=4, max_d=6\n",
      "n_est=160, min_sample=4, max_d=7\n",
      "n_est=160, min_sample=4, max_d=8\n",
      "n_est=160, min_sample=4, max_d=9\n",
      "n_est=160, min_sample=5, max_d=1\n",
      "n_est=160, min_sample=5, max_d=2\n",
      "n_est=160, min_sample=5, max_d=3\n",
      "n_est=160, min_sample=5, max_d=4\n",
      "n_est=160, min_sample=5, max_d=5\n",
      "n_est=160, min_sample=5, max_d=6\n",
      "n_est=160, min_sample=5, max_d=7\n",
      "n_est=160, min_sample=5, max_d=8\n",
      "n_est=160, min_sample=5, max_d=9\n",
      "n_est=160, min_sample=6, max_d=1\n",
      "n_est=160, min_sample=6, max_d=2\n",
      "n_est=160, min_sample=6, max_d=3\n",
      "n_est=160, min_sample=6, max_d=4\n",
      "n_est=160, min_sample=6, max_d=5\n",
      "n_est=160, min_sample=6, max_d=6\n",
      "n_est=160, min_sample=6, max_d=7\n",
      "n_est=160, min_sample=6, max_d=8\n",
      "n_est=160, min_sample=6, max_d=9\n",
      "n_est=160, min_sample=7, max_d=1\n",
      "n_est=160, min_sample=7, max_d=2\n",
      "n_est=160, min_sample=7, max_d=3\n",
      "n_est=160, min_sample=7, max_d=4\n",
      "n_est=160, min_sample=7, max_d=5\n",
      "n_est=160, min_sample=7, max_d=6\n",
      "n_est=160, min_sample=7, max_d=7\n",
      "n_est=160, min_sample=7, max_d=8\n",
      "n_est=160, min_sample=7, max_d=9\n",
      "n_est=160, min_sample=8, max_d=1\n",
      "n_est=160, min_sample=8, max_d=2\n",
      "n_est=160, min_sample=8, max_d=3\n",
      "n_est=160, min_sample=8, max_d=4\n",
      "n_est=160, min_sample=8, max_d=5\n",
      "n_est=160, min_sample=8, max_d=6\n",
      "n_est=160, min_sample=8, max_d=7\n",
      "n_est=160, min_sample=8, max_d=8\n",
      "n_est=160, min_sample=8, max_d=9\n",
      "n_est=160, min_sample=9, max_d=1\n",
      "n_est=160, min_sample=9, max_d=2\n",
      "n_est=160, min_sample=9, max_d=3\n",
      "n_est=160, min_sample=9, max_d=4\n",
      "n_est=160, min_sample=9, max_d=5\n",
      "n_est=160, min_sample=9, max_d=6\n",
      "n_est=160, min_sample=9, max_d=7\n",
      "n_est=160, min_sample=9, max_d=8\n",
      "n_est=160, min_sample=9, max_d=9\n",
      "n_est=185, min_sample=1, max_d=1\n",
      "n_est=185, min_sample=1, max_d=2\n",
      "n_est=185, min_sample=1, max_d=3\n",
      "n_est=185, min_sample=1, max_d=4\n",
      "n_est=185, min_sample=1, max_d=5\n",
      "n_est=185, min_sample=1, max_d=6\n",
      "n_est=185, min_sample=1, max_d=7\n",
      "n_est=185, min_sample=1, max_d=8\n",
      "n_est=185, min_sample=1, max_d=9\n",
      "n_est=185, min_sample=2, max_d=1\n",
      "n_est=185, min_sample=2, max_d=2\n",
      "n_est=185, min_sample=2, max_d=3\n",
      "n_est=185, min_sample=2, max_d=4\n",
      "n_est=185, min_sample=2, max_d=5\n",
      "n_est=185, min_sample=2, max_d=6\n",
      "n_est=185, min_sample=2, max_d=7\n",
      "n_est=185, min_sample=2, max_d=8\n",
      "n_est=185, min_sample=2, max_d=9\n",
      "n_est=185, min_sample=3, max_d=1\n",
      "n_est=185, min_sample=3, max_d=2\n",
      "n_est=185, min_sample=3, max_d=3\n",
      "n_est=185, min_sample=3, max_d=4\n",
      "n_est=185, min_sample=3, max_d=5\n",
      "n_est=185, min_sample=3, max_d=6\n",
      "n_est=185, min_sample=3, max_d=7\n",
      "n_est=185, min_sample=3, max_d=8\n",
      "n_est=185, min_sample=3, max_d=9\n",
      "n_est=185, min_sample=4, max_d=1\n",
      "n_est=185, min_sample=4, max_d=2\n",
      "n_est=185, min_sample=4, max_d=3\n",
      "n_est=185, min_sample=4, max_d=4\n",
      "n_est=185, min_sample=4, max_d=5\n",
      "n_est=185, min_sample=4, max_d=6\n",
      "n_est=185, min_sample=4, max_d=7\n",
      "n_est=185, min_sample=4, max_d=8\n",
      "n_est=185, min_sample=4, max_d=9\n",
      "n_est=185, min_sample=5, max_d=1\n",
      "n_est=185, min_sample=5, max_d=2\n",
      "n_est=185, min_sample=5, max_d=3\n",
      "n_est=185, min_sample=5, max_d=4\n",
      "n_est=185, min_sample=5, max_d=5\n",
      "n_est=185, min_sample=5, max_d=6\n",
      "n_est=185, min_sample=5, max_d=7\n",
      "n_est=185, min_sample=5, max_d=8\n",
      "n_est=185, min_sample=5, max_d=9\n",
      "n_est=185, min_sample=6, max_d=1\n",
      "n_est=185, min_sample=6, max_d=2\n",
      "n_est=185, min_sample=6, max_d=3\n",
      "n_est=185, min_sample=6, max_d=4\n",
      "n_est=185, min_sample=6, max_d=5\n",
      "n_est=185, min_sample=6, max_d=6\n",
      "n_est=185, min_sample=6, max_d=7\n",
      "n_est=185, min_sample=6, max_d=8\n",
      "n_est=185, min_sample=6, max_d=9\n",
      "n_est=185, min_sample=7, max_d=1\n",
      "n_est=185, min_sample=7, max_d=2\n",
      "n_est=185, min_sample=7, max_d=3\n",
      "n_est=185, min_sample=7, max_d=4\n",
      "n_est=185, min_sample=7, max_d=5\n",
      "n_est=185, min_sample=7, max_d=6\n",
      "n_est=185, min_sample=7, max_d=7\n",
      "n_est=185, min_sample=7, max_d=8\n",
      "n_est=185, min_sample=7, max_d=9\n",
      "n_est=185, min_sample=8, max_d=1\n",
      "n_est=185, min_sample=8, max_d=2\n",
      "n_est=185, min_sample=8, max_d=3\n",
      "n_est=185, min_sample=8, max_d=4\n",
      "n_est=185, min_sample=8, max_d=5\n",
      "n_est=185, min_sample=8, max_d=6\n",
      "n_est=185, min_sample=8, max_d=7\n",
      "n_est=185, min_sample=8, max_d=8\n",
      "n_est=185, min_sample=8, max_d=9\n",
      "n_est=185, min_sample=9, max_d=1\n",
      "n_est=185, min_sample=9, max_d=2\n",
      "n_est=185, min_sample=9, max_d=3\n",
      "n_est=185, min_sample=9, max_d=4\n",
      "n_est=185, min_sample=9, max_d=5\n",
      "n_est=185, min_sample=9, max_d=6\n",
      "n_est=185, min_sample=9, max_d=7\n",
      "n_est=185, min_sample=9, max_d=8\n",
      "n_est=185, min_sample=9, max_d=9\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n_est in range(10, 200, 25):\n",
    "    for min_sample in range(1, 10, 1):\n",
    "        for max_d in range(1, 10, 1):\n",
    "            \n",
    "            print(\"n_est={}, min_sample={}, max_d={}\".format(n_est, min_sample, max_d))\n",
    "            RF = RandomForestClassifier(n_estimators = n_est,\n",
    "                                     min_samples_leaf = min_sample,\n",
    "                                      max_depth = max_d,\n",
    "                                         bootstrap=True, \n",
    "                                      oob_score=True, random_state=22)\n",
    "            RF.fit(Xvars, yvals)\n",
    "            score = 1-RF.oob_score_\n",
    "            \n",
    "            \n",
    "            r = (score, n_est, min_sample, max_d)\n",
    "            #print(r)\n",
    "            results.append(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05681818181818177, 85, 2, 5),\n",
       " (0.05681818181818177, 85, 2, 6),\n",
       " (0.05681818181818177, 85, 2, 7),\n",
       " (0.05681818181818177, 85, 2, 8),\n",
       " (0.05681818181818177, 85, 2, 9),\n",
       " (0.0625, 35, 2, 5),\n",
       " (0.0625, 60, 2, 5),\n",
       " (0.0625, 60, 2, 6),\n",
       " (0.0625, 60, 2, 7),\n",
       " (0.0625, 60, 2, 8)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort results and print\n",
    "results.sort()\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above we can shrink the error rate to .056 by using n_est = 85, min_sample = 2, and max_depth from 5-9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1d): Use sklearn to fit the model in part b using a SVM. Do k-folds with k=4 as in part b. Play with param values of C and gamma. Report the MSE and param values from this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits = k, random_state=22, shuffle=True)\n",
    "kf.get_n_splits(Xvars)\n",
    "mse_list = []\n",
    "\n",
    "# iterate over possible values of gamme and C\n",
    "for gamma_test in np.linspace(.04, 4, 10):\n",
    "    for c_test in np.linspace(.04, 4, 10):\n",
    "\n",
    "        k_ind = 0\n",
    "        c_mse_splits = []\n",
    "        for train_index, test_index in kf.split(Xvars):\n",
    "\n",
    "            X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "            y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "\n",
    "            svc = svm.SVC(kernel='rbf', gamma = 1.7, C=1)\n",
    "            svc.fit(X_train, y_train)    \n",
    "\n",
    "            y_pred = svc.predict(X_test)\n",
    "            mse = ((y_test != y_pred) ** 2).mean()\n",
    "\n",
    "            c_mse_splits.append(mse)\n",
    "        assert len(c_mse_splits) == 4\n",
    "\n",
    "        c_mse = np.mean(c_mse_splits)    \n",
    "        results = (c_mse, c_test, gamma_test)\n",
    "\n",
    "        mse_list.append( results )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6487603305785125, 0.04, 0.04),\n",
       " (0.6487603305785125, 0.04, 0.48),\n",
       " (0.6487603305785125, 0.04, 0.92),\n",
       " (0.6487603305785125, 0.04, 1.36),\n",
       " (0.6487603305785125, 0.04, 1.8),\n",
       " (0.6487603305785125, 0.04, 2.24),\n",
       " (0.6487603305785125, 0.04, 2.68),\n",
       " (0.6487603305785125, 0.04, 3.12),\n",
       " (0.6487603305785125, 0.04, 3.56),\n",
       " (0.6487603305785125, 0.04, 4.0)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_list.sort()\n",
    "mse_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be an error in the estimation code because the MSE is essentially stuck at .64. Regardless, the result of the 'regression fishing' is an optimal, mse-minimizig params of 0.04 and 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1e): Use sklearn to fit the model to MLPC. Repeat k-folds with k=4. Play with params hidden_layer_sizes, activation, and alpha. Report the MSE and param values from this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.647210743801653, 'identity', 0.04, 100)\n",
      "(0.647210743801653, 'identity', 0.04, 150)\n",
      "(0.6485020661157025, 'identity', 1.0, 100)\n",
      "(0.6485020661157025, 'identity', 1.0, 150)\n",
      "(0.646823347107438, 'logistic', 0.04, 100)\n",
      "(0.6443698347107438, 'logistic', 0.04, 150)\n",
      "(0.6464359504132232, 'logistic', 1.0, 100)\n",
      "(0.6464359504132232, 'logistic', 1.0, 150)\n",
      "(0.6430785123966942, 'tanh', 0.04, 100)\n",
      "(0.6402376033057852, 'tanh', 0.04, 150)\n",
      "(0.6466942148760331, 'tanh', 1.0, 100)\n",
      "(0.6460485537190083, 'tanh', 1.0, 150)\n",
      "(0.6452737603305785, 'relu', 0.04, 100)\n",
      "(0.6461776859504132, 'relu', 0.04, 150)\n",
      "(0.6465650826446281, 'relu', 1.0, 100)\n",
      "(0.6478564049586777, 'relu', 1.0, 150)\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits = k, random_state=22, shuffle=True)\n",
    "kf.get_n_splits(Xvars)\n",
    "mse_list = []\n",
    "\n",
    "# iterate over possible values of C\n",
    "for activ in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "    for a in np.linspace(.04, 1, 2):\n",
    "        for layer in range(100, 200, 50):\n",
    "            k_ind = 0\n",
    "            c_mse_splits = []\n",
    "            for train_index, test_index in kf.split(Xvars):\n",
    "\n",
    "                X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "                y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "\n",
    "                mlpc = MLPClassifier(activation=activ, solver='lbfgs',\n",
    "                                        alpha=a, random_state=25,\n",
    "                                        hidden_layer_sizes = layer)\n",
    "                mlpc.fit(X_train, y_train)    \n",
    "\n",
    "                y_pred = mlpc.predict(X_test)\n",
    "                mse = ((y_test != y_pred) ** 2).mean()\n",
    "\n",
    "                c_mse_splits.append(mse)\n",
    "            assert len(c_mse_splits) == 4\n",
    "\n",
    "            c_mse = np.mean(c_mse_splits)    \n",
    "            results = (c_mse, activ, a, layer)\n",
    "            print(results)\n",
    "\n",
    "            mse_list.append( results )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6402376033057852, 'tanh', 0.04, 150),\n",
       " (0.6430785123966942, 'tanh', 0.04, 100),\n",
       " (0.6443698347107438, 'logistic', 0.04, 150),\n",
       " (0.6452737603305785, 'relu', 0.04, 100),\n",
       " (0.6460485537190083, 'tanh', 1.0, 150),\n",
       " (0.6461776859504132, 'relu', 0.04, 150),\n",
       " (0.6464359504132232, 'logistic', 1.0, 100),\n",
       " (0.6464359504132232, 'logistic', 1.0, 150),\n",
       " (0.6465650826446281, 'relu', 1.0, 100),\n",
       " (0.6466942148760331, 'tanh', 1.0, 100)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_list.sort()\n",
    "mse_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, There still appears to be an error in the estimation code because the MSE is essentially stuck at .64. Regardless, the result of the 'regression fishing' is an optimal, mse-minimizig params of 0.04 and 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1f): Which of the above four models is the best predictor? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would expect the nueral net to have the best predictive power because it has the greatest flexibiity in its functional form. Assuming we have tuned the model correctly, the NN would be the most predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
