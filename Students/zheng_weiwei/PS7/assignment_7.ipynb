{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set #7\n",
    "## Name: Weiwei Zheng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      5\n",
       "weight          0\n",
       "acceleration    0\n",
       "year            0\n",
       "origin          0\n",
       "name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('Auto.csv', sep=',', na_values = \"?\")\n",
    "auto.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0      0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1      1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2      2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3      3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4      4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   year  origin                       name  \n",
       "0    70       1  chevrolet chevelle malibu  \n",
       "1    70       1          buick skylark 320  \n",
       "2    70       1         plymouth satellite  \n",
       "3    70       1              amc rebel sst  \n",
       "4    70       1                ford torino  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.dropna(inplace = True)\n",
    "auto = auto.reset_index()\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (auto['mpg'] >= auto['mpg'].median()).astype(int)\n",
    "X = auto[['cylinders', 'displacement', 'horsepower', 'weight', \\\n",
    "         'acceleration', 'year', 'origin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***a) logistic regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "X.loc[:,'constant'] = 1\n",
    "kf_log = KFold(n_splits = 4, shuffle = True, random_state = 15)\n",
    "kf_log.get_n_splits(X)\n",
    "error_df_log = pd.DataFrame({\"error\": np.zeros(0), \"y_test\": np.zeros(0), \\\n",
    "                              \"y_pred\": np.zeros(0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xvals = X.values\n",
    "yvals = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_log = 0\n",
    "    \n",
    "for train_index, test_index in kf_log.split(Xvals):\n",
    "    X_train, X_test = Xvals[train_index], Xvals[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "    LogReg = LogisticRegression()\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    error_df_k = pd.DataFrame({\"error\": np.zeros(len(test_index)), \\\n",
    "                            \"y_test\": y_test, \"y_pred\": y_pred})\n",
    "    error_df_k['error'] = (error_df_k[\"y_test\"] != error_df_k[\"y_pred\"]).astype(int)\n",
    "    error_df_log = pd.concat([error_df_log, error_df_k])    \n",
    "    MSE_log += error_df_k[\"error\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.88      0.89       196\n",
      "        1.0       0.88      0.91      0.89       196\n",
      "\n",
      "avg / total       0.89      0.89      0.89       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(error_df_log[\"y_test\"], error_df_log[\"y_pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE_log= 0.10714285714285715\n",
      "error rate for mpg_high = 1 is 0.1188118811881188\n",
      "error rate for mpg_high = 0 is 0.09473684210526316\n"
     ]
    }
   ],
   "source": [
    "print('test estimate MSE_log=', MSE_log/4)\n",
    "print('error rate for mpg_high = 1 is', error_df_log[error_df_log[\"y_pred\"] \\\n",
    "                                                     == 1][\"error\"].mean())\n",
    "print('error rate for mpg_high = 0 is', error_df_log[error_df_log[\"y_pred\"] \\\n",
    "                                                     == 0][\"error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***b) random forest ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_random = RandomForestClassifier(n_estimators = 20, max_features = 2, \\\n",
    "                                     bootstrap = True, oob_score = True, \n",
    "                                     random_state = 25)\n",
    "X_sub = auto[['cylinders', 'displacement', 'horsepower', 'weight', \\\n",
    "         'acceleration', 'year', 'origin']]\n",
    "tree_random.fit(X_sub, y)\n",
    "y_pred = pd.DataFrame(tree_random.oob_decision_function_.T[1], columns = ['y_pred'])\n",
    "y_pred['y_pred'] = (y_pred['y_pred'] >= .5).astype(int)\n",
    "mse_tree = mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.942     0.913     0.927       196\n",
      "          1      0.916     0.944     0.930       196\n",
      "\n",
      "avg / total      0.929     0.929     0.929       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred, digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE_tree= 0.0714285714286\n",
      "error rate for mpg_high = 1 is 0.084\n",
      "error rate for mpg_high = 0 is 0.058\n"
     ]
    }
   ],
   "source": [
    "print('test estimate MSE_tree=', mse_tree)\n",
    "print('error rate for mpg_high = 1 is 0.084')\n",
    "print('error rate for mpg_high = 0 is 0.058')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***c) support vector machine ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_svm = KFold(n_splits = 4, shuffle = True, random_state = 15)\n",
    "kf_svm.get_n_splits(X_sub)\n",
    "error_df_svm = pd.DataFrame({\"error\": np.zeros(0), \"y_test\": np.zeros(0), \\\n",
    "                              \"y_pred\": np.zeros(0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.04      0.07        55\n",
      "          1       0.45      1.00      0.62        43\n",
      "\n",
      "avg / total       0.76      0.46      0.31        98\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      1.00      0.65        47\n",
      "          1       0.00      0.00      0.00        51\n",
      "\n",
      "avg / total       0.23      0.48      0.31        98\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      1.00      0.64        45\n",
      "          1       1.00      0.04      0.07        53\n",
      "\n",
      "avg / total       0.76      0.48      0.33        98\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      1.00      0.69        49\n",
      "          1       1.00      0.10      0.19        49\n",
      "\n",
      "avg / total       0.76      0.55      0.44        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "MSE_svm = 0\n",
    "    \n",
    "for train_index, test_index in kf_svm.split(X_sub):\n",
    "    X_train, X_test = X_sub.values[train_index], X_sub.values[test_index]\n",
    "    y_train, y_test = yvals[train_index], yvals[test_index]    \n",
    "    svm_rbf = svm.SVC(C=1, gamma = 0.2)\n",
    "    svm_rbf.fit(X_train, y_train)\n",
    "    y_pred = svm_rbf.predict(X_test)\n",
    "    print('\\n',classification_report(y_test, y_pred))   \n",
    "    error_df_k = pd.DataFrame({\"error\": np.zeros(len(test_index)), \\\n",
    "                               \"y_test\": y_test, \"y_pred\": y_pred})\n",
    "    error_df_k['error'] = (error_df_k[\"y_test\"] != error_df_k[\"y_pred\"]).astype(int)\n",
    "    error_df_svm = pd.concat([error_df_svm, error_df_k])    \n",
    "    MSE_svm += error_df_k[\"error\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <th>y_pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y_test\n",
       "error y_pred        \n",
       "0.0   0.0        143\n",
       "      1.0         50\n",
       "1.0   0.0        146\n",
       "      1.0         53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df_svm.groupby(['error', 'y_pred']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0      0.495     0.730     0.590       196\n",
      "        1.0      0.485     0.255     0.334       196\n",
      "\n",
      "avg / total      0.490     0.492     0.462       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(error_df_svm[\"y_test\"], error_df_svm[\"y_pred\"], digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE_log= 0.5076530612244898\n",
      "error rate for mpg_high = 1 is 0.5145631067961165\n",
      "error rate for mpg_high = 0 is 0.5051903114186851\n"
     ]
    }
   ],
   "source": [
    "print('test estimate MSE_log=', MSE_svm/4)\n",
    "print('error rate for mpg_high = 1 is', error_df_svm[error_df_svm[\"y_pred\"] \\\n",
    "                                                     == 1][\"error\"].mean())\n",
    "print('error rate for mpg_high = 0 is', error_df_svm[error_df_svm[\"y_pred\"] \\\n",
    "                                                     == 0][\"error\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***d) model comparision ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, random forest should be the best approach of the three to predict mpg_high, for it has the lowest MSE, and highes precision for both categories. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
